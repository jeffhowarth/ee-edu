{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ee pattern book","text":"<p>A collection of timeless problems of spatial analysis and image processing and how to solve them with Google Earth Engine.      </p> <p>Jeff Howarth Associate Professor of Geography  Geography Department Middlebury College Vermont, USA</p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"geo-module/","title":"geo module","text":"<p>The geo module is a collection of methods that I am writing and packaging in a way that will allow you to use the methods without having to write them from scratch. </p> <p>I wrote these methods for two reasons:    </p> <ol> <li> <p>Each represents a recurring task of geospatial analysis that is supported by other geographic information systems (like QGIS or ArcGIS).</p> </li> <li> <p>Each requires a chain of transformations to make in Earth Engine which can be conceptually confusing and technically difficult for novices to do.    </p> </li> </ol> <p>My hope is that providing ready-made methods may help you focus on how different methods of spatial analysis and cartography work conceptually in workflows without having to get bogged down in writing complicated task chains for common tools.  </p>"},{"location":"geo-module/#import-module","title":"import module","text":"<p>To use the module, create a container and require the module. </p> <pre><code>var geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n</code></pre> <p>The code block above will import the module and print the module\u2019s help dictionary and palette dictionary to the Console. The help dictionary lists all methods and url links to their docs. The palette dictionary lists all palettes in the module. You only need to import the module once in a script that calls a method or palette from the module. I usually place the above code snippet near the top of my script (under the header).  </p>"},{"location":"geo-module/#docs-in-eepatterns","title":"docs in eePatterns","text":"<p>A globe icon  identifies methods from module. </p> <p>In the METHODS documentation, the  symbol identifies a method that requires the geo module. To use any of these methods, you will need to include the import module in your script prior to calling the method. </p>"},{"location":"geo-module/#peak-under-hood","title":"peak under hood","text":"<p>Add module to your READER tray if you want to see the underlying code to any method.</p> <p>The module only hides the code from you if you do not want to see it. If you would like to look under the hood, I have made the code for the module public and you can add it to the READER tray of the IDE by clicking here. </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"intro/","title":"introduction","text":"<p>This book aims to help you create geospatial workflows with Google Earth Engine.  </p> <p>In general, these workflows grab geographic data stored in the cloud, alter it (with purpose), and then visualize the results as map layers.  </p> <p> <pre><code>graph LR\n  step01[(\"GEOGRAPHIC\\nDATA\\n\\n stored in cloud\")] ;\n  step02&gt;\"GEOSPATIAL WORKFLOW\\n\\n alter and visualize\"] ;\n\n  step01 --&gt; step02\n\n  classDef store fill:#4AA8A0,stroke-width:0px,color:#FFFFFF; \n  classDef transform fill:#4A92A8,stroke-width:0px,color:#FFFFFF;\n\n  class step01 store; \n  class step02 transform;\n\n</code></pre> <p></p> <p>To do this, we will use a web-based Integrated Development Environment (IDE) for the Earth Engine Javascript Application Programming Interface (API). That is a mouthful, but in practical terms it means that we will create workflows by writing scripts with javascript.   </p>"},{"location":"intro/#data-transformation","title":"data transformation","text":"<p>The basic element of all geospatial workflows is a three step process that Waldo Tobler called a cartographic transformation: you start with geographic data in a certain state (input), you do something to alter the data (method), and you store the result (output). Often but not always, one or more options (arguments) constrain how a method alters the input.   </p> <p> <pre><code>graph LR\n\n  input[\"INPUT\"] ;\n  method(\"METHOD\") ;\n  output[/\"OUTPUT\"/]  ;\n\n  input --&gt; method --&gt; output\n\n  arg[\"argument\"] ;\n\n  arg --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg; </code></pre> <p></p>"},{"location":"intro/#statements","title":"statements","text":"<p>With JavaScript, we transform geographic data by writing a statement. The syntax generally takes this form:</p> <pre><code>var output = input.method(argument);\n</code></pre> <p>The general pattern is that you start by defining a name for a container that you would like to make so that you can store the output. This container of data is called a variable that you create with the keyword <code>var</code>. You then say that this container will contain <code>=</code> what results from taking the input and applying a method to it <code>.</code> with one or more arguments <code>()</code>. A semicolon <code>;</code> punctuates a statement like a period (or wink ).  </p>"},{"location":"intro/#task-tree","title":"task tree","text":"<p>Workflows are a means to achieving an end. When you sit down to write a workflow, you have some goal state for the data in mind. Your problem is to figure out how to change the data from their original condition to the goal state in your head.  </p> <p>Most workflows can be decomposed into a task tree: at the top, a (big) problem  may be broken down into a sequence of smaller tasks, each of these tasks may be broken down into smaller subtasks.    </p> <pre><code>graph TD\n\n  L01(\"PROBLEM\") ;\n  L11[\"TASK 1\"] ;\n  L12[\"TASK 2\"] ;\n  L21[\"SUBTASK 1\"] ;\n  L22[\"SUBTASK 2\"] ;\n  L23[\"SUBTASK 3\"] ;\n  L24[\"SUBTASK 4\"] ;\n\n  L01 --- L11 \n  L01 --- L12\n  L11 --- L21\n  L11 --- L22\n  L12 --- L23\n  L12 --- L24\n\n  classDef L0 fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef L1 fill:#CCCCCC,stroke-width:0px,color:#000000;\n  classDef L2 fill:#000000,stroke-width:0px,color:#FFFFFF;  \n\n  class L01 L0; \n  class L11 L1;\n  class L12 L1;\n  class L21 L2;\n  class L22 L2;\n  class L23 L2;\n  class L24 L2;\n\n</code></pre> <p></p>"},{"location":"intro/#task-chain","title":"task chain","text":"<p>The lowest branches of the tree are individual transformations, the foundational elements of a workflow. Higher branches of the tree often require linking together two or more transformations as a task chain, where the output of one transformation becomes the input of another. </p> <p> <pre><code>graph LR\n  step01(\"INPUT\") ;\n  step02[\"METHOD\"] ;\n  step03(\"OUTPUT\")  ;\n  step04[\"METHOD_2\"] ;\n  step05(\"OUTPUT_2\")  ;\n  arg01(\"argument\") ;\n  arg02(\"argument_2\") ;\n\n  step01 --&gt; step02 --&gt; step03 --&gt; step04 --&gt; step05\n  arg01 --- step02\n  arg02 --- step04\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class step04 op;\n  class step05 in-out;\n  class arg01 arg;\n  class arg02 arg;\n\n</code></pre> <p></p>"},{"location":"intro/#summary","title":"summary","text":"<p>If this all sounds a bit wonky, do not worry too much. We will get to examples that illustrate all of this soon. For now, I just want you to know:  </p> <ol> <li>a workflow is a chain of input-method-output transformations </li> <li>you can think of a workflow visually (as a flow diagram) and verbally (as javascript).  </li> <li>visually, a workflow contains a vertical hierarchy of purpose (task tree) and a horizontal sequence of transformations (task chains). </li> </ol> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"three-t/","title":"the three Ts","text":"<p>Writing geospatial workflows brings together three domains:  </p> <ol> <li> <p>Thematic: the vocabulary, concepts, principles, theories, etc. of your application domain; the academic discipline, professional context, etc that defines the terms and beliefs of your inquiry.  </p> </li> <li> <p>Technical: the concepts and methods of the geographic information software that you are using to develop your workflows. For example, Google Earth Engine Javascript API, ArcGIS Pro, QGIS, GDAL, etc.</p> </li> <li> <p>Theoretical: the timeless concepts and methods of geospatial analysis and cartography; the body of knowledge that you need to understand to solve geospatial problems regardless of the thematic or technical domains that you are working in. </p> </li> </ol> <p>more soon</p>"},{"location":"three-t/#conceptual-models","title":"conceptual models","text":"<p>A key idea in geospatial workflows is that you can represent the world as a series of map layers for computation and comparison. So it is helpful to become familiar with the relatively small set of conceptual models that geospatial workflows tend to employ as instruments for representing the world as map layers.  </p> <p></p>"},{"location":"three-t/#data-models","title":"data models","text":"<p>When you develop geospatial workflows, your recurring task is to move between conceptual models and data models. In other words, you conceptualize a way to represent geography and then you implement this concept with a data model. </p> <p>more soon </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/composite-mosaic/","title":"flatten collections","text":"<p>PATTERNS</p>"},{"location":"patterns/composite-mosaic/#flatten-image-collections","title":"flatten image collections","text":"<p>Many workflows for image collections will include a step that transforms an image collection into a single image (and flattens the collection).  </p>"},{"location":"patterns/composite-mosaic/#composite-image","title":"composite image","text":"<p>If the collection represents a time series of satellite scenes, the workflow will often include a step that makes a composite image.</p> <p>We will get to composite images in the second half of the semester. </p>"},{"location":"patterns/composite-mosaic/#mosaic-image","title":"mosaic image","text":"<p>If the collection contains a set of small tiles, then a workflow will often include a step that makes a mosaic image. This is a common step in workflows with lidar products.  </p> <p></p> <p> <pre><code>graph LR\n\n  method(\"geo.icFlatten.mosaicToImage()\") ;\n  output[/\"ic_mosaic\"/]  ;\n\n  method --&gt; output\n\n  arg[\"ic\"] ;\n\n  arg --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg; </code></pre> <p></p> <pre><code>var ic_mosaic = geo.icFlatten.mosaicToImage(ic);\n\nprint(\"Mosaic\", ic_mosaic);\n</code></pre> <p>This method mosaics the tiles into a single image and gives the new image the same coordinate reference system as the first image in the collection. The crs defines the xy units of the image and this enables you to use the mosaic image as an input in terrain operations.  </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/convert-data/","title":"convert data","text":"<p>PATTERNS</p>"},{"location":"patterns/convert-data/#convert-data","title":"convert data","text":"<p>These methods change the models used to represent geographic data and include:</p> <ul> <li>vector to raster</li> <li>raster to vector</li> </ul>"},{"location":"patterns/convert-data/#vector-to-raster","title":"vector to raster","text":"<p>These methods typically convert feature collections to images. </p> <p>more soon </p>"},{"location":"patterns/convert-data/#any-fc-to-boolean-raster","title":"any FC to boolean raster","text":"<p>This method converts a feature collection into a boolean raster. </p> <pre><code>var image_boolean = geo.fcConvert.toBooleanImage(fc);\n</code></pre>"},{"location":"patterns/convert-data/#nominal-fc-to-integer-raster","title":"nominal FC to integer raster","text":"<p>This method converts a feature collection with text attributes to a single-band image. It essentially creates a list of unique text attributes from a table column (defined by \u201ccolumn_name\u201d) and matches each unique text attribute to a unique integer. The result is an image with integer pixel values. The method also prints a dictionary to the Console that reports the integer code for each unique attribute.   </p> <pre><code>var image_nominal = geo.fcConvert.toNominalImage(fc, \"column_name\");\n</code></pre>"},{"location":"patterns/convert-data/#numeric-fc-to-numeric-raster","title":"numeric FC to numeric raster","text":"<p>This method uses numeric attribute data in a feature collection to create a raster. </p> <pre><code>var image_numeric = geo.fcConvert.toNumericImage(fc, \"column_name\", \"reducer\");\n</code></pre> <p>The method takes three arguments that are defined in the table below.  </p> ARGUMENTS DESCRIPTION fc The feature collection to convert. \u201ccolumn_name\u201d The name of the column with the numeric data to populate the pixel values of the output raster. \u201creducer\u201d How you would like to handle cases where two of more features overlap. Essentially, what value do you want to populate a pixel with when there is more than one number? This must be a string and one of the following: \u201cmean\u201d, \u201cfirst\u201d, \u201cmax\u201d, \u201cmin\u201d."},{"location":"patterns/convert-data/#raster-to-vector","title":"raster to vector","text":"<p>These methods typically convert images to feature collections.  </p> <p>more soon </p>"},{"location":"patterns/convert-data/#make-objects-with-vectors","title":"make objects with vectors","text":"<p>This method identifies objects from rasters based on two conditions: </p> <p>(1) Pixels share the same value. (2) Pixels form contiguous regions that can be represented with a polygon.  </p> <p>It returns a feature collection of distinct regions and includes the area as an attribute of each feature.  </p> <pre><code>var objects_with_vectors = geo.iConvert.makeObjectsWithVectors(image, \"property\", scale, extent, \"unit\");\n</code></pre> ARGUMENTS DESCRIPTION image Input image with a band that represent boolean or nominal (class) raster to clump. \u201cproperty\u201d A description (as a string) of the boolean or class data used to clump. Flr example, \u201cclass\u201d. scale Scale of analysis to help troubleshoot TIME OUT errors. Often good practice to start relatively coarse and then increase resolution in later runs. extent The area of interest or study region to constrain analysis. \u201cunit\u201d Choose between \u201cacres\u201d, \u201csq_m\u201d, and \u201csq_km\u201d <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/customize-Map/","title":"customize Map","text":"<p>PATTERNS</p>"},{"location":"patterns/customize-Map/#customize-map","title":"customize Map","text":"<p>It is often helpful to customize the Map so that it centers and zooms on your area of interest and uses a base map that supports your purpose.  </p> <p>The diagram below shows a general pattern.</p> <p> <pre><code>graph LR\n\n  step01(\"Set map center and zoom\") ;\n  step02(\"Set base map style\") ;\n\n  step01 --&gt; step02\n\n  classDef task fill:#C3C8E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>It is good practice to set the map center and zoom level before setting the base map so that the base map does not need to redraw.</p>"},{"location":"patterns/customize-Map/#set-map-center-and-zoom","title":"set map center and zoom","text":"<p>Use a data object to center the map and to suggest an appropriate zoom level. </p> <pre><code>Map.centerObject(\nobject,             // data object to center the Map. \n16                  // zoom level to display the Map.\n);\n</code></pre>"},{"location":"patterns/customize-Map/#set-basemap-style","title":"set basemap style","text":"<p>Select a basemap that provides the most helpful reference information from your data. </p> <pre><code>Map.setOptions(\"HYBRID\");\n</code></pre> <p>Choose from the following options: </p> <p><pre><code>\"ROADMAP\" </code></pre> <pre><code>\"SATELLITE\" </code></pre> <pre><code>\"HYBRID\"\n</code></pre> <pre><code>\"TERRAIN\" </code></pre></p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/explain-code/","title":"explain code","text":"<p>PATTERNS</p>"},{"location":"patterns/explain-code/#explain-code","title":"explain code","text":"<p>Always write your code for two main audiences: </p> <ol> <li>a computer that will compile and execute your code;</li> <li>a person who will read your code and try to make sense of it. </li> </ol> <p>The second audience may be yourself in the future, when you return to a script that you wrote after some time has passed. It may be an instructor in this course who wants to help you troubleshoot something in your script that is not working. Or it may be someone you have never met who is looking to adapt and recycle parts of your script for a slightly different purpose. Whoever the reader may be, you should always aim to help people read your code by placing explanations directly in your workflow. </p> <p>The patterns below describe different ways to explain your code and make it more readable for a human audience. </p>"},{"location":"patterns/explain-code/#script-header","title":"script header","text":"<p>Write a header at the top of your script.</p> <p>At a minimum, the header should identify who wrote the script, when they wrote it, and why they wrote it. This is also where many authors will define the license for the script.  </p> <p>I usually include a couple lines of repeating symbols to visually block the header and separate it from the rest of the script.  </p> <pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     \n    TITLE:  \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n</code></pre>"},{"location":"patterns/explain-code/#task-description","title":"task description","text":"<p>Write a line comment before each major task in your workflow.</p> <p>Describe what you are doing or why you are doing it. Use full sentences and correct punctuation (start each comment with a capital letter and end each comment with a period).  </p> <p>I usually include a line of repeating symbols above and below the task description to help visually separate the code into discrete chunks.  </p> <pre><code>// -------------------------------------------------------------\n//  To illustrate a task description.\n// -------------------------------------------------------------\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/explain-symbology/","title":"explain symbology","text":"<p>PATTERNS</p>"},{"location":"patterns/explain-symbology/#explain-layer-symbology","title":"explain layer symbology","text":"<p>Methods for defining what colors in palettes mean on your map.  </p> <p>more forthcoming </p>"},{"location":"patterns/explain-symbology/#define-colors-with-legend","title":"define colors with legend","text":"<p>These methods take some or all of the following arguments.</p> ARGUMENT DESCRIPTION \u201ctitle\u201d Label for the legend. Must be a string. Often a short description of image will do. viz The viz dictionary that defines how to visualize (display) the data. class_labels A list of names for each color in the palette that define the classes or categories of the data. \u201cposition-on-map\u201d Where to place the legend. Must be a string. Composed as \u201crow - column\u201d, where rows are \u201cbottom\u201d, \u201cmiddle\u201d, or \u201ctop\u201d and columns are \u201cleft\u201d, \u201ccenter\u201d, \u201cright\u201d. For example, \u201cbottom-right\u201d. There is no \u201cmiddle-center\u201d."},{"location":"patterns/explain-symbology/#image-with-continuous-data","title":"image with continuous data","text":"<p>If the image contains continuous or cyclical data, place a snapshot of the color gradient on the Map with labels that identify the minimum, maximum, and midpoint data value mapped to the color gradient. </p> <pre><code>// Make legend from image with continuous data. \n\nvar legend_continuous = geo.iCart.legendContinuous(\n\"title\", viz, \"position-on-map\"\n)\n;\n\n// Add legend to Map.  \n\nMap.add(legend_continuous);\n</code></pre>"},{"location":"patterns/explain-symbology/#from-image-with-nominal-data","title":"from image with nominal data","text":"<p>If the image contains nominal (discrete) data, place a symbol dictionary that defines each swatch of the palette with a label, or name for the class.     </p> <pre><code>// Make legend from image with nominal data.\n\nvar legend_nominal = geo.iCart.legendNominal(\n\"title\", viz, class_labels, \"position-on-map\"\n)\n;\n\n// Add legend to Map.  \n\nMap.add(legend_nominal);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/export/","title":"export data","text":"<p>PATTERNS</p>"},{"location":"patterns/export/#export-data","title":"export data","text":"<p>Earth Engine does not permanently store the data objects that you make in your workflows unless you specifically ask it to do so. The patterns below deal with two different scenarios:  </p> <ol> <li>exporting data to a cloud asset</li> <li>exporting data to a cloud drive</li> </ol>"},{"location":"patterns/export/#to-cloud-asset","title":"to cloud asset","text":"<p>Whenever you pan your Map or zoom in and out of your Map, Earth Engine will run through all the steps required to make your data layers at the scale and extent that you are requesting.  </p> <p>Because of this, it is common to get to the point in a workflow where two things happen:  </p> <ol> <li> <p>Earth Engine starts to balk at the amount of work you are asking it to do and throws time out or tile errors.  </p> </li> <li> <p>You get impatient waiting for Earth Engine to process a long workflow just to zoom in and out and pan around your map. (When the slippy map gets sticky, it is like watching a game or movie that keeps buffering.)  </p> </li> </ol> <p>At this point, I tend to export my data as an asset so that I can just call the result directly. This is analogous to saving a copy of your data in the cloud. The asset will have a cloud address that you can then use to gather the data back into your workflow with a constructor like <code>ee.Image()</code>.   </p> <p>Please note that when you export data as cloud assets, you are no longer storing it as a variable. So these patterns do not begin by declaring a variable. They simply execute a function.   </p>"},{"location":"patterns/export/#export-fc","title":"export fc","text":"<p>This method will create a task that will export a feature collection as a Google Earth Engine asset. You will need to go to the task tab and run the task. When it is complete, you can access the asset through the asset tab. Open the asset (double-click) and then copy the asset id. You can then use this address in a data gathering pattern for vector data.</p> <pre><code>geo.fcExport.toCloudAsset(fc, \"asset_name\");\n</code></pre> <p> ARGUMENT DESCRIPTION fc A feature collection to export. \u201casset_name\u201d A name for the asset. <p></p>"},{"location":"patterns/export/#export-image","title":"export image","text":"<p>This method will create a task that will export an image as a Google Earth Engine asset. You again will need to go to the task tab and run the task. When it is complete, you can access the asset through the asset tab. Open the asset (double-click) and then copy the asset id. You can then use this address in a data gathering pattern for raster data.</p> <pre><code>geo.iExport.toCloudAsset(\nimage, \"asset_name\",\nextent, \"pyramiding\"\n);\n</code></pre> <p> ARGUMENT DESCRIPTION image An image to export. \u201casset_name\u201d A name for the asset. extent The area of interest or study region to define the bounds of the image. \u201cpyramiding\u201d The method for generating pyramid layers to display in slippy map. Use \u201cmode\u201d for boolean, categorical, and object rasters and \u201cmean\u201d for field rasters. <p></p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/filter-collections/","title":"filter collections","text":"<p>PATTERNS</p>"},{"location":"patterns/filter-collections/#filter-collections","title":"filter collections","text":"<p>Image and feature collections often include more data than you need. As a result, both tend to follow this pattern: </p> <p> <pre><code>graph LR\n\n  step01(\"Access collection from cloud\") ;\n  step02(\"Filter collection\") ;\n\n  step01 --&gt; step02\n\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000 ;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>A filter is a method of asking a true or false question about the content of a collection and then only keeping the records where the answer is true. In other GIS, these are called selections or queries which are often written in SQL, which follows a similar logic but employs a different syntax.  </p> <p>In Earth Engine, you can filter collections in three ways:  </p> <ul> <li>by time, </li> <li>by location, </li> <li>by attribute. </li> </ul>"},{"location":"patterns/filter-collections/#filter-by-time","title":"filter by time","text":"<p>we will get to this in a couple of weeks </p>"},{"location":"patterns/filter-collections/#filter-by-location","title":"filter by location","text":"<p>This involves making spatial comparisons between two layers. One layer is a collection of things (features, images) that has more things than you need. The other layer is a geometry, feature, or feature collection that defines your place of interest. These filters work by comparing the location of things in the first collection with the location of the place of interest in the second layer.   </p>"},{"location":"patterns/filter-collections/#by-bounds","title":"by bounds","text":"<p>One of the most common spatial filters tests for overlap between items in the collection and the place of interest. Any item in the collection that overlaps the place of interest will pass through the filter and the rest of the things will be filtered out. Even things that only overlap the place of interest on the very edge will still pass through the filter and remain in the collection. The diagram below shows this by passing items 7, 13, 19 through the filter. You can think of the items in this collection as either individual images (image collection) or individual features (feature collection).   </p> <p></p> <p>It is sometimes helpful to think of this as a fork filter, because this filter does not alter the shape of the items in the collection. The filter does not cut them, as a knife would, and the collective shape of the items that pass through the filter does not match the shape of the place of interest.  </p> <p>The syntax for this method in Earth Engine looks a little clunky because you first call <code>.filter()</code> on the collection that you want to filter (called c for collection in the code snippet), which then takes <code>ee.Filter.bounds()</code> as an argument, which itself takes the place of interest object as an argument.  </p> <pre><code>graph LR\n\n  input[\"collection\"] ;\n  method(\"&lt;b&gt;.filter()&lt;/b&gt;\") ;\n  output[/\"collection_filter_bounds\"/]  ;\n\n  input --&gt; method --&gt; output\n\n  arg[\"ee.Filter.bounds()\"] ;\n\n  arg --o method\n\n  arg2[\"place_of_interest\"] ;\n\n  arg2 --o arg\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg; \n  class arg2 arg;</code></pre> <pre><code>var collection_filter_bounds = collection.filter(ee.Filter.bounds(place_of_interest));\n</code></pre> <p>Because this method is very commonly used to filter both image and feature collections but has such wonky syntax, Earth Engine provides an alternative expression to call the method that is a bit simpler to write. In the snippet below, c is the collection to filter and place_of_interest is the object that is being used to test for overlap it. </p> <pre><code>var collection_filter_bounds = collection.filterBounds(place_of_interest);\n</code></pre> <p>The main advantage of learning to write the first, clunky syntax is that you can use it to include the filter in AND methods (see below).  </p>"},{"location":"patterns/filter-collections/#check-results","title":"check results","text":"<p>After applying a filter, it is good practice to quickly check to see if the filter reduced the collection and by how much.    </p> <pre><code>print(\n\"collection before:\",\ncollection.size(),\n\"collection after:\"\ncollection_filter_bounds.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#full-pattern","title":"full pattern","text":"<p>Here is the full pattern for filtering by overlap.  </p> <pre><code>// Filter feature collection for overlap with fork. \n\nvar collection_filter_bounds = collection.filterBounds(fork);\n\n// Check filtered result.  \n\nprint(\n\"collection before:\",\ncollection.size(),\n\"collection after:\"\ncollection_filter_bounds.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#other-spatial-filters","title":"other spatial filters","text":"<p>The <code>.filterBounds()</code> method is a generally fast method to filter by location, but sometimes you may not want to keep features that only overlap the boundary of the place of interest. To help in these cases, I wrote a custom method that allows you to filter features in one collection based on their spatial relationship to features in another collection (place of interest).      </p> <pre><code>var fc_spatial_filter = geo.fcFilter.spatial('spatialRelationship', collection, place_of_interest);\n</code></pre> <p>You may choose one of three spatial relationships.  </p> SPATIAL RELATIONSHIP DESCRIPTION \u201ccontainedIn\u201d Returns features in collection that are contained by place of interest. \u201cdisjoint\u201d Returns features in collection that do not touch place of interest. \u201cintersects\u201d Returns features in collection that touch a place of interest."},{"location":"patterns/filter-collections/#filter-by-attribute","title":"filter by attribute","text":"<p>These methods allow you to filter a collection based on property values of items in the collection. They work for both image collections and feature collections. The filter essentially asks a true/falsw question about the properties of the collection and returns the elements of the collection where the answer is true. </p> <p></p>"},{"location":"patterns/filter-collections/#filter-by-attribute_1","title":"filter by attribute","text":"<pre><code>var collection_filtered = collection.filter(\nee.Filter.eq('property', 'value')\n);\n</code></pre>"},{"location":"patterns/filter-collections/#check-filter-results","title":"check filter results","text":"<pre><code>print(\n\"collection before:\",\ncollection.size(),\n\"collection after:\"\ncollection_filtered.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#full-pattern_1","title":"full pattern","text":"<pre><code>// Filter by attribute  \n\nvar collection_filtered = collection.filter(\nee.Filter.eq('property', 'value')\n);\n\n// Check filtered result.  \n\nprint(\n\"collection before:\",\nc.size(),\n\"collection after:\"\nc_filtered.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#other-criteria","title":"other criteria","text":"<p>There are a number of filters that follow the same pattern as above and take property and attribute value as arguments. The <code>ee.Filter.eq()</code> and <code>ee.Filter.neq()</code> can take either a string or number as the value argument. The other filters listed below typically take a number.  </p> <pre><code>ee.Filter.eq('property', 'value')        // Equal to\n</code></pre> <pre><code>ee.Filter.neq('property', 'value')       // Not equal to\n</code></pre> <pre><code>ee.Filter.gt('property', 0)              // greater than\n</code></pre> <pre><code>ee.Filter.gte('property', 0)            // greater than or equal to\n</code></pre> <pre><code>ee.Filter.lt('property', 0)             // less than\n</code></pre> <pre><code>ee.Filter.lte('property', 0)            // less than or equal to\n</code></pre>"},{"location":"patterns/filter-collections/#filter-fc-by-multiple-criteria","title":"filter FC by multiple criteria","text":"<p>More soon</p>"},{"location":"patterns/filter-collections/#and-filter","title":"AND filter","text":"<pre><code>var fc_filter_and = fc.filter(\nee.Filter.and(\nee.Filter.eq(\"property\", \"value\"),\nee.Filter.eq(\"property\", \"value\")\n)\n);\n\nprint(\n\"collection before:\",\nc.size(),\n\"collection after:\"\nc_filtered.size()\n);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/focal-operations/","title":"focal (neighborhood) operations","text":"<p>PATTERNS</p>"},{"location":"patterns/focal-operations/#focal-operations","title":"focal operations","text":"<p>Focal operations use a moving window to carry out a computation based on values in the neighborhood of a focal cell. The window moves systematically across the raster, performing calculations for each pixel.    </p> <p></p> <p>The result of each neighborhood calculation is stored in the output raster pixel that corresponds with the location of the focal pixel in the input raster. The shape and size of the moving window is defined by a kernel.  The example below uses a square, 3 x 3 pixel kernel to compute the average neighborhood value for a focal pixel.  </p> <p> </p>"},{"location":"patterns/focal-operations/#scale-of-analysis","title":"scale of analysis","text":"<p>;</p> <p>source</p>"},{"location":"patterns/focal-operations/#object-rasters-from-clusters","title":"Object rasters from clusters","text":"<p>more soon </p>"},{"location":"patterns/focal-operations/#make-objects-from-clusters","title":"make objects from clusters","text":"<p>This method uses uses either a \u2018plus\u2019 or \u2018square\u2019 moving window to clump pixels that:</p> <ol> <li>have the same value and</li> <li>touch on adjacent sides (\u2018plus\u2019 window) and/or corners (\u2018square\u2019 window).  </li> </ol> <p>It returns an image with the original band(s) and a new band called \u2018labels\u2019 that identifies contiguous regions with unique integer values. It is usually helpful to select the \u2018labels\u2019 band and visualize it with <code>.randomVisualizer()</code>. </p> <p>The method works relatively quickly, but has two important quirks that result from Earth Engine\u2019s architecture:  </p> <ol> <li>It cannot identify objects that are larger than 1024 pixels.  </li> <li>The scale of analysis is determined by zoom level. Because of this, the results will change as you zoom in and out of the output layer.  </li> </ol> <p>Here is the basic pattern.  </p> <pre><code>var objects_from_clusters = geo.iFocal.makeObjectsFromClusters(image, 'kernel');  Map.addLayer(objects_from_clusters.select(\"labels\").randomVisualizer(), {}, \"4.1. Objects from clusters\";\n</code></pre> ARGUMENT DESCRIPTION image Input image with a band that contains a boolean or nominal (class) raster. If image contains more than one band, select the band that identifies the classes that you want to cluster. \u2018kernel\u2019 Either \u2018plus\u2019 or \u2018square\u2019. A \u2018square\u2019 will clump pixels that touch at corners, while a \u2018plus\u2019 will only clump pixels that share a side."},{"location":"patterns/focal-operations/#object-area-from-clusters","title":"object area from clusters","text":"<p>This method calculates the area of distinct objects with a square (3x3 pixel) moving window. It is similar to the method described above, but differs in two ways:  </p> <ol> <li>It can only use a \u2018square\u2019 window (so pixels will be clustered if they touch on corners).</li> <li>It returns an image with only one band, named \u2018area\u2019, that stores the area (square meters) of the object in each pixel of the object.  </li> </ol> <p>It suffers from the same two quirks described above (limited size and changes with zoom level).</p> <p>Here is the basic pattern:</p> <pre><code>var object_area_clusters = geo.iFocal.objectAreaFromClusters(image, \"band\");\n</code></pre> <p>The table below describes the arguments.  </p> ARGUMENTS DESCRIPTION image An input image. \u201cband\u201d The band name with boolean or class values to cluster. <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/gather-raster-data/","title":"gather raster data","text":"<p>PATTERNS</p>"},{"location":"patterns/gather-raster-data/#gather-raster-data","title":"gather raster data","text":"<p>One of the first things you will usually do with Earth Engine is gather some data from the cloud. Before we get too deep into this, we should review the basic templates for storing geographic data (geographic data models) and how they are implemented in Earth Engine.     </p>"},{"location":"patterns/gather-raster-data/#raster-data-model","title":"raster data model","text":"<p>A raster stores geographic data with a grid of pixels. Each pixel, or cell in the grid, stores a value as a digital number. The data type defines the length of binary numbers used to store the digital number. In the diagram below, the values shown on the left can be stored as a 8 bit unsigned integer, or byte, data type shown on the right. </p> <p></p>"},{"location":"patterns/gather-raster-data/#image-data-object","title":"image data object","text":"<p>In Earth Engine, the raster model underlies the image data object, where an image is composed of one or more bands and each band is a raster.  </p> <p></p>"},{"location":"patterns/gather-raster-data/#accessing-images-from-cloud","title":"accessing images from cloud","text":"<p>The diagram below shows a typical pattern for accessing cloud data.</p> <p> <pre><code>\ngraph LR\n\n  step01(\"Construct from address\") ;\n  step02(\"Inspect data object\") ;\n\n  step01 --&gt; step02\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>The pattern is to first construct the object and then immediately inspect the properties of the object.  </p>"},{"location":"patterns/gather-raster-data/#construct-image-from-address","title":"construct image from address","text":"<p>Use the <code>ee.Image()</code> method to construct an image from the cloud. This method takes the address for the data asset as an argument.   </p> <p> <pre><code>graph LR\n  step02(\"ee.Image()\") ;\n  step03[/\"image\"/]  ;\n  arg01[\"'address/of/cloud/data'\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; \n</code></pre> <p></p> <p>To adapt the snippet below, you will just need to replace <code>'address/of/cloud/data'</code> with the data address. The address must be a string.  </p> <pre><code>var image = ee.Image('address/of/cloud/data');\n</code></pre>"},{"location":"patterns/gather-raster-data/#inspect-data-properties","title":"inspect data properties","text":"<p>After constructing or altering a data object, I usually want to quickly familiarize myself the properties of the data. To do this, use the <code>print()</code> method to print the properties of the data object to the Console.  </p> <pre><code>print(\n\"A helpful label\",\nimage\n)\n;\n</code></pre> <p>To adapt the snippet below, replace <code>\"A helpful label\"</code> with a label that describes the image you are working with. This label must be a string. As necessary, replace <code>image</code> in the following line with the name of the variable that contains the image data.  </p>"},{"location":"patterns/gather-raster-data/#full-pattern","title":"full pattern","text":"<p>Here are the two parts of the pattern together.</p> <pre><code>var image = ee.Image('address/of/cloud/data');\n\nprint(\n\"A helpful label\",\nimage\n)\n;\n</code></pre>"},{"location":"patterns/gather-raster-data/#image-collection-data-object","title":"image collection data object","text":"<p>In Earth Engine, an image collection is what it sounds like: a collection of images. Earth Engine often uses these raster data objects to store satellite observations, because most satellites observe a region of the earth\u2019s surface (often called a scene) at a moment in time and then return to this scene at regular intervals to create a time series. In these cases, an image collection provides a way to store all the different scenes observed at all the different times by a satellite mission.    </p> <p>image forthcoming </p> <p>Image collections are also useful for storing high-resolution rasters as a set of small tiles, or images with relatively small geographic extent, that can be stitched together into larger images as needed. For example, Earth Engine will often store Lidar products and high resolution imagery as image collections. </p> <p></p>"},{"location":"patterns/gather-raster-data/#construct-from-address","title":"construct from address","text":"<p>Use the <code>ee.ImageCollection()</code> method to construct an image collection from the cloud. The method takes the cloud address as an argument.  </p> <p> <pre><code>graph LR\n  step02(\"ee.ImageCollection()\") ;\n  step03[/\"ic\"/]  ;\n  arg01[\"'address/of/cloud/data'\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; </code></pre> <p></p> <p>Here is the pattern in javascript:</p> <pre><code>var ic = ee.ImageCollection('address/of/cloud/data');\n</code></pre>"},{"location":"patterns/gather-raster-data/#inspect-data","title":"inspect data","text":"<p>After constructing an ic object, I tend to use a <code>print()</code> method to learn a couple things about the data.  </p> <pre><code>print(\n\"IC Name\",\nic.size(),          // Consider commenting out this line to make script run faster. \nic.first(),\n)\n;\n</code></pre> <p>The <code>ic.size()</code> method tells me how many images the collection contains. If the collection is huge, this method can take a while to run, so often I will comment out this line after I have looked at the result to help make the script run faster on subsequent runs. The <code>ic.first()</code> method tells me some details about the first image in the collection and usually the other images in the collection will have the same band names and property keys.  </p>"},{"location":"patterns/gather-raster-data/#full-pattern_1","title":"full pattern","text":"<p>Here are the two parts of the pattern together.  </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/gather-vector-data/","title":"gather vector data","text":"<p>PATTERNS</p>"},{"location":"patterns/gather-vector-data/#gather-vector-data","title":"gather vector data","text":"<p>Points and polylines and polygons, oh my.  </p> <p>more forthcoming </p>"},{"location":"patterns/gather-vector-data/#accessing-data-from-cloud","title":"accessing data from cloud","text":"<p>The general pattern for acquiring vector data from the cloud is quite similar to the one for raster data.   </p> <p> <pre><code>graph LR\n\n  step01(\"Construct from address\") ;\n  step02(\"Inspect data object\") ;\n\n  step01 --&gt; step02\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p>"},{"location":"patterns/gather-vector-data/#construct-fc-from-address","title":"construct fc from address","text":"<pre><code>var fc = ee.FeatureCollection(\"address/of/cloud/data\");\n</code></pre>"},{"location":"patterns/gather-vector-data/#inspect-data","title":"inspect data","text":"<p>Working with vector data in Earth Engine can be a little challenging because you never really get to see the data as a table. You can, however, try to piece together the basic structure of the table by asking a set of questions about the data with the <code>print()</code> method.   </p>"},{"location":"patterns/gather-vector-data/#how-many-rows-in-table","title":"how many rows in table?","text":"<p>This method will print the number of features in the collection to the Console, which is the same as the number of rows in a table. </p> <pre><code>print(\n\"fc size\",\nfc.size()\n);\n</code></pre> <p>It is often helpful to know how many features the collection contains at the start as a way to monitor the results of your filters in subsequent steps.  </p>"},{"location":"patterns/gather-vector-data/#what-is-first-row-of-table","title":"what is first row of table?","text":"<p>This method will print the first row of the table as a dictionary to the Console.  </p> <pre><code>print(\n\"fc first row\",\nfc.first()\n);\n</code></pre> <p>The keys of the dictionary are the column names of the table. The values in the dictionary are the values for the first row of the table. Often, the first row is arbitrary and you may not even know where this feature is in the world. But your goal here is to understand the data schema:  </p> <ul> <li>what are the column names that define the categories of attributes stored in the table?  </li> <li>what is the format of the column names and attribute values? Are they text or numbers? If text, are they all caps, title case, all lower?  </li> </ul> <p>This information is usually quite helpful when you need to filter the collection in subsequent steps.  </p>"},{"location":"patterns/gather-vector-data/#what-are-all-unique-values-of-a-target-column","title":"what are all unique values of a target column?","text":"<p>This method will print all the unique values for a target column that you specify with the \u201cproperty_name\u201d argument. You usually find the column name use the <code>fc.first()</code> method shown above.  </p> <pre><code>print(\n\"FC unique values for target category\",\nfc.aggregate_array('property_name').distinct().sort()\n);\n</code></pre> <p>This information usually facilitates filter by attribute methods. (I often copy and paste attributes from this list to avoid typos).     </p>"},{"location":"patterns/gather-vector-data/#full-pattern","title":"full pattern","text":"<p>Here is the full pattern for constructing and inspecting feature collections.  </p> <pre><code>// Gather fc data from address.\n\nvar fc = ee.FeatureCollection(\"address/of/cloud/data\");\n\n// Inspect the table.  \n\nprint(\n\"FC NAME\",\n\"number of rows:\",\nfc.size(),\n\"first row of table:\",\nfc.first(),\n\"unique values for target column:\",\nfc.aggregate_array('column_name').distinct().sort()\n);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/javascript/","title":"javascript","text":"<p>PATTERNS</p>"},{"location":"patterns/javascript/#javascript","title":"JavaScript","text":"<p>Here are some basic patterns for writing in JavaScript.</p>"},{"location":"patterns/javascript/#comments","title":"comments","text":"<p>Use comments to explain your code.</p> <pre><code>// Line comments start with two forward slashes. Like this line. \n\n/* Multi-line comments start with a forward slash and a star,\nand end with a star and a forward slash. */ </code></pre>"},{"location":"patterns/javascript/#variables","title":"variables","text":"<p>Use variables to contain (hold, store) data. </p> <pre><code>// Write a statement using the keyword var.\n\nvar hello = 'Hello world';    // Statements should end in a semi-colon, or else the Code Editor complains.\n\nvar test = \"I feel incomplete...\"\n\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n// !! Variable names cannot contain spaces or - dashes - !!\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n// Use underscores to separate words in variable names.\n\nvar this_is_called_snake_case = 'Hello, snake!';\n\n// Or use capitalizations to separate words:\n\nvar thisIsCalledCamelCase = 'Hello, camel!';\n</code></pre>"},{"location":"patterns/javascript/#print-to-console","title":"print to console","text":"<p>Use print function to print contents of variables and objects to console. </p> <pre><code>// Use parenthesis to pass arguments to print function.  \n\nprint(hello);\n\n// Use commas to pass multiple arguments. \n\nprint('Print test', hello);\n</code></pre>"},{"location":"patterns/javascript/#strings","title":"strings","text":"<p>Use strings to store text (character strings). </p> <pre><code>// Use single quotes to define string.\n\nvar hello = 'Hello world!'  // This is a string. \n\n// You can also use double quotes to enclose string.\n\nvar obi_one = \"Hello there\";\n\n// Just do not mix them.\n\nvar cranky = \"Hello Newman';  // This will throw an error. You will need to match the quotation marks to fix it. \n</code></pre> <p>A string has a set of methods that work with that type of data.</p> <pre><code>// Use a period and parentheses to call a string method.\n\nprint(\nhello,                  // Original object that contains a string.\nhello.slice(0,2),       // Keep the first through third characters of the string.\nhello.concat('!'),      // Add an exclamation point after the string.\nhello.toUpperCase()     // Change the case to all upper. \n)\n;\n</code></pre>"},{"location":"patterns/javascript/#numbers","title":"numbers","text":"<p>Use numbers to store numerical data. </p> <pre><code>// These are both numbers. \n\nvar integer = 12;\nvar decimal = 11.987654321;\n\nprint(integer, decimal);              // Print number variables to Console\n\n// You can call some number methods with dot notation.\n\nprint(decimal.toFixed(4));  // Or call Javascript Math method that take number object as argument.\n\nprint(Math.round(decimal));           // Round decimal number to integer.\nprint(Math.floor(decimal));           // Round decimal number DOWN to nearest integer.\nprint(Math.ceil(decimal));            // Round decimal number UP to nearest integer.\n</code></pre>"},{"location":"patterns/javascript/#lists","title":"lists","text":"<p>Use lists to store a set of data. </p> <pre><code>// Use square brackets to define a list.\n\nvar some_vt_towns = ['Middlebury', 'New Haven', 'Bristol'];\n\n// Use square brackets after lists to select items.\n\nprint(some_vt_towns, some_vt_towns[0]);\n\n// Call list methods with dot notation.  \n\nprint(some_vt_towns.reverse());\n</code></pre>"},{"location":"patterns/javascript/#dictionaries","title":"dictionaries","text":"<p>Use dictionaries to store keys and values. </p> <pre><code>// Use curly brackets (or braces) to define dictionaries.\n\nvar midd = {\n\"name\": \"Middlebury\",  // Dictionaries are composed of key:value pairs.\n\"pop_2010\": 8496,\n\"pop_2020\": 9152\n};\n\nprint(\"Middlebury\", midd);\n\n// Use dot notation to call the value(s) of a key.\n\nprint(midd.name);\n</code></pre>"},{"location":"patterns/javascript/#functions","title":"functions","text":"<p>Write functions to make chunks of code reuseable. </p> <pre><code>// A simple function the takes a string as an argument.  \n\nvar i_love_function = function(some_string) {\nreturn 'I love '.concat(some_string).concat('!');\n};\n\nprint(i_love_function('maps'));\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/local-operations/","title":"local overlay operations","text":"<p>PATTERNS</p>"},{"location":"patterns/local-operations/#local-overlay-operations","title":"local overlay operations","text":"<p>These methods compare values at corresponding pixels in two or more rasters. </p> <p></p>"},{"location":"patterns/local-operations/#masks","title":"masks","text":"<p>Masks act like masking tape when you paint. When you mask pixels in a raster before displaying the raster as a map layer, all the pixels with the mask will remain transparent (they will not be displayed with a color). Similarly, when you mask pixels of an input raster in an operation, the masked pixels will be excluded from the computation.  </p> <p>Typically, workflows with masks involve three steps.    </p> <p> <pre><code>graph LR\n  step01(\"Make mask\")\n  step02(\"Apply mask\") ;\n  step03(\"Paint (display as layer)\") ;\n  step04(\"Transform (input in operation)\") ;\n\n\n  step01 --&gt; step02\n  step02 --&gt; step03\n  step02 --&gt; step04\n\n\n  classDef steps fill:#C9C3E6,stroke-width:1px,stroke: #00000000, color:#000000; \n\n\n\n  class step01 steps; \n  class step02 steps;\n  class step03 steps;\n  class step04 steps; </code></pre> <p></p>"},{"location":"patterns/local-operations/#mask-pixels","title":"mask pixels","text":"<p>This pattern uses another raster, typically a Boolean raster as a mask on another raster. </p> <p>Any pixel with the value 0 in the mask acts like masking tape and prevents numbers in the output raster from being painted at that location. Masked values will not be displayed with colors when you place the raster layer on a Map. Masked values in an input raster will also be ignored in any subsequent operation.    </p> <p></p> <p> <pre><code>graph LR\n  input[image]\n  method(\".updateMask()\") ;\n  output[/\"image_with_mask\"/]  ;\n  arg01[\"mask&lt;br&gt;boolean_raster\"] ;\n\n  input --&gt; method\n  method --&gt; output\n  arg01 --o method\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg01 arg; </code></pre> <p></p> <pre><code>var image_with_mask = image.updateMask(boolean_image);\n</code></pre>"},{"location":"patterns/local-operations/#self-mask-pixels","title":"self mask pixels","text":"<p>If you want to ignore pixels that store the value 0 in an raster, you can self-mask. This is not technically a local operation because it only involves one raster, but I wanted to keep the mask operations together. </p> <p></p> <p> <pre><code>graph LR\n  input[image]\n  method(\".selfMask()\") ;\n  output[/\"image_with_mask\"/]  ;\n\n  input --&gt; method\n  method --&gt; output\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;</code></pre> <p></p> <pre><code>var image_with_mask = image.selfMask();\n</code></pre>"},{"location":"patterns/local-operations/#unmask","title":"unmask","text":"<p>If you are working with a masked image, you can remove the mask and populate all the masked locations with a constant. Again, this is not technically a local operation because it only involves one raster, but I wanted to keep the mask operations together. </p> <p></p> <p> <pre><code>graph LR\n  input[\"image_with_mask\"]\n  method(\".unmask()\") ;\n  output[/\"image_without_mask\"/]  ;\n  arg[\"constant\"]\n\n  input --&gt; method\n  method --&gt; output\n  arg --o method  \n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg</code></pre> <p></p> <pre><code>var image_without_mask = image_with_mask.unmask();\n</code></pre> <p>In Earth Engine, <code>unmask()</code> will replace masked values with 0 by default (This makes the method the inverse of <code>selfMask()</code>. You can include an argument (a number in the parantheses) to specify a different constant.   </p>"},{"location":"patterns/local-operations/#logical-comparisons","title":"logical comparisons","text":"<p>The diagram below illustrates three common logical comparisons between two regions: A, B. Going from left to right, the first picture shows the two regions. The second picture shows where either region A or region B are present (or true), called the union of the two. The third picture shows where both region A and region B are present, called the intersection of the two. The fourth and final picture shows where region A is present but not region B. In this last case, region B acts like an eraser or knife that cuts out the portion of region A that it touches. Sometimes this last case is called the difference or subtraction of two sets.    </p> <p></p> <p>The patterns below describe how each logical comparison shown above can be implemented with raster data models.  </p>"},{"location":"patterns/local-operations/#union","title":"union","text":"<p>The <code>.or()</code> method takes two rasters as inputs and kicks out a boolean raster that represents their union: pixels in the output raster are true if they are true (not 0) in either raster A or raster B.  </p> <p></p> <p>The inputs are commonly boolean rasters, as illustrated in the above diagram, but the method will work with nominal (class) data, returning a boolean raster.  </p> <p></p> <p>The order of the inputs (which raster is image_A versus image_B) does not really matter. The main thing to remember here is that any masked pixels will be excluded from this operation. So it is good practice to triple-check your inputs to see if you are using a mask on pixels that should be zeros so that you do not inadvertently erase locations that are true in one layer but masked in another.  </p> <pre><code>var image_union = image_A.or(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#intersection","title":"intersection","text":"<p>The <code>and()</code> method takes two rasters as inputs and kicks out a boolean raster that represents their intersection: pixels in the output raster are true (not 0) if they are true (not zero) in both raster A and raster B.  </p> <p></p> <p>Like the <code>or</code> operation, the inputs are commonly boolean rasters, but the method will work with nominal (class) data, returning a boolean raster as shown below.  </p> <p></p> <p>The order of inputs again does not really matter here. And because this operation is like a knife that cuts and alters the shapes of inputs, this method is less sensitive to masks, unlike the <code>or()</code> method.</p> <pre><code>var image_intersection = image_A.and(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#not","title":"not","text":"<p>In Earth Engine, finding locations that are in raster A but not in raster B is a little tricky. The workflow involves inverting the binary of raster_B and then multiplying it against raster_A.   </p> <p></p> <pre><code>var image_A_not_B = image_A.multiply(image_B_inverted_binary);\n</code></pre>"},{"location":"patterns/local-operations/#map-arithmetic","title":"map arithmetic","text":"<p>As the diagram at the top of this page illustrates, a common type of local overlay operation performs arithmetic operations (addition, subtraction, multiplication, and division) with two rasters.  </p>"},{"location":"patterns/local-operations/#addition","title":"addition","text":"<p>The <code>.add()</code> method performs addition between values in corresponding pixels of two rasters. The order (which raster is A versus B) does not matter. The main thing to remember is that any pixel that is masked will be excluded from the operation (so that output pixel will remain masked).  </p> <p></p> <pre><code>var image_A_add_B = image_A.add(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#subtraction","title":"subtraction","text":"<p>The <code>.subtract()</code> method performs subtraction between values in corresponding pixels of two rasters. The order matters here: you subtract image_B from image_A. Masked pixels in either raster will remain masked in the output.  </p> <p></p> <pre><code>var image_A_subtract_B = image_A.subtract(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#multiplication","title":"multiplication","text":"<p>The <code>.multiply()</code> method performs multiplication between values in corresponding pixels of two rasters. The order does not matter here. Masked pixels do matter and will remain masked. </p> <p>Multiplication is often used with a boolean raster as a method to erase values in another image, because 0 will convert to 0 and 1 will retain the original value.   </p> <p></p> <pre><code>var image_A_subtract_B = image_A.multiply(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#division","title":"division","text":"<p>The <code>.divide()</code> method performs division between values in corresponding pixels of the two rasters. The order does matter here because you divide the values in image_A by the values in image_B. Masked pixels in either image again remain masked in the output.  </p> <p></p> <pre><code>var image_A_divide_B = image_A.divide(image_B);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/map-raster-layers/","title":"map raster as layers","text":"<p>PATTERNS</p>"},{"location":"patterns/map-raster-layers/#map-raster-layers","title":"map raster layers","text":"<p>Any geographic information system will provide methods for displaying data as a map layer.  </p> <p>To understand these patterns, it will be helpful to review some basic concepts of data visualization.  </p>"},{"location":"patterns/map-raster-layers/#data-values-vs-display-values","title":"data values vs. display values","text":"<p>When you visualize data, you map data values to display values. Two things often happen by default:  </p> <ol> <li>The data type of the digital numbers defines the range of values that get mapped to the display values.</li> <li>The relationship between data values and display values is linear.  </li> </ol> <p></p> <p>The reason that the displayed values in the example above have such poor contrast is a result of the mismatch between the possible data values defined by the data type and the actual data values stored in the raster.  </p> <p>A histogram is one way to compare the possible and actual data values of a raster. </p> <p></p> <p>A common strategy to improve the contrast of an image is to stretch the display values over the range of actual data values by setting the linear map to begin and end at the minimum and maximum actual data value, respectively. This is usually called stretch enhancement.   </p> <p></p>"},{"location":"patterns/map-raster-layers/#display-image-as-layer","title":"display image as layer","text":"<p>The diagram below shows a general pattern to display an image as a map layer with Earth Engine. The first two tasks \u2013 print min &amp; max value and chart histogram \u2013 are methods to identify the range of actual data values in the image and how they are distributed, respectively. The middle task \u2013 define viz dictionary \u2013 is a method for storing the min and max values for stretch enhancements. The last task \u2013 display data as map layer \u2013 draws the result on the Map.  </p> <p> <pre><code>graph LR\n\n  step01(\"Print min &amp; max value\") ;\n  step02(\"Chart histogram\") ;\n  step03(\"Define viz dictionary\")  ;\n  step04(\"display data as map layer\") ;\n\n  step01 --&gt; step03 \n  step02 --&gt; step03 \n  step03 --&gt; step04\n\n  classDef task fill:#C3D3E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n  class step03 task;\n  class step04 task;\n</code></pre> <p></p>"},{"location":"patterns/map-raster-layers/#print-min-max-value-of-image","title":"print min &amp; max value of image","text":"<p>Print the min and max data value of a raster image to use as min and max values in viz dictionary.   </p> <pre><code>var output_min_max = geo.iCart.iMinMax(image, scale, extent);\n\nprint(\"Min &amp; max value of image\", output_min_max);\n</code></pre> ARGUMENT DESCRIPTION image The name of the variable that contains the image data to process. scale The scale of analysis. If possible, use the scale (resolution) of the input image. If this runs really slow (or times out), then increase the scale of analysis by a factor of 2 or more. extent Usually the area of interest or the geographic footprint of the image."},{"location":"patterns/map-raster-layers/#chart-histogram-of-data-values","title":"chart histogram of data values","text":"<p>See how your data are distributed between the minimum and maximum data value by charting a histogram.</p> <pre><code>var output_histogram = geo.iCart.iHistogram(image, scale, extent);\n\nprint(\"Image histogram\", output_histogram);\n</code></pre> ARGUMENT DESCRIPTION input_image The name of the variable that contains the image data to process. scale The scale of analysis. If possible, use the scale (resolution) of the input image. If this runs really slow (or times out), then increase the scale of analysis by a factor of 2 or more. extent Usually the area of interest or the geographic footprint of the image."},{"location":"patterns/map-raster-layers/#define-raster-viz-dictionary","title":"define raster viz dictionary","text":"<p>For raster data, store the viz dictionary as a variable and then call this variable when you add the map layer. </p> <p>Here is a common pattern to visualize single-band images with grayscale:</p> <pre><code>var single_viz = {\nmin: [],        max: [],        }\n;\n</code></pre> <p>Here is a common pattern to visualize single-band images with color (this includes both color gradient layers and nominal layers where a unique color displays each unique class):</p> <pre><code>var single_viz = {\nmin: [],        max: [],        palette: [],    }\n;\n</code></pre> <p>This is a common pattern to visualize multi-band images as a combination of red, green, and blue channels:</p> <pre><code>var multi_viz = {\nbands: [],      min:  [].      max: [],        gamma: [],      }\n;\n</code></pre> <p>If your image data represents nominal data with integers, you can quickly visualize this data with random colors using the <code>.randomVisualizer()</code> method on the image and calling an empty dictionary for the viz parameters.    </p> <pre><code>Map.addLayer(image.randomVisualizer(), {}, \"Nominal Classes\");\n</code></pre> <p>This pattern is most useful for quick visualizations, when the color used to display the class does not matter too much. If you want to be able to control which color displays each class, then you should use the single band image with color pattern described earlier and make sure that the length (number of) integer values in your class set equals the length of colors in your palette.   </p>"},{"location":"patterns/map-raster-layers/#add-map-layer","title":"add map layer","text":"<p><code>Map.addLayer()</code> method will display data as a map layer.    </p> <pre><code>Map.addLayer(data,viz,\"Layer Name\",show,opacity);\n</code></pre> <p>The <code>Map.addLayer()</code> method takes the following arguments: </p> ARGUMENT DESCRIPTION data The name of the variable that contains the data that you wish to display. viz The viz dictionary that defines how to visualize (display) the data. layer name A string that provides a label for the data in the list of layers. show A boolean argument to control whether or not the layer is displayed when first loaded. opacity A decimal number between 0 and 1 to adjust the opacity of the layer."},{"location":"patterns/map-raster-layers/#complete-pattern","title":"complete pattern","text":"<p>Here is a complete pattern for single-band grayscale images.</p> <pre><code>// Print min and max values of image. \n\nprint(\"Min &amp; max value of image\", geo.iCart.iMinMax(image, scale, extent));\n\n// Chart histogram of actual data values.\n\nprint(\"Image histogram\", geo.iCart.iHistogram(image, scale, extent));\n\n// Define viz dictionary. \n\nvar single_viz = {\nmin: [],        max: [],        }\n;\n\n// Add map layer. \n\nMap.addLayer(image,single_viz,\"Layer Name\");\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/map-vector-layers/","title":"map vector as layers","text":"<p>PATTERNS</p>"},{"location":"patterns/map-vector-layers/#map-vector-layers","title":"map vector layers","text":"<p>Earth Engine is primarily a tool for visualizing raster data. This means two things:  </p> <ul> <li>you can choose a color to display vector data, but not much else;</li> <li>if you want to control more than just the color, you will need to convert your vector data into an image. </li> </ul>"},{"location":"patterns/map-vector-layers/#simple-viz-with-color","title":"simple viz with color","text":"<p>Similar to raster data, you use the <code>Map.addLayer()</code> method to display a feature collection as a map layer. This method takes the same five data objects described previously, but the viz dictionary here is much simpler: it can only contain a <code>color</code> key. Because of this, I usually write the dictionary directly into the statement.    </p> <pre><code>Map.addLayer(fc, {color: 'white'}, \"Layer Name\");\n</code></pre>"},{"location":"patterns/map-vector-layers/#paint-strokes-without-fill","title":"paint strokes without fill","text":"<p>Sometimes it is helpful to draw just the outlines (strokes) of features on a map, leaving the fills (interiors) completely transparent. This is particularly helpful with cadastre (property) lines and other boundaries of human geography.  </p> <p>The method below allows you to paint the strokes of features in a collection with a color and weight (thickness) of your choice and store the output as an RGB image. (An RGB image has three bands that combine to make colors).  </p> <p>You can then add the rgb image to the map as a layer, using empty curly brackets <code>{}</code> as a placeholder for the viz dictionary. You do not need to define the viz parameters because the data type is a byte (0-255) and Earth Engine will display the three bands (red, green, blue) correctly by default.  </p> <pre><code>var strokes = geo.fcCart.paintStrokes(fc, \"white\", 0.5);\n\nMap.addLayer(strokes, {}, \"Feature outlines\");\n</code></pre> <p>If you then add the <code>strokes</code> layer on top of the other layers on the Map, you will be able to see the underlying layer through the transparent interiors of the features in the collection.  </p>"},{"location":"patterns/map-vector-layers/#paint-nominal-values-with-colors","title":"paint nominal values with colors","text":"<p>If you have a feature collection with nominal data (classes, categories) and you would like to display each class with a unique color, then this pattern should work:</p> <p> <pre><code>graph LR\n\n  step01(\"Convert fc to nominal image\") ;\n  step02(\"Display image as layer\") ;\n\n  step01 --&gt; step02\n\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000 ;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/proximity-operations/","title":"proximity operations","text":"<p>PATTERNS</p>"},{"location":"patterns/proximity-operations/#proximity-operations","title":"proximity operations","text":"<p>Proximity operations concern questions of distance, how near (or far) places are from each other.  </p> <p>more soon </p>"},{"location":"patterns/proximity-operations/#a-short-illustration","title":"a short illustration","text":"<p>I find the proximity methods in earth engine to be a little confusing, so I made the app below to illustrate how some important concepts. The text below walks you through how to build the map layers in the app. </p> <p> </p> <p>open app in new tab</p>"},{"location":"patterns/proximity-operations/#00-start-a-script","title":"00 start a script","text":"<p>This workflow draws on methods in the geo module, so you will need to load that module after you write a script header. </p> <pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   Jeff Howarth   \n    DATE:     10/7/2024  \n    TITLE:    On distance with web mercator\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n</code></pre>"},{"location":"patterns/proximity-operations/#01-proximity-with-vector","title":"01 proximity with vector","text":"<p>The first part of the script demonstrates proximity methods with vector. We start by constructing and drawing a test point in the center of Youngman\u2019s Field. </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. Proximity with vector. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Gather Test point\n// -------------------------------------------------------------\n\nvar test_point = ee.FeatureCollection(\"projects/ee-patterns/assets/t05/youngman_center\");\n\n// -------------------------------------------------------------\n//  1.2 Set Map center, zoom, and base layer. \n// -------------------------------------------------------------\n\nMap.centerObject(test_point, 19);\nMap.setOptions('HYBRID');\n\n// -------------------------------------------------------------\n//  1.3 Add test point layer. \n// -------------------------------------------------------------\n\nMap.addLayer(test_point, {color: 'yellow'}, \"1.3 Test Point\", false);\n</code></pre> <p>We then use the vector tool <code>geo.fcProximity.bufferByDistance()</code> to buffer the point by 50 yards and add the result as a layer to the Map.  </p> <pre><code>// -------------------------------------------------------------\n//  1.4 Buffer the point by 50 yards (45.72 meters)\n// -------------------------------------------------------------\n\nvar d = 45.72;\n\nvar test_buffer = geo.fcProximity.bufferByDistance(test_point, d);\n\n// -------------------------------------------------------------\n//  1.5 Add layer to Map.\n// -------------------------------------------------------------\n\nMap.addLayer(test_buffer, {color: \"red\"}, \"1.3 Test vector buffer 50 yards\", false);\n</code></pre> <p>Notice how the buffer lines up pretty well with the goal lines that are 50 yards from center field.   </p>"},{"location":"patterns/proximity-operations/#02-proximity-with-raster","title":"02 proximity with raster","text":"<p>Now we can try to reproduce this simple buffer using raster methods. The first step involves converting the test point feature collection to a boolean image and displaying the result as a Map layer.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. Proximity with raster.\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n// 2.1 Convert test point to a Boolean image.\n// -------------------------------------------------------------\n\nvar image_boolean_test = geo.fcConvert.toBooleanImage(test_point);\n\n// -------------------------------------------------------------\n// 2.2 Display test point image. \n// -------------------------------------------------------------\n\nMap.addLayer(image_boolean_test, {min:0, max:1}, \"2.2 Test point Image\", false);\n</code></pre> <p>The next step is to use <code>geo.iFocal.iDistance()</code> to calculate the euclidean distance from all non-zero pixels in the test point image. At this point, we will use the coordinate reference system for web mercator. </p> <pre><code>// -------------------------------------------------------------\n//  2.3. Calculate euclidean distance from test point.\n// -------------------------------------------------------------\n\nvar crs = \"EPSG: 3857\";  // web mercator\n\nvar distance_image_test = geo.iFocal.iDistance(image_boolean_test, d, crs, \"euclidean\", \"pixels\");\n\n// -------------------------------------------------------------\n//  2.4. Define viz parameters\n// -------------------------------------------------------------\n\nvar viz_euc = {min:0, max: d, palette: geo.iPalettes.iDistance.inferno.reverse()};\n\n// -------------------------------------------------------------\n//  2.5. Display euclidean distance as layer on Map.\n// -------------------------------------------------------------\n\nMap.addLayer(distance_image_test,  viz_euc, \"2.5 Euc distance\", false);\n</code></pre> <p>In a last step, we can create a raster version of a buffer by applying a threshold of 50 yards to the distance image that results in a Boolean image. And then add this result to the Map as a layer.   </p> <pre><code>// -------------------------------------------------------------\n// 2.6 Threshold euclidean distance image at 50 yards. \n// -------------------------------------------------------------\n\nvar distance_image_test_threshold = distance_image_test.lte(d).selfMask();\n\n// -------------------------------------------------------------\n// 2.7 Add threshold image as layer to Map. \n// -------------------------------------------------------------\n\nMap.addLayer(distance_image_test_threshold, {min:0, max:1}, '2.7 Threshold Distance at 50 Yards', false);\n</code></pre>"},{"location":"patterns/proximity-operations/#reflection","title":"reflection","text":"<p>You just made a 50 yard buffer around a point in the center of Youngman Field with vector and raster methods. How do they differ? What do you think causes their difference?  </p>"},{"location":"patterns/proximity-operations/#03-crs-matters","title":"03 crs matters","text":"<p>Go back to section 2.3 and replace the crs variable with this:</p> <pre><code>var crs = \"EPSG: 32145\";    // VT State Plane (NAD83)\n</code></pre> <p>Then run your script and compare the results to the vector method. Why do you think crs matters for raster proximity methods? Do they also matter for vector methods?  </p>"},{"location":"patterns/proximity-operations/#vector-methods","title":"vector methods","text":""},{"location":"patterns/proximity-operations/#buffer-by-distance","title":"buffer by distance","text":"<p>This method takes a feature collection and distance (in meters) as arguments. The result is a buffer around each feature in the collection; the buffer defines the zone that is within the specified distance to each feature in the collection.  </p> <pre><code>var fc_buffer = geo.fcProximity.bufferByDistance(fc, distance);\n</code></pre>"},{"location":"patterns/proximity-operations/#raster-methods","title":"raster methods","text":""},{"location":"patterns/proximity-operations/#make-distance-raster","title":"make distance raster","text":"<p>This method makes an image that represents the distance of each pixel from all non-zero (and unmasked) pixels in the input image. </p> <pre><code>var crs = \"EPSG: 32145\";    // VT State Plane (NAD83)\n\nvar image_distance = geo.iFocal.iDistance(image_input, radius, crs, \"model\", \"units\");\n</code></pre> <p>The method takes four arguments:  </p> ARGUMENT DESCRIPTION image_input Input image to calculate distance to all non-zero but unmasked cells. Often a boolean or an object image. radius The radius of the distance kernel. This defines the size of the moving window used to calculate distance. It can not be greater than 255. crs A coordinate reference system as a string that provides the EPSG definition. \u201cmodel\u201d Defines the model of distance employed. Must be a string and one of the following: \u201ceuclidean\u201d, \u201cmanhattan\u201d, \u201cchebyshev\u201d. \u201cunits\u201d Defines the system of measurement for the distance kernel, either \u201cpixels\u201d or \u201cmeters\u201d. Must be a string. <p></p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"patterns/reclassify/","title":"reclassify raster","text":"<p>PATTERNS</p>"},{"location":"patterns/reclassify/#reclassify-raster","title":"reclassify raster","text":"<p>These methods purposefully reclassify the values in a raster. </p>"},{"location":"patterns/reclassify/#boolean-raster","title":"Boolean raster","text":"<p>This pattern asks a true or false question about each value in the input raster and returns a 1 if true and 0 if false in the corresponding pixel of the output raster.   </p> <p></p> <p> <pre><code>graph LR\n  input[image]\n  method(\".gt()\") ;\n  output[/\"image_boolean\"/]  ;\n  arg1[\"number\"]  ;\n\n  input --&gt; method\n  method --&gt; output\n  arg1 --o method\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg1 arg;</code></pre> <p></p> <pre><code>var image_boolean = image.gt(number);  </code></pre> <p>The table below lists some of the common methods to ask true or false questions about a raster. Each takes a number as an argument. Some technical folks will use the verb threshold to describe methods that use greater than or less than methods to produce boolean rasters.  </p> <p> METHOD DESCRIPTION <code>.eq()</code>, <code>.neq()</code> Equal to, not equal to <code>.gt()</code> <code>.gte()</code> Greater than, greater than or equal to <code>.lt()</code> <code>.lte()</code> Less than, less than or equal to <p></p>"},{"location":"patterns/reclassify/#reclassify-by-equal-intervals","title":"Reclassify by equal intervals","text":"<p>This method assigns raster values into equal interval classes. The method divides each value in a raster by the interval number and then rounds down to the nearest integer (finds the floor). The integers in the output are ordinal but arbitrary class numbers. </p> <p></p> <p> <pre><code>graph LR\n  method(\"geo.iReclass.equalInterval()\") ;\n  output[/\"image_reclassified\"/]  ;\n  arg1[\"image\"]  ;\n  arg2[\"interval\"]  ;\n\n  method --&gt; output\n  arg1 --o method\n  arg2 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class method op;\n  class output in-out;\n  class arg1 arg;\n  class arg2 arg;</code></pre> <p></p> <pre><code>var image_reclassified = geo.iReclass.equalInterval(image, interval);\n</code></pre>"},{"location":"patterns/reclassify/#remap-old-values-to-new-values","title":"Remap old values to new values","text":"<p>This method assigns integer values in the input raster to new integer values in the output raster based on transition rules defined by two lists. The first list defines the set of original values in the input raster. The second list defines the set of new values to be stored in the output raster. The order of the two lists determines the transition. The two lists must be the same length (have the same number of values).</p> <p></p> <p> <pre><code>graph LR\n  input[\"image\"] ;\n  method(\".remap()\") ;\n  output[/\"image_remapped\"/]  ;\n  arg1[\"[original values]\"]  ;\n  arg2[\"[new values]\"]  ;\n\n  input --&gt; method  \n  method --&gt; output\n  arg1 --o method\n  arg2 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out;\n  class method op;\n  class output in-out;\n  class arg1 arg;\n  class arg2 arg;</code></pre> <p></p> <pre><code>var image_remapped = image.remap(\n[0,1,2,3,4],            // Original values\n[1,0,0,0,1]             // New values \n)                       // Lengths of two lists must be equal.\n;\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/scalar-operations/","title":"scalar operations","text":"<p>PATTERNS</p>"},{"location":"patterns/scalar-operations/#scalar-operations","title":"scalar operations","text":"<p>Uniformly change the values of all data in a raster object by adding, subtracting, multiplying, or dividing the raster by a constant.   </p>"},{"location":"patterns/scalar-operations/#add","title":"add","text":"<p>Add each pixel value by constant. For example, pattern below adds by one.  </p> <pre><code>var image_add_constant = image.add(1)\n</code></pre>"},{"location":"patterns/scalar-operations/#subtract","title":"subtract","text":"<p>Subtract each pixel value by constant. For example, pattern below subtracts by 1.</p> <pre><code>var image_subtract_constant = image.subtract(1)\n</code></pre>"},{"location":"patterns/scalar-operations/#multiply","title":"multiply","text":"<p>Multiply each pixel value by constant. For example, pattern below multiplies by 2.</p> <pre><code>var image_multiply_constant = image.multiply(2)\n</code></pre>"},{"location":"patterns/scalar-operations/#divide","title":"divide","text":"<p>Divide each pixel value by constant. For example, pattern below divides by 2.</p> <pre><code>var image_divide_constant = image.divide(2)\n</code></pre>"},{"location":"patterns/scalar-operations/#problem-types","title":"problem types","text":"<p>Here are a few types of problems that can be solved with scalar operations.  </p>"},{"location":"patterns/scalar-operations/#change-value-units","title":"change value units","text":"<p>A common example is when you need to change the units of your data. For example, to change elevation data from centimeters to meters you divide all elevation values by the number 100 (scalar).   </p> <p> <pre><code>graph LR\n  input[\"image_cm\"] ;\n  method(\".divide()\") ;\n  output[/\"image_m\"/]  ;\n  arg1[\"100\"]  ;\n\n\n  input --&gt; method  \n  method --&gt; output\n  arg1 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out;\n  class method op;\n  class output in-out;\n  class arg1 arg;</code></pre> <p></p> <pre><code>var image_m = image_cm.divide(100);\n</code></pre> <p>The table below lists some common types of unit conversions and their pattern context.</p> CONTEXT INPUT UNITS OUTPUT UNITS METHOD TERRAIN cm m <code>.divide(100)</code> TERRAIN ft m <code>.multiply(3.28084)</code> SLOPE degrees percent <code>.divide(180).multiply(Math.PI).tan().multiply(100)</code>"},{"location":"patterns/scalar-operations/#vertical-exaggeration","title":"vertical exaggeration","text":"<p>Another common example is when you want to apply vertical exaggeration to a terrain operation by multiplying the elevation values by a constant, usually called the z-factor. For example, by multiplying elevation by 2, you will exaggerate the terrain, making every location appear twice as high as it \u2018really\u2019 is. It is often helpful to exaggerate terrain when visualizing micro-topography at large scales or macro-topography at small scales. </p> <p> <pre><code>graph LR\n  input[\"image_m\"] ;\n  method(\".multiply()\") ;\n  output[/\"image_m_ve_2\"/]  ;\n  arg1[\"2\"]  ;\n\n\n  input --&gt; method  \n  method --&gt; output\n  arg1 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out;\n  class method op;\n  class output in-out;\n  class arg1 arg;</code></pre> <p></p> <pre><code>var image_m_ve_2 = image_m.multiply(2);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/terrain/","title":"terrain","text":"<p>PATTERNS</p>"},{"location":"patterns/terrain/#terrain","title":"terrain","text":"<p>These methods derive topographic attributes of terrain from raster elevation data. Most terrain operations characterize attributes of a surface with focal (neighborhood) operations.</p> <p>Before we get too deep into these methods, it is helpful to understand some general concepts about terrain analysis with raster data models.  </p>"},{"location":"patterns/terrain/#change-in-elevation","title":"change in elevation","text":""},{"location":"patterns/terrain/#concepts","title":"concepts","text":"<p>Slope describes how the vertical dimension of space changes with respect to the  horizontal dimension. Many of us first learn about slope as \u201crise over run\u201d which can be expressed as a percentage. Most GIS will compute slope as a percentage or in degrees. Earth Engine calculates slope in degrees and then, if you would like to find the percent slope for your application, it leaves it to you to convert from degrees to percentage with scalar operations.  </p> <p></p> <p>A raster model will define \u201crun\u201d based on distance between the centers of cells. As a result, the distance between two adjacent cells that share a side will be the same as the length of a pixel side, or the scale of the raster.   </p> <p></p> <p>In raster analysis, a common slope computation employs a neighborhood operation with a kernel that resembles a \u201cplus\u201d sign. The crosspiece of the plus computes the difference in z-values (elevation) for the x dimension, while the post of the plus computes the difference in z-values for the y dimension. The change in elevation with respect to change in distance can be found by dividing by the distance across the crosspiece or post (which will both be double the cell size). The degree of slope is then found through some trigonometry.</p> <p></p> <p>Because the slope calculation directly compares changes in elevation with changes in distance, the units of the z-values must be the same as the units of the xy values. In Earth Engine, the xy units will generally be meters. Therefore, accurate slope computations require elevation data in meters.   </p>"},{"location":"patterns/terrain/#decision-flow","title":"decision flow","text":"<p>The workflow for slope analysis will often depend on the data you are using and your purpose. I tend to think through some version of the flowchart depicted below. The </p> <p> <pre><code>graph TD\n\n  q1&gt;\"Do z-units = xy units?\"] ;\n  q2&gt;\"Is your purpose to visualize slope shading?\"] ;\n  q3&gt;\"Does your application require slope in percent?\"] ;  \n  step01(\"Change units \\n\\n APPLY SCALAR\") ;\n  step02(\"Consider changing z-factor \\n\\n APPLY SCALAR\") ;\n  step03(\"Derive slope\") ;\n  step04(\"Convert slope units\") ;\n  step05(&amp;#128526);\n\n  q1-- NO --&gt;step01 --&gt; q2\n  q1-- YES --&gt;q2\n  q2-- YES --&gt;step02\n  q2-- NO --&gt;step03\n  step02 --&gt; step03\n  step03 --&gt; q3\n  q3-- YES --&gt; step04  \n  q3 -- NO --&gt; step05\n  step04 --&gt; step05\n\n\n\n  classDef task fill:#DDE6C3,stroke-width:0px,color:#000000;\n  classDef check fill:#C3D1E6, stroke-width:0px,color:#000000;  \n  classDef done fill:#FFFFFF, stroke-width:0px,color:#000000;  \n\n\n  class q1 check; \n  class q2 check; \n  class q3 check; \n  class step01 task;\n  class step02 task;\n  class step03 task;\n  class step04 task;\n  class step05 done; \n</code></pre> <p></p>"},{"location":"patterns/terrain/#slope-method","title":"slope method","text":"<p>Derive slope of a surface in degrees from elevation in meters. </p> <p>Call the <code>ee.Terrain.slope</code> method with the elevation data (with z-units meters) as the argument.  </p> <p> <pre><code>graph LR\n  step02(\"ee.Terrain.slope()\") ;\n  step03[/\"image_slope\"/]  ;\n  arg01[\"image_elevation_meters\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; </code></pre> <p></p> <pre><code>var image_slope = ee.Terrain.slope(image_elevation_meters);\n</code></pre>"},{"location":"patterns/terrain/#direction-of-change","title":"direction of change","text":""},{"location":"patterns/terrain/#concepts_1","title":"concepts","text":"<p>Closely related to slope, aspect reports the direction of change, or the steepest downhill direction of a pixel. </p> <p>Like slope, aspect is derived with a kernel that computes change in elevation in both x- and y- dimensions, but rather than reporting the steepness of the slope, aspect reports the direction, generally expressed as an azimuthal angle from North 0.  </p> <p> </p>"},{"location":"patterns/terrain/#aspect-method","title":"aspect method","text":"<p>In Earth Engine, the aspect method closely resembles the pattern for slope. </p> <p> <pre><code>graph LR\n  step02(\"ee.Terrain.aspect()\") ;\n  step03[/\"image_aspect\"/]  ;\n  arg01[\"image_elevation_meters\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; </code></pre> <p></p> <pre><code>var image_aspect = ee.Terrain.aspect(image_elevation_meters);\n</code></pre> <p>Because the method directly compares changes in z-values to changes in x- and y- values, the units for elevation must match the units for x- and y- dimensions. Practically, this means the elevation units must be meters.  </p> <p>The output aspect image reports the direction of slope in degrees. Completely flat pixels (with no slope direction) receive the value 0. It is often good practice to mask these pixels so as not to confuse them with north-facing locations.  </p>"},{"location":"patterns/terrain/#analytic-hillshading","title":"analytic hillshading","text":""},{"location":"patterns/terrain/#concepts_2","title":"concepts","text":"<p>Shaded relief is a method to visualize a three-dimensional surface by creating the illusion of highlights and shadows thrown by sunlight on a terrain. Before computers, cartographers created shaded relief by hand (manual shaded relief) in a workflow that blended science and art. Most GIS software now provide a method to automate shaded relief, called analytic hillshading, that simplifies the shading illusion. </p> <p>The method assumes that the illumination source (sun) is an infinite distance from Earth. As a result, the illumination rays travel and reach the Earth\u2019s surface in parallel.  </p> <p></p> <p>The angle of the illumination rays depends on the sun\u2019s position, which is determined by two coordinates. The solar azimuth angle defines the sun\u2019s position on the horizon in degrees from North. It is often most effective to put the illumination source above the northwest horizon, even though in the northern hemisphere it would be unusual to find the sun in this part of the sky. An interesting fact about the illusion of shaded relief is that placing the illumination source in the southern sky will make the landscape appear inverted: mountain ridges look like valleys and creeks look like ridge lines. Because of this, many analytic hillshade tools in GIS will use 315 as the starting solar azimuth angle. You can then adjust this \u00b1 30 degrees depending on the orientation of ridges and valleys in the area of interest, while taking care not to invert the landscape by pushing the sun too far.  </p> <p>The second solar coordinate the defines the sun\u2019s position above the horizon, or how high the sun hangs in the sky. Many GIS call this the zenith angle, but in Earth Engine it is called elevation. If the sun is directly overhead, the zenith angle is 90 and the sun approaches 0 as it nears the horizon. By default, many GIS go with the Goldilocks solution and set the zenith angle at 45. It is often good to start here and then adjust based on your terrain. Lowering the zenith angle can be helpful on flat terrain, while raising the angle can be helpful in more rugged landscapes.       </p> <p></p> <p>The brightness of the reflected ray is determined by the local incidence angle from the surface normal (perpendicular to the surface). When the incidence angle is near 0, the rays directly strike the surface and reflect at their brightest power. Because most GIS will store the output of the analytic hillshade method as a byte data type (0-255), the brightest pixels will have the data value 255. In a grayscale palette, this value will be displayed white. As the incidence angle increases, the rays strike the surface obliquely, the brightness values decrease, and the display values change from white to gray. As the angle exceeds 90, the brightness values change from gray to black.</p> <p> </p>"},{"location":"patterns/terrain/#hillshade-operation","title":"hillshade operation","text":"<p>In Earth Engine, the <code>ee.Terrain.hillshade()</code> method takes three arguments to output a hillshade image.  </p> <p> <pre><code>graph LR\n  step02(\"ee.Terrain.hillshade()\") ; \n  step03[/\"image_hs\"/]  ;\n  arg01[\"image_elevation_meters\"] ;\n  arg02[\"azimuth angle\"] ;\n  arg03[\"zenith angle\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n  arg02 --o step02\n  arg03 --o step02\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg;\n  class arg02 arg; \n  class arg03 arg; </code></pre> <p></p> <pre><code>var image_hs = ee.Terrain.hillshade(image_elevation_meters, azimuth, zenith);\n</code></pre>"},{"location":"patterns/terrain/#deviation-from-mean-elevation","title":"deviation from mean elevation","text":"<p>Description forthcoming </p> <pre><code>var image_dme = geo.iTerrain.devFromMeanElev(image, 10);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/vector-analysis/","title":"vector analysis","text":"<p>PATTERNS</p>"},{"location":"patterns/vector-analysis/#vector-analysis","title":"vector analysis","text":"<p>forthcoming</p>"},{"location":"patterns/vector-analysis/#transform-geometries","title":"transform geometries","text":"<p>These methods create new geometries based on the input geometries of feature collections.  </p> <p>More to come.</p>"},{"location":"patterns/vector-analysis/#bounding-box","title":"bounding box","text":"<pre><code>var fc_bounds = geo.fcGeometry.boundingBox(fc);\n\nMap.addLayer(fc_bounds, {color: 'cyan'}, \"Bounding box\", false);\n</code></pre>"},{"location":"patterns/vector-analysis/#centroid","title":"centroid","text":"<pre><code>var fc_centroid = geo.fcGeometry.centroidPoint(fc);\n\nMap.addLayer(fc_centroid, {color: 'yellow'}, \"Centroid point\", false);\n</code></pre>"},{"location":"patterns/vector-analysis/#convex-hull","title":"convex hull","text":"<pre><code>var fc_convex_hull = geo.fcGeometry.convexHullPolygon(fc);\n\nMap.addLayer(fc_convex_hull, {color: 'magenta'}, \"Convex hull\", false);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/vector-overlay/","title":"vector overlay operations","text":"<p>PATTERNS </p>"},{"location":"patterns/vector-overlay/#vector-overlay-operations","title":"vector overlay operations","text":"<p>Vector overlay operations compare locations between two vector layers. In Earth Engine, the vector layers are generally features in a feature collection.  </p> <p>more soon </p>"},{"location":"patterns/vector-overlay/#clip-by-region","title":"clip by region","text":"<p><code>geo.fcOverlay.clipByRegion()</code> is a knife method that takes two arguments. </p> ARGUMENT DESCRIPTION fc_dough A vector dataset (feature collection) with features that you want to cut. fc_cutter A vector dataset (feature collection) with features that you want to use as the knife to cut the dough. <p>The output is a feature collection that retains that attributes but alters the geometry of the dough.  </p> <pre><code>var fc_clip = geo.fcOverlay.clipByRegion(fc_dough, fc_cutter);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/zonal-operations/","title":"zonal overlay operations","text":"<p>PATTERNS</p>"},{"location":"patterns/zonal-operations/#zonal-operations","title":"zonal operations","text":"<p>Zonal operations analyze pixel values in one layer based zones (regions) defined by another layer. In Earth Engine, the zones are generally defined by features in a feature collection.  </p> <p>more soon </p>"},{"location":"patterns/zonal-operations/#zonal-area","title":"zonal area","text":"<p>These methods use the zones defined by the geometry of a feature collection to compute the area of each class in a nominal or boolean layer.  </p>"},{"location":"patterns/zonal-operations/#area-of-classes","title":"area of classes","text":"<p>This method returns a dictionary that reports the total area (in square meters) of each class (integer value) in the input raster.  </p> <pre><code>var area_of_classes = geo.iZonal.areaClasses(image, scale, region, \"band_name\");\n\nprint(\n\"Area (square meters)\",\narea_of_classes\n);\n</code></pre> <p>The table below describes the arguments.  </p> ARGUMENT DESCRIPTION image The boolean or nominal (class) image to compute the area for each unique pixel value. scale The pixel scale for analysis to troubleshoot TIME OUT errors. It can be helpful to first run at a coarse resolution and then increase resolution (make number smaller) as appropriate. region Feature collection with one or more features that define the area of analysis or study region. \u201cband_name\u201d The band name in the image with the integer values that identify the classes to compute the area of."},{"location":"patterns/zonal-operations/#area-of-classes-as-percent-of-region","title":"area of classes as percent of region","text":"<p>This method returns a dictionary that reports the total area of each class (integer value) in the input raster as a percent of the region. It takes the output from <code>.areaClasses()</code> (above) as the input and returns a dictionary. </p> <pre><code>var class_percent_of_region = geo.iZonal.classPercentRegion(area_of_classes);\n\nprint(\n\"Area (percent of region)\",\narea_of_classes\n)\n;\n</code></pre>"},{"location":"patterns/zonal-operations/#complete-pattern","title":"complete pattern","text":"<p>Here is the complete pattern for calculating the area of raster classes and their percent area of a region.  </p> <pre><code>var area_of_classes = geo.iZonal.areaClasses(image, scale, region, \"band_name\");\n\nprint(\n\"Area (square meters)\",\narea_of_classes\n);\n\nvar class_percent_of_region = geo.iZonal.classPercentRegion(area_of_classes);\n\nprint(\n\"Area (percent of region)\",\nclass_percent_of_region\n)\n;\n</code></pre>"},{"location":"patterns/zonal-operations/#zonal-statistics","title":"zonal statistics","text":"<p>This method calculates a statistic of image values within a zone of analysis defined by one or more features in a feature collection. The output of the method is a feature collection with a new column that contains the statistic.  </p> <p>more soon </p> <pre><code>var fc_zonal_stat = geo.iZonal.zonalStats(dough, cutter, \"statistic\", scale);\n</code></pre> <p>The method takes four arguments that are defined in the table below.  </p> ARGUMENTS DESCRIPTION dough The image with pixel values to be analyzed. cutter The feature collection with one or more features that define the zones of analysis. \u201cstatistic\u201d The statistic to calculate within each zone of analysis. Must be a string from these options: \u201csum\u201d, \u201cmax\u201d, \u201cmin\u201d, \u201cmean\u201d, \u201ccount\u201d, \u201cvariety\u201d (\u201ccount\u201d reports the number of pixels, while \u201cvariety\u201d reports the number of unique pixel values). scale The scale of analysis. When you encounter time out errors, you can try to resolve by increasing the scale of analysis. <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-01/","title":"P1. Memory under cover","text":"<p>PRACTICE 1</p>"},{"location":"problems/practice-01/#memory-under-cover","title":"Memory under cover","text":""},{"location":"problems/practice-01/#goal","title":"goal","text":"<p>Your goal is to import a digital elevation model (DEM), make a Map with the five layers shown in the app below, and then use these layers to interpret the four POI.</p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-01/#starter-script","title":"starter script","text":"<pre><code>// -------------------------------------------------------------\n//  Access image from this cloud address:\n//  \"projects/ee-patterns/assets/p01/chipmanHill_2023_35cm_DEMHF\"\n// -------------------------------------------------------------\n\nvar image ;\n\n\n// -------------------------------------------------------------\n//  Customize Map. \n// -------------------------------------------------------------\n\n// Set map center and zoom level.\n\n\n//  Set basemap style to hybrid.\n\n\n// -------------------------------------------------------------\n//  Display image as a map layer;\n//  Stretch layer display values over image data range.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Multiply the elevation values by 2 (apply a scalar operation)\n//  and then derive slope of this surface.\n// -------------------------------------------------------------\n\nvar image_slope ;\n\n// -------------------------------------------------------------\n//  Display slope image as a map layer;\n//  Stretch layer display values over image data range.\n//  Display so that \"steeper is darker\".\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Multiply the elevation values by 2 (apply a scalar operation)\n//  and then calculate the hillshade of this surface. \n// -------------------------------------------------------------\n\nvar image_hs ;\n\n// -------------------------------------------------------------\n//  Using the original elevation surface (without a scalar applied),\n//  calculate the deviation from mean elevation;\n//  Use 10 as the distance argument.\n//  Try to display the layer with this palette: ['blue', 'white', 'red']\n// -------------------------------------------------------------\n\nvar image_dme ;\n\n\n// -------------------------------------------------------------\n//  PRACTICE CHECKS\n// -------------------------------------------------------------\n\n//  I. QUANTITATIVE \n\nprint(\"QUANTITATIVE CHECKS:\");\n\n//  Import check module for tutorial 1.\n//  Uncomment the line below.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p01.js\");\n\n//  Uncomment the three lines below, run script, and look at the results in Console. \n\n// check.checkPoint(\"CP1:\", image_slope);\n// check.checkPoint(\"CP2:\", image_hs);\n// check.checkPoint(\"CP3:\", image_dme);\n\n//  II. QUALITATIVE  \n\n//  Use zoom to inspect locations marked A, B, C, D.\n//  For each letter, please write down:\n\n//    1. What do you think the linear feature marked by the letter \"is\"?\n//    2. Why?\n\n//  When you have completed this practice problem, please take the short quiz on Canvas where you will report your results. \n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-02/","title":"P2. Ice age bathtub","text":"<p>PRACTICE 2</p>"},{"location":"problems/practice-02/#ice-age-bathtub","title":"Ice age bathtub","text":""},{"location":"problems/practice-02/#goal","title":"goal","text":"<p>Your goal is to import a digital elevation model (DEM) and make a Map with the four layers shown in the app below. When you have finished solving the problem (or when the clock is approaching 5pm on Friday), please work through the check-up on Canvas as best you can. </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-02/#starter-script","title":"starter script","text":"<pre><code>var geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.\nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module.  \n\n// -------------------------------------------------------------------------------\n//  Gather image from \"projects/ee-patterns/assets/p02/NOAA-CoNED-SOCAL\".\n//  Print a histogram - do you see land vs ocean floor in the histogram?\n// -------------------------------------------------------------------------------\n\nvar image = ee.Image(\"projects/ee-patterns/assets/p02/NOAA-CoNED-SOCAL\");\n\nprint(\"Image\", image);\n\n\n// -------------------------------------------------------------------------------\n//  Area of interest for practice problem.\n// -------------------------------------------------------------------------------\n\nvar aoi = image.geometry();\n\n\n// Center map on aoi at zoom level 9 and set base layer to hybrid.\n\n\n\n\n// -------------------------------------------------------------------------------\n//  Apply a vertical exageration (z-factor) of 2 to elevation data for hillshade. \n//  Make a hillshade from this image and display the hillshade image as layer on Map.\n// -------------------------------------------------------------------------------\n\nvar image_ve ;\n\nvar image_hs ;\n\n\n// -------------------------------------------------------------------------------\n//  Separate the original elevation image (without vertical exageration) into two different images:\n\n//  (1) land elevations\n//  (2) ocean floor elevations (bathymetry)\n\n//  Each image should only store land or bathymetry elevation values, respectively.\n//  All other values should be masked.\n// -------------------------------------------------------------------------------\n\nvar image_land ;\n\nvar image_bathy ;\n\n// -------------------------------------------------------------------------------\n//  Reclassify the bathymetry image at 100 meter intervals. \n//  Display the reclassified image as layer on Map with 0.5 opacity.\n//  To improve contrast, set max of viz dictionary such that all locations less than -2000 m (or class 20) are the darkest blue in palette.\n//  Use this palette: geo.iPalettes.iBathy.eleven\n// -------------------------------------------------------------------------------\n\n\n\nvar image_bathy_reclass ;\n\n\n\n// -------------------------------------------------------------------------------\n//  Define the Pleistocene shoreline as 130 meters lower than today's shoreline.\n//  Make a boolean image that shows all land above ocean in Pleistocene.\n//  Display boolean image as layer on Map with all non-land masked.\n//  Set opacity of layer at 0.5.\n// -------------------------------------------------------------------------------\n\nvar image_pleistocene ;\n\n\n// -------------------------------------------------------------------------------\n//  Reclassify the land image at equal 100 meter intervals. \n//  Display the reclassified image as layer on Map with 0.5 opacity.\n//  Use this palette: geo.iPalettes.iHypso.bartholomew\n//  Set opacity of layer at 0.5.\n// -------------------------------------------------------------------------------\n\nvar image_land_reclass ;\n\n\n\n\n// -------------------------------------------------------------\n//  PRACTICE CHECKS\n// -------------------------------------------------------------\n\n//  I. QUANTITATIVE \n\nprint(\"QUANTITATIVE CHECKS:\");\n\n//  Import check module for tutorial 1.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p02.js\");\n\n//  Uncomment the five lines below, run script, and look at the results in Console. \n\n// check.checkPoint(\"CP1:\", image_hs);\n// check.checkPoint(\"CP2:\", image_land);\n// check.checkPoint(\"CP3:\", image_bathy);\n// check.checkPoint(\"CP4:\", image_pleistocene);\n// check.checkPoint(\"CP5:\", image_bathy_reclass);\n</code></pre>"},{"location":"problems/practice-02/#advice-on-printing-histograms","title":"advice on printing histograms","text":"<p>This is a BIG dataset. Whenever you print histogram or min-max values, set the scale to 30 and the extent to aoi.  </p> <pre><code>print(\"Image histogram\", geo.iCart.iHistogram(image, 30, aoi));\n</code></pre> <pre><code>print(\"Min &amp; max value of image\", geo.iCart.iMinMax(image, 30, aoi));\n</code></pre>"},{"location":"problems/practice-02/#check-definitions","title":"check definitions","text":"VARIABLE DESCRIPTION image_hs Hillshade image from elevation data with vertical exaggeration of 2, azimuth 315, and zenith 35. image_land Land elevations only. All sea floor elevations should be masked. image_bathy Sea floor elevations only. All land elevations should be masked. Include 0 elevation as sea floor. image_pleistocene Flexible depending on how you solve this. It could represent sea floor elevations when the sea-level was 130 meters lower than today, or you could skip this step and just define the boolean image. Many different answers are potentially fine for this one and we will discuss in class on Monday. image_bathy_reclass Modern sea floor (bathy) elevations reclassified into equal interval classes."},{"location":"problems/practice-02/#data-sources","title":"data sources","text":"<p>CoNED </p> <p>GEE Awesome Community Datasets </p> <p>CoNED Data Archive </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-03/","title":"P3. Parent materials of soils","text":"<p>PRACTICE 3</p>"},{"location":"problems/practice-03/#parent-materials-of-soils","title":"Parent materials of soils","text":""},{"location":"problems/practice-03/#purpose","title":"purpose","text":"<p>Your goal is to make a map that could help town planners in Addison County compare information from the Addison County Soil Survey (1971) to property parcels in their town.  </p> <p>Practically, your workflow will include the following patterns:  </p> <ul> <li>gather and inspect vector data  </li> <li>filter feature collections  </li> <li>convert vector to raster  </li> <li>mask raster data </li> <li>display layer of nominal classes with unique colors </li> <li>explain nominal class symbology    </li> <li>filter and flatten an image collection  </li> <li>make terrain layers </li> <li>paint strokes    </li> </ul> <p>When you solve the problem, you should have a workflow that uses the town of Middlebury as the test subject to produce a map with the layers shown in the app below. Ideally, you will write the script so that you can very easily shift the map to any other town in Addison County, Vermont.   </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-03/#data-sources","title":"data sources","text":"<p>We will use a number of datasets that are available through the cloud, either through the Earth Engine Data Catalog or assets that I maintain for Vermont geography.  </p> <p> DATA DESCRIPTIONS US Counties sourcebackground VT Towns source VT Parcels sourcebackground VT Soils sourcebackgroundreport DEM 1m sourcebackground <p></p>"},{"location":"problems/practice-03/#starter-script","title":"starter script","text":"<pre><code>var geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n\n// -------------------------------------------------------------\n//  DATA SOURCES \n// ------------------------------------------------------------- \n\nvar fc_address_county = \"TIGER/2018/Counties\";\nvar fc_address_town = \"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\";\nvar fc_address_parcel = \"projects/vt-conservation/assets/state/FS_VCGI_OPENDATA_Cadastral_VTPARCELS_poly_standardized_parcels_SP_v1\";\nvar fc_address_soils = \"projects/conservation-atlas/assets/soils/VT_Data_NRCS_Soil_Survey_Units\";\nvar ic_address_dem = \"USGS/3DEP/1m\"; var palette_soils = geo.iPalettes.iSoils.parent_materials_addison_county;\nvar class_labels_soils = geo.iPalettes.iSoils.parent_materials_addison_county_labels;\n\nprint(\"SOILS Palette and Class labels\", palette_soils, class_labels_soils);\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. GATHER HUMAN GEOGRAPHY\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Make Addison County layer\n// -------------------------------------------------------------\n\nvar fc_county ;\n\n// -------------------------------------------------------------\n//  1.2 Make study town (Middlebury) layer\n// -------------------------------------------------------------\n\nvar fc_town ;\n\n// -------------------------------------------------------------\n//  1.3 Center map on study town\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  1.4 Make parcels in study town layer\n// -------------------------------------------------------------\n\nvar fc_parcels ;\n\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. GATHER SOILS DATA AND FILTER FOR ADDISON COUNTY \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  2.1 Gather soils data\n// -------------------------------------------------------------\n\n\nvar fc_soils ;\n\n\n\n// -------------------------------------------------------------\n//  2.2 Filter for soils that overlap Addison County\n// ------------------------------------------------------------- \n\nvar fc_filter_bounds_soils ;\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  3. MAKE PARENT MATERIAL IMAGE FOR STUDY TOWN. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  3.1 Make nominal image of soil parent material. \n// -------------------------------------------------------------\n\nvar image_nominal_soils ;\n\n// -------------------------------------------------------------\n//  3.2 Mask by Addison County.\n// -------------------------------------------------------------\n\nvar image_with_mask_soils ;\n\n// -------------------------------------------------------------\n//  3.3 Display masked soils image as layer. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.4 Add legend to bottom-left of Map. \n// -------------------------------------------------------------\n\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  4. GATHER DEM \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  4.1 Construct image collection. \n// -------------------------------------------------------------\n\nvar ic_dem ;\n\n// -------------------------------------------------------------\n//  4.2 Filter for images that overlap Addison County.\n// -------------------------------------------------------------\n\nvar ic_filtered_dem_county ;\n\n// -------------------------------------------------------------\n//  4.3 Mosaic filtered image collection to image. \n// -------------------------------------------------------------\n\nvar ic_dem_mosaic ;\n\n\n// -------------------------------------------------------------\n//  4.2 Mask mosaic image by Addison County. \n// -------------------------------------------------------------\n\nvar image_with_mask_dem ;\n\n// -------------------------------------------------------------\n//  4.3 Make hillshade from masked image and display as layer with 0.5 opacity.\n//  No vertical exaggeration; azimuth 315; zenith 35.\n// -------------------------------------------------------------\n\nvar hs  ;\n\n// -------------------------------------------------------------\n//  4.6 Make slope from masked image and display as layer with 0.5 opacity.\n// -------------------------------------------------------------\n\nvar slope ;\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  5. PAINT STROKES\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  5.1 Make strokes for parcels (\"white\" and 0.5 weight) and add as layer.\n// -------------------------------------------------------------\n\nvar strokes_parcels ;\n\n// -------------------------------------------------------------\n//  5.2 Make strokes for town (\"white\" and 4 weight) and add as layer.\n// -------------------------------------------------------------\n\nvar strokes_town ;\n\n// -------------------------------------------------------------\n//  PRACTICE CHECKS\n// -------------------------------------------------------------\n\nprint(\"CHECKS:\");\n\n//  Import check module for tutorial 1.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p03.js\");\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n//  PLEASE DO THE FOLLOWING: \n\n// 1. Uncomment all of the check statements below.\n// 2. Replace 'result_#p#' with the name of the data object that you used to map as a layer in each section.\n// 3. Run the script.\n// 4. Use the results printed to Console in the Check Up that is due Friday 5pm. \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n// check.checkCollection(\"Check 1.1\", result_1p1);\n// check.checkCollection(\"Check 1.2\", result_1p2);\n// check.checkCollection(\"Check 1.4\", result_1p4);\n// check.checkCollection(\"Check 2.1\", result_2p1);\n// check.checkCollection(\"Check 2.2\", result_2p2);\n\n// check.checkPoint(\"Check 3.3\", result_3p3);\n// check.checkPoint(\"Check 4.5\", result_4p5);\n// check.checkPoint(\"Check 4.6\", result_4p6);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-04/","title":"P4. Forest blocks and habitat connectors","text":"<p>PRACTICE 4 </p>"},{"location":"problems/practice-04/#forest-blocks-and-habitat-connectors","title":"Forest blocks and habitat connectors","text":""},{"location":"problems/practice-04/#goal","title":"goal","text":"<p>This problem continues working on our map of forest habitat blocks for the town of Middlebury, Vt.  </p> <p>Your practical goal is to:</p> <ol> <li>include rare natural communities in your forest habitat block layer; </li> <li>incorporate lidar-informed flood inundation data to map habitat connectors;</li> <li>distinguish habitat blocks and connectors as separate classes in a single raster layer.</li> </ol> <p>Your workflow should reproduce all the layers shown in the app below.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-04/#data-sources","title":"data sources","text":"<p>This problem uses several datasets from the tutorial problem. In addition, we will use two new datasets described in the table below.  </p> <p> ASSET NAME DESCRIPTION FORMAT RESOLUTION LakeChamplainBasin Lake Champlain Basin Lidar-Informed Flood Inundation Layer Image 70 cm SignificantNaturalCommunities VT Significant Natural Communities FC <p></p>"},{"location":"problems/practice-04/#starter-script","title":"starter script","text":""},{"location":"problems/practice-04/#00-getting-started","title":"00 Getting started","text":"<p>Begin with a header and importing the module. The address variables will give you access to all the data that you need for this problem.  </p> <pre><code>/*     \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     \n    TITLE:  \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// Feature collections\n\nvar vt_town_address = \"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\";\nvar rare_address = \"projects/conservation-atlas/assets/rarity/Significant_Natural_Communities\";\nvar large_blocks_middlebury = \"projects/ee-patterns/assets/vt-conservation/t04_habitat_blocks\";\n\n// Images\n\nvar valley_bottom_address = \"projects/vt-conservation/assets/champlain_basin/LakeChamplainBasin\";\nvar imp_address = \"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Impervious\";\n</code></pre>"},{"location":"problems/practice-04/#01-define-study-region","title":"01 Define study region","text":"<p>This section is pretty similar to the tutorial, so you should be able to recycle that code here.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. Define study region.\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Define study town (Middlebury)\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.2 Convert study town into boolean (to use as mask later)\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.3 Define aoi as study town and towns that overlap (share boundary) with study town.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.4 Convert aoi into a boolean (to use as mask later).\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.5 Center map on study town and set basemap to hybrid. \n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-04/#02-include-rarity-in-blocks","title":"02 Include rarity in blocks","text":"<p>Often, rare elements on the landscape are small in size. So by selecting habitat blocks that are greater than 100 acres, we may show bias and under-represent rare elements of the landscape in our conservation plan, essentially making poverty traps for rare but significant natural communities. </p> <p>To try to right this wrong, this chunk of the problem gathers data on Significant Natural Communities collected through Vermont\u2019s Natural Heritage program and includes these locations in our habitat blocks layer, even if they are relatively small.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. Make blocks inclusive of rare communities.  \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  2.1 Gather habitat blocks cloud asset that overlap aoi. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.2 Convert 2.1 to a boolean image.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.3 Gather rare natural communities that overlap aoi.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  2.4 Make boolean image of rare natural communities that overlap aoi.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.5 Make a boolean image of locations that are either blocks or rare natural communities.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-04/#03-classify-habitat-blocks-versus-habitat-connectors","title":"03 Classify habitat blocks versus habitat connectors","text":"<p>If you look at the habitat block layers we have mapped thus far, you will notice that many blocks have both low connectivity and low circuitry. In this step, we aim to improve both conditions by modeling habitat connectors.  </p> <p>Your goal in this set of tasks is to use the Lidar-Informed Flood Inundation layer to represent valley bottoms. Your final layer should bring in valley bottom locations so that any valley bottom that does not overlap a habitat block is classed with the value 2. This will make a layer with three classes as shown in the table below.  </p> VALUE CLASS NAME 0 Neither a block or valley bottom. 1 Habitat blocks. 2 Habitat connectors (valley bottoms that are not habitat blocks or not impervious surfaces). <p>When you have made this layer, it is a good time to export the image as a cloud asset to use in the final steps of the problem.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  3. Classify habitat blocks versus habitat connectors.  \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  3.1 Gather valley bottom, make it boolean (anything not 0 is true), and mask for aoi.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  3.2 Erase all impervious land from valley bottoms.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.3 Distinguish valley bottoms without impervious that do not intersect habitat blocks as a new habitat class.\n// Your goal here is to make a single layer where the value 1 represents habitat blocks and 2 represents connectors that are not also blocks nor are they an impervious surface. \n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  3.4 Export 3.3 image to asset and display asset as Map layer.   \n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-04/#04-cartography","title":"04 Cartography","text":"<p>Finish your workflow with a little cartography to provide support to a map reader.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  4. A little cartography \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  4.1 Add a legend for the habitat block/connector layer.  \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  4.2 Add layer of outlines for study town.  \n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-04/#05-checks","title":"05 Checks","text":"<pre><code>// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n//  PRACTICE CHECKS\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\nprint(\"CHECKS:\");\n\n//  Import check module for practice problem 4.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p04.js\");\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\n//  PLEASE DO THE FOLLOWING: \n\n// 1. Uncomment all of the check statements below.\n// 2. Replace 'result_#p#' with the name of the data object that you used to map as a layer in each section.\n// 3. Run the script.\n// 4. Use the results printed to Console in the Check Up that is due Friday 5pm. \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\n// check.checkCollection(\"Check 1.1\", result_1p1);\n// check.checkCollection(\"Check 1.3\", result_1p3);\n// check.checkCollection(\"Check 2.1\", result_2p1);\n// check.checkCollection(\"Check 2.3\", result_2p3);\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  Check 3.4. What percent of Middlebury are habitat blocks and connectors?  \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// Please calculate percent area based on your result from 3.4.\n// When calculating area, please use 5 for scale and study_town (Middlebury) for extent.\n// The last two checks in Canvas will ask you to report area for habitat blocks and habitat connectors separately. \n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-05/","title":"P5. Land use in watershed riparian zones","text":"<p>PRACTICE 05 </p>"},{"location":"problems/practice-05/#land-use-in-watershed-riparian-zones","title":"land use in watershed riparian zones","text":""},{"location":"problems/practice-05/#goal","title":"goal","text":"<p>This problem aims to help you practice working with proximity and zonal statistics in Earth Engine. </p> <p>Your practical goal is to make a map that reports the percent of riparian zones that are either developed or used for agriculture in each watershed that overlaps a study town.  </p> <p>We will define key terms as follows: </p> <ul> <li>study town: Middlebury, Vermont  </li> <li>aoi: all level 12 watersheds that overlap the study town  </li> <li>surface waters: all streams, rivers, ponds, and lakes    </li> <li>riparian: all land within 50 feet of surface waters  </li> <li>developed: all impervious surfaces (buildings, roads, pavement, and railroads)  </li> <li>agriculture: all agricultural land uses (hayfields, crop fields, and pasture)  </li> <li>scale: for Part 9, use scale of 30 to help the model run a little faster</li> </ul> <p>Your solution should produce a map with the layers shown in the app below.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-05/#data-sources","title":"data sources","text":"<p>In this problem, we will use the National Hydrology Dataset (NHD) that is available as a cloud asset through the Awesome Earth Engine Community Catalog.</p> <p>In addition, we will use town and land cover data that we have worked with in previous problems.  </p>"},{"location":"problems/practice-05/#workflow","title":"workflow","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR: \n    DATE:   \n    TITLE:  Land use in watershed riparian zones\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// -------------------------------------------------------------\n//  datasets\n// -------------------------------------------------------------\n\n// Towns\n\nvar vt_towns = ee.FeatureCollection(\"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\"); // Land cover\n\nvar vt_ag = ee.Image(\"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Agriculture\");\nvar vt_imp = ee.Image(\"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Impervious\");\n\n// National Hydrology Dataset\n\nvar nhd_wbdhu12 = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/WBDHU12\");\nvar nhd_flowline = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/NHDFlowline\");\nvar nhd_area = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/NHDArea\");\nvar nhd_waterbody = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/NHDWaterbody\");\n\n// Viz helpers\n\nvar viz_bool = {min:0, max:1};\nvar red_palette = geo.iPalettes.yellowOrangeRed[6];\n\n// General parameters.\n\nvar scale = 30;  // To help model run a little faster, please set scale at 30 in Part 9. \n\n// -------------------------------------------------------------\n//  1. Define study town and set up map.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2. Select Level 12 watersheds that overlap study town. \n// -------------------------------------------------------------  \n\n\n\n// -------------------------------------------------------------\n//  3. Select NHD features that overlap selected watersheds. \n// -------------------------------------------------------------  \n\n\n// -------------------------------------------------------------\n//  4. Clip selected area features to selected watersheds. \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  5. Define riparian as buffer of selected hydrology features by 50 feet.  \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  6. Make union of buffered hydrology features.    \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  7. Define developed land as union of impervious and ag lands.    \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  8. Define developed land in riparian.     \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  9. Compute percent of developed land in riparian. (Set scale = 30 to help model run faster.)       \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  10. Classify percent into equal 10% intervals.  \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  11. Add watershed reference lines and legend.     \n// ------------------------------------------------------------- \n</code></pre>"},{"location":"problems/practice-05/#checks","title":"checks","text":"<p>Please add this code to the end of your script and edit the names to match those of your layers. You will need this answers to complete the checkup on Canvas that is due Monday by 5pm.</p> <pre><code>// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n//  PRACTICE CHECKS\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\nprint(\"CHECKS:\");\n\n//  Import check module for practice problem 4.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p05.js\");\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\n//  PLEASE DO THE FOLLOWING: \n\n// 1. Uncomment all of the check statements below.\n// 2. Replace 'result_part_#' with the name of the data object that you used to map as a layer in each section.\n// 3. Run the script.\n// 4. Use the results printed to Console in the Check Up that is due Monday 5pm. \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\n\ncheck.checkFeature(\"Check Part 1:\", result_part_1);\ncheck.checkFeature(\"Check Part 2:\", result_part_2);\ncheck.checkArea(\"Check Part 6:\", result_part_6);\ncheck.checkArea(\"Check Part 7:\", result_part_7);\ncheck.checkArea(\"Check Part 8:\", result_part_8);\ncheck.checkPoint(\"Check Part 9:\", result_part_9);\ncheck.checkPoint(\"Check Part 10:\", result_part_10);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-01/","title":"T1. A sketch map from lidar","text":"<p>TUTORIAL 1</p>"},{"location":"problems/tutorial-01/#a-sketch-map-from-lidar","title":"A sketch map from lidar","text":""},{"location":"problems/tutorial-01/#goal","title":"goal","text":"<p>In this tutorial, our practical goal is to import a digital surface model (DSM) from this address:</p> <pre><code>\"projects/ee-patterns/assets/t01/Elevation_DSM0p7m2017_cm\"\n</code></pre> <p>and make a map with the layers shown below.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-01/#starter-script","title":"starter script","text":"<pre><code>// -------------------------------------------------------------\n//  Construct image data object from address.\n// -------------------------------------------------------------\n\nvar image ;\n\n// -------------------------------------------------------------\n//  Print properties of image to the Console. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Set map center and zoom level.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Set basemap style.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Display image as a map layer.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Import geoMethods module. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Set viz range to data range.\n// -------------------------------------------------------------\n\nvar image_min_max ;\n\n\n\n// -------------------------------------------------------------\n//  Chart histogram of image data values.\n// -------------------------------------------------------------\n\nvar image_histogram ;\n\n\n// -------------------------------------------------------------\n//  Apply scalar operation; \n//  convert image data from centimeters to meters.\n// -------------------------------------------------------------\n\nvar image_meters ;\n\n// -------------------------------------------------------------\n//  Display new image as a layer\n//  with viz range set to data range.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  Derive slope of the surface image. \n// -------------------------------------------------------------\n\nvar image_slope ;\n\n// -------------------------------------------------------------\n//  Display slope image as map layer so that \"steeper is darker\".\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  TUTORIAL CHECKS\n// -------------------------------------------------------------\n\n//  I. QUANTITATIVE \n\n//  Import check module for tutorial 1.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/t01.js\");\n\n//  Uncomment the four lines below, run script, and look at the results in Console. \n\n// print(\"QUANTITATIVE CHECKS:\");\n// check.checkPoint(\"CP1:\", image);\n// check.checkPoint(\"CP2:\", image_meters);\n// check.checkPoint(\"CP3:\", image_slope);\n\n//  II. QUALITATIVE  \n\n//  Use zoom to inspect locations marked A, B, C, D.\n//  For each letter, please write down:\n\n//    1. What do you think the location \"is\"?\n//    2. How does the location represent environmental change?\n\n//  We will discuss in next lecture. \n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-02/","title":"T2. A slippy topographic map","text":"<p>TUTORIAL 2</p>"},{"location":"problems/tutorial-02/#a-slippy-topographic-map","title":"A slippy topographic map","text":""},{"location":"problems/tutorial-02/#goal","title":"goal","text":"<p>In this tutorial, our practical goal is to import a digital elevation model (DEM) from this address:</p> <pre><code>'USGS/3DEP/10m'\n</code></pre> <p>and make a map with the layers shown below.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-02/#starter-script","title":"starter script","text":"<pre><code>// Require geo module. \n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\"); print(\"geo dictionary\", geo.help);      // Prints dictionary of all tools in module.\nprint(\"geo palettes\", geo.iPalettes);   // Prints dictionary of all palettes in module. \n\n// -------------------------------------------------------------------------------\n//  Area of interest for tutorial.\n// -------------------------------------------------------------------------------\n\nvar aoi = geo.aoi.t2;\n\nprint(\"Area of interest\", aoi);\n\n// -------------------------------------------------------------------------------\n//  MAP\n//\n//  Center map on aoi at zoom level 10. \n//  Set basemap to hybrid.\n// -------------------------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------------------------\n//  DEM\n//\n//  Gather raster from this address: 'USGS/3DEP/10m'\n//  Display the image with stretch enhancement. \n//  Do not show the image by default. \n// -------------------------------------------------------------------------------\n\nvar image ;\n\n// -------------------------------------------------------------------------------\n//  SLOPE\n//\n//  Derive slope of a surface in degrees from elevation in meters from DEM.\n//  Display the image with stretch enhancement. \n// -------------------------------------------------------------------------------\n\nvar image_slope ;\n\n\n// -------------------------------------------------------------------------------\n//  HILLSHADE\n//\n//  Derive hillshade from DEM.\n//  Display as layer. \n// -------------------------------------------------------------------------------\n\nvar image_hs ;\n\n// -------------------------------------------------------------------------------\n//  ASPECT\n//\n//  Derive aspect from DEM.\n//  Display image as pseudo-color layer with palette: geo.iPalettes.iAspect.cyclical\n//  Add legend aspect image (continuous data) to 'bottom-left' of Map.\n//  Do not show the image by default. \n// -------------------------------------------------------------------------------\n\nvar image_aspect ;\n\n\n// -------------------------------------------------------------------------------\n//  ASPECT, part 2\n//\n//  Make a boolean image where all pixels not equal to 0 are true.\n//  Display boolean image as a map layer.\n//  Do not show the image by default. \n\n//  Mask all pixels in aspect image that are equal to 0.\n//  Display masked image as a map layer. \n//  Do not show the image by default. \n// -------------------------------------------------------------------------------\n\n//  Make a boolean (true/false) image based on a criterion.\n\nvar aspect_neq_0 ;\n\n// -------------------------------------------------------------------------------\n//  ASPECT, part 3\n//\n//  Reclassify the aspect image by equal intervals (22.5).\n//  Remap the image to represent N, NE, E, SE, S, SW, W, NW categories. \n//  Display remapped image as a pseudo-color layer with palette: geo.iPalettes.iAspect.nominal\n//  Add legend to the bottom-left corner of Map.\n// -------------------------------------------------------------------------------\n\n//  Reclassify by equal intervals.\n\nvar image_aspect_reclassified ;\n\n//  Remap values. \n\nvar image_aspect_remapped ;\n\n// -------------------------------------------------------------------------------\n//  ADD AOI ON TOP OF MAP\n// -------------------------------------------------------------------------------\n\nMap.add(geo.aoi.t2_layer);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-03/","title":"T3. Intro to feature collections","text":"<p>TUTORIAL 3</p>"},{"location":"problems/tutorial-03/#introduction-to-feature-collections","title":"Introduction to feature collections","text":""},{"location":"problems/tutorial-03/#goal","title":"goal","text":"<p>This tutorial aims to introduce you to gathering, filtering, and displaying large vector datasets in Earth Engine. Your goal is to work through the starter script and try to reproduce the layers that are shown in the app below.</p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-03/#starter-script","title":"starter script","text":"<pre><code>var geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ---------------------------------------------------------------------------\n//  I. A SIMPLE FEATURE COLLECTION PATTERN\n//\n//  (1) Gather feature collection from \"TIGER/2018/Counties\".\n//  (2) Note the number of rows in the table, the column names, and the first row of data.\n//  (3) Also find all the unique county names in the county. How many are there?\n//  (4) Display all the rows in the collection as a Map layer. Use {color: 'white'} \n// ---------------------------------------------------------------------------\n\n\n\n\n// ---------------------------------------------------------------------------\n//  II. FILTER BY ATTRIBUTE\n//\n//  (1) How may counties in the USA are named \"Addison\"?\n//  (2) Display all counties named Addison in the USA on the Map with {color: 'gray'}.\n// ---------------------------------------------------------------------------\n\n\n\n// ---------------------------------------------------------------------------\n//  III. FILTER BY LOCATION\n//\n//  (1) Use the geometry tool (upper left of Map) to create a point somewhere inside Addison County, Vermont.\n//  (2) Filter the original feature collection by location using this poi. \n//  (3) Display the result (Addison county filtered by poi) on the Map with {color: 'black'}.\n// ---------------------------------------------------------------------------\n\n\n\n\n// ---------------------------------------------------------------------------\n//  IV. FILTER BY MULTIPLE ATTRIBUTES.\n//  \n//  (1) Filter the original collection for \"Orange\" county.\n//  (2) How many Orange counties are in the USA?\n//  (3) Display the result (All counties named 'Orange') on map as layer with {color: 'orange'}.\n\n//  (4) Use AND filter to filter the original collection of counties for \"Orange\" county IN VERMONT.\n//  HINT: the STATEFP column stores strings (even through they look like numbers).\n//  (5) Display the result as a layer on the Map with {color: 'OrangeRed'}.\n// ---------------------------------------------------------------------------\n\n\n\n\n// ---------------------------------------------------------------------------\n//  V. FILTER BY ATTRIBUTE AND LOCATION\n//\n//  (1) Construct a new feature collection from \"TIGER/2018/States\".\n//  (2) Filter collection for Vermont.\n//  (3) Center Map on Vermont. \n//  (4) Add Vermont layer to Map with {color: 'green'}\n//  (5) Filter original county collection by name \"Orange\" and use a FILTER BY LOCATION to filter in bounds of Vermont state.\n//  (6) Display result on map with {color: \"LightGreen\"}\n// ---------------------------------------------------------------------------\n\n\n\n\n// ---------------------------------------------------------------------------\n//  VI. FILTER BY ATTRIBUTE AND LOCATION: TRICKY CASE\n//  \n//  (1) Try to reproduce last workflow (FILTER BY ATTRIBUTE AND FILTER BY LOCATION) to map \"Essex\" county in Vermont.\n//  (2) How did it work? What do you think happened?\n//  (3) Can you fix it with a workflow that does not use AND but still links together\n//    (A) a FILTER BY ATTRIBUTE with \n//    (B) a SPATIAL FILTER  \n//  (4) Display the fixed result as a layer to the map with {color: 'magenta'}.\n// ---------------------------------------------------------------------------\n\n\n\n// ---------------------------------------------------------------------------\n//  VII. FIRST CHALLENGE \n//\n//  (1) How could you select all the counties in Vermont using a FILTER BY ATTRIBUTE workflow?\n//  (2) After you filter the data, add the result  {color: \"PowderBlue\"}\n// ---------------------------------------------------------------------------\n\n\n\n// ---------------------------------------------------------------------------\n//  VIII. SECOND CHALLENGE\n//\n//  (1) How could you select all the counties in Vermont using a FILTER BY LOCATION workflow?\n//  (2) After you filter the data, add the result  {color: \"DeepSkyBlue\"}\n// ---------------------------------------------------------------------------\n\n\n\n// ---------------------------------------------------------------------------\n//  IX. FINAL TASK\n//  \n//  (1) Convert one of the counties in Vermont dataset (VII or VIII) to nominal image \n//  (2) Display each county in a unique color.\n// ---------------------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-03/#checks-in-starter","title":"checks in starter","text":"<p>Here are some checks that you can print to Console for sections I - V.  </p> SECTION DESCRIPTION CHECKS I-2 Number of rows in table. 3233 I-2 Column names 18 of them, beginning with GEOID and ending with METDIVFP I-2 First row of table id: 00000000000000000011; geometry: Polygon, 656 vertices; properties: 17 I-3 Unique county names 1922 of them II-1 Number of rows in table 1 III-2 Number of rows in table 1 IV-2 Number of rows in table 8 V Number of rows in table (states) 56 <p>For sections VI - IX, you should be able to check your work by visually comparing your map layers to the ones shown in the app above.  </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-04/","title":"T4. Forest blocks","text":"<p>TUTORIAL 4</p>"},{"location":"problems/tutorial-04/#forest-blocks","title":"Forest blocks","text":""},{"location":"problems/tutorial-04/#goal","title":"goal","text":"<p>This tutorial aims to introduce concepts and techniques for working with local overlay operations and geographic objects in Earth Engine.  </p> <p>Our practical goal is to identify all habitat blocks (contiguous regions of tree canopy and shrublands without impervious surfaces) that are greater than 100 acres in area. You will experiment with two different approaches to model these geographic objects and then export one layer as a cloud asset. In the end, your workflow should produce the set of layers shown in the app below. </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-04/#starter-scripts","title":"Starter scripts","text":"<p>Please complete the workflow outlined below. For most tasks, you will produce a layer that you can compare to the layers in the app.</p>"},{"location":"problems/tutorial-04/#00-start-your-workflow","title":"00 Start your workflow.","text":"<p>Start a new script and then add your header, import the geo module, and your cloud data addresses. </p> <pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     \n    TITLE:  \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// -------------------------------------------------------------  \n\n// Feature collections  \n\nvar town_address = \"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\"; // Images\n\nvar canopy_address = \"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_TreeCanopy\" ;\nvar shrub_address = \"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Shrublands\";\nvar imp_address = \"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Impervious\";\n</code></pre>"},{"location":"problems/tutorial-04/#01-define-study-region","title":"01 Define study region.","text":"<p>Your goals here are to first define a study town. We will use Middlebury in this tutorial, but ideally you will write your script so that you will be able to easily switch your study to any other town in Vermont.</p> <p>After you select the study town, please define your study region as the study town plus all adjacent towns (or any town that overlaps a boundary of the study town). </p> <p>Next make boolean images for both the study town and the study region. We will need these to mask layers later in the workflow.  </p> <p>Finally, center the Map on your study town. I used a zoom level of 12, but just pick one that works for your monitor. Then change the base map to \u2018hybrid\u2019 so that you can compare the land cover layers in the next step to an image of ground conditions.    </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. Define study region.\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Make a layer that shows the study town (Middlebury).\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.2 Convert study town into boolean (to use as mask later).\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.3 Define aoi as study town and surrounding towns. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  1.4 Convert aoi into a boolean (to use as mask later).\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.5 Center map on study town.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-04/#02-gather-land-cover-data","title":"02 Gather land cover data.","text":"<p>The next set of tasks involve gathering the land cover data that we will use to model habitat blocks. These datasets are all available through VCGI. I have imported them as assets in the cloud so that we can all share them. The table below provides more details about each dataset used in this tutorial. </p> <p> ASSET NAME DESCRIPTION FORMAT RESOLUTION STATEWIDE_2022_50cm_LANDCOVER_TreeCanopy Vermont Tree Canopy Land Cover 2022 Image 50 cm STATEWIDE_2022_50cm_LANDCOVER_Shrublands Vermont Shrublands Land Cover 2022 Image 50 cm STATEWIDE_2022_50cm_LANDCOVER_Impervious Vermont Impervious Surfaces Land Cover 2022 Image 50 cm <p></p> <p>After you construct images from these address, you will likely need to inspect the data properties of these objects in order to display them effectively. The table below lists the palettes that I used in the tutorial. </p> <pre><code>var canopy_palette = [\"#238b45\", \"#74c476\"];\nvar shrubs_palette = [\"#c0e673\"];\nvar imp_palette = [\"#4e4e4e\", \"#ffffff\", \"#a2a2a2\", \"#C47774\"];\n</code></pre> <p>The layers that you draw on your Map should:  </p> <ul> <li>use the colors from these palettes  </li> <li>only show data for our aoi  </li> </ul> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. Gather land cover data. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  2.1 Gather and display tree canopy masked by aoi.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.2 Gather and display shrub masked by aoi.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.3 Gather and display impervious masked by aoi.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-04/#03-model-habitat-as-a-boolean-image","title":"03 Model habitat as a boolean image.","text":"<p>In this set of tasks, your goal is to use local operations with the land cover data to make a layer that shows locations that are either tree canopy or shrubland but not impervious and then report both the total area and the area as a percent of the study town.  </p> <p>Part of the puzzle here involves working with masks. Remember, that any location that is masked will not be included in the analysis. In this case, you want to exclude all locations outside of your AOI, but include all locations within your AOI.   </p> <p>You might find it helpful to use the inspector tool to click on locations and see their data values. For each layer, you want to make sure that values are masked outside the AOI and not masked inside the aoi.  </p> <p>Also pay close attention that you should report the area and percent area of tree or shrub without impervious in the study town, not the entire AOI. </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  3. Model habitat as boolean image. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  3.1 Make boolean image that shows locations that are either tree canopy or shrub.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.2 Make image of tree or shrub locations that are not impervious.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.3. Calculate area of tree or shrub without impervious in study town.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.3. Calculate area of tree or shrub without impervious as percent of study town. \n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-04/#04-model-habitat-blocks-as-object-image-with-focal-methods","title":"04 Model habitat blocks as object image with focal methods.","text":"<p>In this set of tasks, your goal is to experiment with focal methods to identify objects and calculate their areas.  </p> <p>I would like you to pay attention to two things here:  </p> <ol> <li>How would you describe the habitat that is omitted from the resulting layer? Why do you think this habitat was excluded from the results? </li> <li>How does your result change when you zoom in or out of the layer? What does this tell you about how focal methods work in Earth Engine?  </li> </ol> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  4. Model habitat blocks as object image with focal methods. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  4.1 Make object layer from clusters with 3.2 boolean image.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  4.2 Make object area layer from clusters with 3.2 boolean image.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-04/#05-model-habitat-blocks-as-object-image-with-vector-methods","title":"05 Model habitat blocks as object image with vector methods.","text":"<p>Your goal here is to experiment with vector methods to identify objects. You will find that this approach is computationally expensive and Earth Engine may throw errors at you that complain about how much work you are asking it to do. To help resolve this, you will filter the collection by attribute and select only the habitat blocks that are at least 100 acres in area. You should be able to display this result as a map layer.  </p> <p>Finally, because the vector method is computationally expensive, your last task in this set is to export the feature collection as an asset. We will use this layer in the practice problem later this week.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  5. Model habitat blocks as object image with vector methods. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  5.1 Make objects from 3.2 boolean image using convert to vector method.\n// -------------------------------------------------------------\n\n\n// DO NOT ADD AS LAYER - EE WILL LIKELY PROTEST! \n// Just inspect with print to console methods. \n\n\n// -------------------------------------------------------------\n//  5.2 Filter for blocks greater than 100 acres and display as map layer. \n// -------------------------------------------------------------\n\n\n// Again, this is a big computational ask for Earth Engine, so do not show layer by default.\n\n\n// -------------------------------------------------------------\n//  5.3 Export 5.2 feature collection to asset and display as layer.\n// -------------------------------------------------------------\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-05/","title":"T5. Scale in web mercator","text":"<p>TUTORIAL 5</p>"},{"location":"problems/tutorial-05/#scale-in-web-mercator","title":"scale in web mercator","text":""},{"location":"problems/tutorial-05/#_1","title":"T5. Scale in web mercator","text":"<p>This tutorial aims to introduce concepts and methods for working with proximity and zonal statistics in Earth Engine.  </p> <p>Our practical goal is to make a map of Tissot\u2019s Indicatrix and then compute the area and number of pixels contained by each circle through a zonal overlay method. By the end, your script should reproduce the layers shown in the app below. </p> <p>In addition, you should be able to interpret your results by using the Inspector tool to compare how pixel scale changes with respect to the area and pixel count of Tissot\u2019s indicatrix.   </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-05/#workflow","title":"workflow","text":""},{"location":"problems/tutorial-05/#00-start-script","title":"00 start script","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     10/7/2024\n    TITLE:    Scale in web mercator\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n</code></pre>"},{"location":"problems/tutorial-05/#01-set-up-map","title":"01 set up map","text":"<pre><code>// -------------------------------------------------------------\n//  1. Set up map\n// -------------------------------------------------------------\n\n// 1.1. Center map on prime meridian and equator at zoom level 2.  \n\nMap.setCenter(0,0,2);\n\n// 1.2. Set base map to hybrid.\n\n\n\n// 1.3. Compute Map scale at Map zoom \n\nvar scale = Map.getScale();\n\nprint(\"Map scale\", scale);\n</code></pre>"},{"location":"problems/tutorial-05/#02-visualize-pixel-area","title":"02 visualize pixel area","text":"<pre><code>// -------------------------------------------------------------\n//  2. Visualize change in pixel area across Map.\n// -------------------------------------------------------------\n\n// 2.1. Make a layer that stores area of each pixel in square kilometers.\n\nvar pixel_area = ee.Image.pixelArea().divide(1e6);\n\n// 2.2. Draw a rectangle from equator to pole.\n\nvar test_extent = ee.Geometry.Polygon(\n[[[-139.54012012783244, 16.927790310290327],\n[-139.54012012783244, -85.91090722591649],\n[52.41300487216755, -85.91090722591649],\n[52.41300487216755, 16.927790310290327]]]);\n\n// 2.3. Calculate min and max of area image with test_extent rectangle at scale of zoom level. \n\n\n\n// 2.4. Define viz parameters with palette: geo.iPalettes.iDistance.inferno\n\n\n\n// 2.5. Display pixel_area as layer on Map.\n\n\n\n// 2.6. Make legend of pixel area layer. \n\n\n\n// 2.7. Add legend to Map.  \n</code></pre>"},{"location":"problems/tutorial-05/#03-create-tissots-indicatrix","title":"03 create Tissot\u2019s indicatrix","text":"<pre><code>// -------------------------------------------------------------\n//  3. Create Tissot's Indicatrix. \n// -------------------------------------------------------------\n\n// 3.1. Gather tissot grid.\n\nvar grid = geo.projections.tissot_grid;\n\nprint(\"3.1. grid\", grid);\n\n// 3.2. Display grid as Map layer.\n\n\n\n// 3.3 Buffer each point in grid by 600,000 meters. \n\n\n\n// 3.4 Add buffered points (Tissot's Indicatrix) as Map Layer. \n\nMap.addLayer(indicatrix, {color: 'gold'}, \"3.4. Tissot's Indicatrix\");\n</code></pre>"},{"location":"problems/tutorial-05/#04-visualize-area-of-indicatrix","title":"04 visualize area of indicatrix","text":"<pre><code>// -------------------------------------------------------------\n//  4. Visualize area of Tissot's indicatrix\n// -------------------------------------------------------------\n\n// 4.1 Zonal statistic for sum of pixel area at scale 5000.\n\n\n\n\n// 4.2 Convert 4.1 output to image\n\n\n\n// 4.3 Define viz parameters.\n\n\n\n// 4.4 Display as Map layer.\n\n\n\n// 4.5. Make legend of tissot area layer. \n\n\n\n// 4.6. Add legend to Map.  \n</code></pre>"},{"location":"problems/tutorial-05/#05-visualize-count-of-indicatrix","title":"05 visualize count of indicatrix","text":"<pre><code>// -------------------------------------------------------------\n//  5. Visualize count of indicatrix\n// -------------------------------------------------------------\n\n// 5.1 Zonal statistic for count of pixel area at scale 5000.\n\n\n\n// 5.2 Convert to image. \n\n\n\n// 5.3 Define viz parameters. \n\n\n\n\n// 5.4 Display as Map layer.  \n\n\n\n\n// 5.5. Make legend of tissot area layer. \n\n\n// 5.6. Add legend to Map.  \n</code></pre>"},{"location":"problems/tutorial-05/#06-inspect-your-results","title":"06 inspect your results","text":"<p>Click on the Inspector tab on the right panel of the Code Editor. Moving from the equator towards the poles, clock on the Tissot Indicatrix and note the Scale (approx. m/px) that GEE reports. This number should report the distance on the ground represented by the length of one pixel side.  </p> <p>HINT: You may need to click on the Point header in order to see the scale reports. </p> <p>Try to answer these questions:  </p> <ol> <li>How does scale change with latitude?  </li> <li>How does this jive with the area and count statistics that you calculated for each circle?  </li> <li>How do you explain these results?  </li> </ol> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"solutions/practice/","title":"Practice","text":"<p>SOLUTIONS </p>"},{"location":"solutions/practice/#practice-problems","title":"Practice problems","text":"<p>The links in the table below will open a worked out script for the problem in the Code Editor.  </p> LINK PROBLEM UPDATE P1 Memory under cover 9/11/24 P2 Ice age bathtub 9/18/24 P3 Parent materials of soils 9/25/24 P4 Forest blocks and habitat connectors 10/2/24"},{"location":"solutions/tutorials/","title":"Tutorials","text":"<p>SOLUTIONS </p>"},{"location":"solutions/tutorials/#tutorial-problems","title":"Tutorial problems","text":"<p>The links in the table below will open a worked out script for the problem in the Code Editor.  </p> LINK PROBLEM UPDATE T1 A sketch map from Lidar 9/9/24 T2 A slippy topographic map 9/16/24 T3 Intro to feature collections 9/23/24 T4 Forest blocks (part 1) 9/30/24 T5 Scale in web mercator 10/7/24"}]}