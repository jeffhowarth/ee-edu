{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ee pattern book","text":"<p>A collection of timeless problems of spatial analysis and image processing and how to solve them with Google Earth Engine.      </p> <p>Jeff Howarth Associate Professor of Geography  Geography Department Middlebury College Vermont, USA</p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"geo-module/","title":"geo module","text":"<p>The geo module is a collection of methods that I am writing and packaging in a way that will allow you to use the methods without having to write them from scratch. </p> <p>I wrote these methods for two reasons:    </p> <ol> <li> <p>Each represents a recurring task of geospatial analysis that is supported by other geographic information systems (like QGIS or ArcGIS).</p> </li> <li> <p>Each requires a chain of transformations to make in Earth Engine which can be conceptually confusing and technically difficult for novices to do.    </p> </li> </ol> <p>My hope is that providing ready-made methods may help you focus on how different methods of spatial analysis and cartography work conceptually in workflows without having to get bogged down in writing complicated task chains for common tools.  </p>"},{"location":"geo-module/#import-module","title":"import module","text":"<p>To use the module, create a container and require the module. </p> <pre><code>var geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n</code></pre> <p>The code block above will import the module and print the module\u2019s help dictionary and palette dictionary to the Console. The help dictionary lists all methods and url links to their docs. The palette dictionary lists all palettes in the module. You only need to import the module once in a script that calls a method or palette from the module. I usually place the above code snippet near the top of my script (under the header).  </p>"},{"location":"geo-module/#docs-in-eepatterns","title":"docs in eePatterns","text":"<p>A globe icon  identifies methods from module. </p> <p>In the METHODS documentation, the  symbol identifies a method that requires the geo module. To use any of these methods, you will need to include the import module in your script prior to calling the method. </p>"},{"location":"geo-module/#peak-under-hood","title":"peak under hood","text":"<p>Add module to your READER tray if you want to see the underlying code to any method.</p> <p>The module only hides the code from you if you do not want to see it. If you would like to look under the hood, I have made the code for the module public and you can add it to the READER tray of the IDE by clicking here. </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"intro/","title":"introduction","text":"<p>This book aims to help you create geospatial workflows with Google Earth Engine.  </p> <p>In general, these workflows grab geographic data stored in the cloud, alter it (with purpose), and then visualize the results as map layers.  </p> <p> <pre><code>graph LR\n  step01[(\"GEOGRAPHIC\\nDATA\\n\\n stored in cloud\")] ;\n  step02&gt;\"GEOSPATIAL WORKFLOW\\n\\n alter and visualize\"] ;\n\n  step01 --&gt; step02\n\n  classDef store fill:#4AA8A0,stroke-width:0px,color:#FFFFFF; \n  classDef transform fill:#4A92A8,stroke-width:0px,color:#FFFFFF;\n\n  class step01 store; \n  class step02 transform;\n\n</code></pre> <p></p> <p>To do this, we will use a web-based Integrated Development Environment (IDE) for the Earth Engine Javascript Application Programming Interface (API). That is a mouthful, but in practical terms it means that we will create workflows by writing scripts with javascript.   </p>"},{"location":"intro/#data-transformation","title":"data transformation","text":"<p>The basic element of all geospatial workflows is a three step process that Waldo Tobler called a cartographic transformation: you start with geographic data in a certain state (input), you do something to alter the data (method), and you store the result (output). Often but not always, one or more options (arguments) constrain how a method alters the input.   </p> <p> <pre><code>graph LR\n\n  input[\"INPUT\"] ;\n  method(\"METHOD\") ;\n  output[/\"OUTPUT\"/]  ;\n\n  input --&gt; method --&gt; output\n\n  arg[\"argument\"] ;\n\n  arg --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg; </code></pre> <p></p>"},{"location":"intro/#statements","title":"statements","text":"<p>With JavaScript, we transform geographic data by writing a statement. The syntax generally takes this form:</p> <pre><code>var output = input.method(argument);\n</code></pre> <p>The general pattern is that you start by defining a name for a container that you would like to make so that you can store the output. This container of data is called a variable that you create with the keyword <code>var</code>. You then say that this container will contain <code>=</code> what results from taking the input and applying a method to it <code>.</code> with one or more arguments <code>()</code>. A semicolon <code>;</code> punctuates a statement like a period (or wink ).  </p>"},{"location":"intro/#task-tree","title":"task tree","text":"<p>Workflows are a means to achieving an end. When you sit down to write a workflow, you have some goal state for the data in mind. Your problem is to figure out how to change the data from their original condition to the goal state in your head.  </p> <p>Most workflows can be decomposed into a task tree: at the top, a (big) problem  may be broken down into a sequence of smaller tasks, each of these tasks may be broken down into smaller subtasks.    </p> <pre><code>graph TD\n\n  L01(\"PROBLEM\") ;\n  L11[\"TASK 1\"] ;\n  L12[\"TASK 2\"] ;\n  L21[\"SUBTASK 1\"] ;\n  L22[\"SUBTASK 2\"] ;\n  L23[\"SUBTASK 3\"] ;\n  L24[\"SUBTASK 4\"] ;\n\n  L01 --- L11 \n  L01 --- L12\n  L11 --- L21\n  L11 --- L22\n  L12 --- L23\n  L12 --- L24\n\n  classDef L0 fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef L1 fill:#CCCCCC,stroke-width:0px,color:#000000;\n  classDef L2 fill:#000000,stroke-width:0px,color:#FFFFFF;  \n\n  class L01 L0; \n  class L11 L1;\n  class L12 L1;\n  class L21 L2;\n  class L22 L2;\n  class L23 L2;\n  class L24 L2;\n\n</code></pre> <p></p>"},{"location":"intro/#task-chain","title":"task chain","text":"<p>The lowest branches of the tree are individual transformations, the foundational elements of a workflow. Higher branches of the tree often require linking together two or more transformations as a task chain, where the output of one transformation becomes the input of another. </p> <p> <pre><code>graph LR\n  step01(\"INPUT\") ;\n  step02[\"METHOD\"] ;\n  step03(\"OUTPUT\")  ;\n  step04[\"METHOD_2\"] ;\n  step05(\"OUTPUT_2\")  ;\n  arg01(\"argument\") ;\n  arg02(\"argument_2\") ;\n\n  step01 --&gt; step02 --&gt; step03 --&gt; step04 --&gt; step05\n  arg01 --- step02\n  arg02 --- step04\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class step04 op;\n  class step05 in-out;\n  class arg01 arg;\n  class arg02 arg;\n\n</code></pre> <p></p>"},{"location":"intro/#summary","title":"summary","text":"<p>If this all sounds a bit wonky, do not worry too much. We will get to examples that illustrate all of this soon. For now, I just want you to know:  </p> <ol> <li>a workflow is a chain of input-method-output transformations </li> <li>you can think of a workflow visually (as a flow diagram) and verbally (as javascript).  </li> <li>visually, a workflow contains a vertical hierarchy of purpose (task tree) and a horizontal sequence of transformations (task chains). </li> </ol> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"three-t/","title":"the three Ts","text":"<p>Writing geospatial workflows brings together three domains:  </p> <ol> <li> <p>Thematic: the vocabulary, concepts, principles, theories, etc. of your application domain; the academic discipline, professional context, etc that defines the terms and beliefs of your inquiry.  </p> </li> <li> <p>Technical: the concepts and methods of the geographic information software that you are using to develop your workflows. For example, Google Earth Engine Javascript API, ArcGIS Pro, QGIS, GDAL, etc.</p> </li> <li> <p>Theoretical: the timeless concepts and methods of geospatial analysis and cartography; the body of knowledge that you need to understand to solve geospatial problems regardless of the thematic or technical domains that you are working in. </p> </li> </ol> <p>more soon</p>"},{"location":"three-t/#conceptual-models","title":"conceptual models","text":"<p>A key idea in geospatial workflows is that you can represent the world as a series of map layers for computation and comparison. So it is helpful to become familiar with the relatively small set of conceptual models that geospatial workflows tend to employ as instruments for representing the world as map layers.  </p> <p></p>"},{"location":"three-t/#data-models","title":"data models","text":"<p>When you develop geospatial workflows, your recurring task is to move between conceptual models and data models. In other words, you conceptualize a way to represent geography and then you implement this concept with a data model. </p> <p>more soon </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/RGB-composites/","title":"RGB composites","text":"<p>PATTERNS </p>"},{"location":"patterns/RGB-composites/#rgb-composites","title":"RGB composites","text":""},{"location":"patterns/RGB-composites/#additive-color-system","title":"additive color system","text":"<p>RGB composites use additive color to display raster data values in three bands at once. </p> <p>More soon.</p> <p>Use the RGB mixer below to create the colors by adding values in Red, Green, and Blue channels.  </p> <p> </p> <p>Open app in new browser window </p> <p>Here is the key for primary and secondary additive colors.  </p> <p> </p>"},{"location":"patterns/RGB-composites/#rgb-viz","title":"RGB viz","text":"<p>This is a basic pattern to visualize multi-band images as a combination of red, green, and blue channels.  </p> <pre><code>var rgb_viz = \n    {\n        bands:  ['red', 'green', 'blue'],      \n        min:    [0, 0, 0],        \n        max: [255, 255, 255],\n        gamma: [1,1,1]    \n    }\n;\n</code></pre> <p>The gamma property bends the function that maps display values to data values in order to lighten or darken the midtones of the image. Lowering the gamma value (towards 0) darkens the image, while raising the gamma value (towards 2) lightens the image.  </p> <p>The min, max, and gamma values can be adjusted separately for each band. </p>"},{"location":"patterns/RGB-composites/#natural-and-false-color","title":"natural and false color","text":"<p>A natural color image displays reflectance in the Red, Green, and Blue bands of the EM spectrum using the Red, Green, and Blue color channels, respectively. The result looks roughly similar to what we see when we have a window seat and the shade up. </p> <p>A false color image breaks this like-to-like mapping of the EM spectrum to additive color. For example, the near infrared (NIR) false color image displays reflectance in NIR, Red, and Green bands of the EM spectrum to the Red, Green, and Blue color channels. respectively. The result looks different from our experience, but is often helpful for distinguishing different types of vegetation and surfaces that otherwise look \u2018green\u2019 in natural color composites.  </p> <p>Importantly, a NIR false color image is just one example of a false color image. Many other false color images display reflectance in shortwave infrared (SWIR), sometimes called mid-range infrared, that are useful in wide range of applications. </p> <p>To better understand how false color images work, please read:</p> <ul> <li>Why is that Forest Red and that Cloud Blue? How to Interpret a False-Color Satellite Image </li> </ul> <p>This is an old but still helpful reference for exploring different band combinations for false color:  </p> <ul> <li>Landsat band combinations </li> </ul>"},{"location":"patterns/RGB-composites/#chart-spectral-signatures","title":"chart spectral signatures","text":"<p>To interpret and explain why false color images look the way they do, it can be helpful to chart the spectral signature of locations in an image.  </p> <p>If you add the appropriate pattern below to the end of a script that produces an image from a Landsat collection, you should be able to click on locations on the Map and chart the spectral signature of each location.    </p>"},{"location":"patterns/RGB-composites/#landsat-5","title":"Landsat 5","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from L5 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\n  config.poi = ee.Geometry.Point(coords.lon, coords.lat);\n  samples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\n  panel_chart.clear();\n  panel_chart.add(geo.icLandsat.chartSpectralSignatureL5(\n    output,                             // Name of L5 image ('output' assumes you are using starter script).\n    samples\n    ));\n  }\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#landsat-7","title":"Landsat 7","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from L7 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\n  config.poi = ee.Geometry.Point(coords.lon, coords.lat);\n  samples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\n  panel_chart.clear();\n  panel_chart.add(geo.icLandsat.chartSpectralSignatureL7(\n    output,                             // Name of L7 image ('output' assumes you are using starter script).\n    samples\n    ));\n  }\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#landsat-8","title":"Landsat 8","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from L8 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\n  config.poi = ee.Geometry.Point(coords.lon, coords.lat);\n  samples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\n  panel_chart.clear();\n  panel_chart.add(geo.icLandsat.chartSpectralSignatureL8(\n    output,                             // Name of L8 image ('output' assumes you are using starter script).\n    samples\n    ));\n  }\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#landsat-9","title":"Landsat 9","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from L9 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\n  config.poi = ee.Geometry.Point(coords.lon, coords.lat);\n  samples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\n  panel_chart.clear();\n  panel_chart.add(geo.icLandsat.chartSpectralSignatureL9(\n    output,                             // Name of the L9 image ('output' assumes you are using starter script).\n    samples\n    ));\n  }\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#modis","title":"MODIS","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from MODIS image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\n  config.poi = ee.Geometry.Point(coords.lon, coords.lat);\n  samples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\n  panel_chart.clear();\n  panel_chart.add(geo.icMODIS.chartSpectralSignatureMODIS(\n    output,                             // Name of the MODIS image ('output' assumes you are using starter script).\n    samples\n    ));\n  }\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#sentinel-2","title":"Sentinel 2","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from S2 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\n  config.poi = ee.Geometry.Point(coords.lon, coords.lat);\n  samples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\n  panel_chart.clear();\n  panel_chart.add(geo.icSentinel.chartSpectralSignatureS2(\n    output,                             // Name of the S2 image ('output' assumes you are using starter script).\n    samples\n    ));\n  }\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"patterns/composite-mosaic/","title":"flatten collections","text":"<p>PATTERNS</p>"},{"location":"patterns/composite-mosaic/#flatten-image-collections","title":"flatten image collections","text":"<p>Many workflows for image collections will include a step that transforms an image collection into a single image (and flattens the collection).  </p>"},{"location":"patterns/composite-mosaic/#composite-image","title":"composite image","text":"<p>If the collection represents a time series of satellite scenes, the workflow will often include a step that makes a composite image. This reduces the image collection to a single image.  </p> <p>Conceptually, composite methods are analogous to local operations for images because they perform calculations for each pixel across a stack of images. The main difference is that the stack of images in a collection can be quite large and not restricted to  comparisons of just two images.  </p> <p>diagram forthcoming </p>"},{"location":"patterns/composite-mosaic/#statistical-composites","title":"statistical composites","text":"<p>These methods calculate a statistic of all values at each pixel across a stack of all matching bands.  </p> <pre><code>var mean_collection = ic.mean();\n\nprint(\"Composite collection by mean\", mean_collection);\n</code></pre> <p>The example above calculates the mean value in each pixel across the stack of matching bands in the ic. Here are some other common statistical composites. </p> <pre><code>var median_collection = ic.median();\n\nprint(\"Composite collection by median\", median_collection);\n</code></pre> <pre><code>var max_collection = ic.max();\n\nprint(\"Composite collection by max\", max_collection);\n</code></pre> <pre><code>var min_collection = ic.min();\n\nprint(\"Composite collection by min\", min_collection);\n</code></pre> <pre><code>// Mode is the most common value at each pixel. \n\nvar mode_collection = ic.mode();\n\nprint(\"Composite collection by mode\", mode_collection);\n</code></pre>"},{"location":"patterns/composite-mosaic/#mosaic-image","title":"mosaic image","text":"<p>If the collection contains a set of small tiles, then a workflow will often include a step that makes a mosaic image. This is a common step in workflows with lidar products.  </p> <p></p> <p> <pre><code>graph LR\n\n  method(\"geo.icFlatten.mosaicToImage()\") ;\n  output[/\"ic_mosaic\"/]  ;\n\n  method --&gt; output\n\n  arg[\"ic\"] ;\n\n  arg --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg; </code></pre> <p></p> <pre><code>var ic_mosaic = geo.icFlatten.mosaicToImage(ic);\n\nprint(\"Mosaic\", ic_mosaic);\n</code></pre> <p>This method mosaics the tiles into a single image and gives the new image the same coordinate reference system as the first image in the collection. The crs defines the xy units of the image and this enables you to use the mosaic image as an input in terrain operations.  </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/convert-data/","title":"convert data","text":"<p>PATTERNS</p>"},{"location":"patterns/convert-data/#convert-data","title":"convert data","text":"<p>These methods change the models used to represent geographic data and include:</p> <ul> <li>vector to raster</li> <li>raster to vector</li> </ul>"},{"location":"patterns/convert-data/#vector-to-raster","title":"vector to raster","text":"<p>These methods typically convert feature collections to images. </p> <p>more soon </p>"},{"location":"patterns/convert-data/#any-fc-to-boolean-raster","title":"any FC to boolean raster","text":"<p>This method converts a feature collection into a boolean raster. </p> <pre><code>var image_boolean = geo.fcConvert.toBooleanImage(fc);\n</code></pre>"},{"location":"patterns/convert-data/#nominal-fc-to-integer-raster","title":"nominal FC to integer raster","text":"<p>This method converts a feature collection with text attributes to a single-band image. It essentially creates a list of unique text attributes from a table column (defined by \u201ccolumn_name\u201d) and matches each unique text attribute to a unique integer. The result is an image with integer pixel values. The method also prints a dictionary to the Console that reports the integer code for each unique attribute.   </p> <pre><code>var image_nominal = geo.fcConvert.toNominalImage(fc, \"column_name\");\n</code></pre>"},{"location":"patterns/convert-data/#numeric-fc-to-numeric-raster","title":"numeric FC to numeric raster","text":"<p>This method uses numeric attribute data in a feature collection to create a raster. </p> <pre><code>var image_numeric = geo.fcConvert.toNumericImage(fc, \"column_name\", \"reducer\");\n</code></pre> <p>The method takes three arguments that are defined in the table below.  </p> ARGUMENTS DESCRIPTION fc The feature collection to convert. \u201ccolumn_name\u201d The name of the column with the numeric data to populate the pixel values of the output raster. \u201creducer\u201d How you would like to combine the values of each intersecting feature into a final result to store in the pixel? This must be a string and one of the following: \u201cmean\u201d, \u201cfirst\u201d, \u201cmax\u201d, \u201cmin\u201d."},{"location":"patterns/convert-data/#raster-to-vector","title":"raster to vector","text":"<p>These methods typically convert images to feature collections.  </p> <p>more soon </p>"},{"location":"patterns/convert-data/#make-objects-with-vectors","title":"make objects with vectors","text":"<p>This method identifies objects from rasters based on two conditions: </p> <p>(1) Pixels share the same value. (2) Pixels form contiguous regions that can be represented with a polygon.  </p> <p>It returns a feature collection of distinct regions and includes the area as an attribute of each feature.  </p> <pre><code>var objects_with_vectors = geo.iConvert.makeObjectsWithVectors(image, \"property\", scale, extent, \"unit\");\n</code></pre> ARGUMENTS DESCRIPTION image Input image with a band that represent boolean or nominal (class) raster to clump. \u201cproperty\u201d A description (as a string) of the boolean or class data used to clump. Flr example, \u201cclass\u201d. scale Scale of analysis to help troubleshoot TIME OUT errors. Often good practice to start relatively coarse and then aim to match resolution of image in later runs. extent The area of interest or study region to constrain analysis. \u201cunit\u201d Choose between \u201cacres\u201d, \u201csq_m\u201d, and \u201csq_km\u201d <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/customize-Map/","title":"customize Map","text":"<p>PATTERNS</p>"},{"location":"patterns/customize-Map/#customize-map","title":"customize Map","text":"<p>It is often helpful to customize the Map so that it centers and zooms on your area of interest and uses a base map that supports your purpose.  </p> <p>The diagram below shows a general pattern.</p> <p> <pre><code>graph LR\n\n  step01(\"Set map center and zoom\") ;\n  step02(\"Set base map style\") ;\n\n  step01 --&gt; step02\n\n  classDef task fill:#C3C8E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>It is good practice to set the map center and zoom level before setting the base map so that the base map does not need to redraw.</p>"},{"location":"patterns/customize-Map/#set-map-center-and-zoom","title":"set map center and zoom","text":"<p>Use a data object to center the map and to suggest an appropriate zoom level. </p> <pre><code>Map.centerObject(\n    object,             // data object to center the Map. \n    16                  // zoom level to display the Map.\n);\n</code></pre>"},{"location":"patterns/customize-Map/#set-basemap-style","title":"set basemap style","text":"<p>Select a basemap that provides the most helpful reference information from your data. </p> <pre><code>Map.setOptions(\"HYBRID\");\n</code></pre> <p>Choose from the following options: </p> <p><pre><code>\"ROADMAP\" \n</code></pre> <pre><code>\"SATELLITE\" \n</code></pre> <pre><code>\"HYBRID\"\n</code></pre> <pre><code>\"TERRAIN\" \n</code></pre></p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/explain-code/","title":"explain code","text":"<p>PATTERNS</p>"},{"location":"patterns/explain-code/#explain-code","title":"explain code","text":"<p>Always write your code for two main audiences: </p> <ol> <li>a computer that will compile and execute your code;</li> <li>a person who will read your code and try to make sense of it. </li> </ol> <p>The second audience may be yourself in the future, when you return to a script that you wrote after some time has passed. It may be an instructor in this course who wants to help you troubleshoot something in your script that is not working. Or it may be someone you have never met who is looking to adapt and recycle parts of your script for a slightly different purpose. Whoever the reader may be, you should always aim to help people read your code by placing explanations directly in your workflow. </p> <p>The patterns below describe different ways to explain your code and make it more readable for a human audience. </p>"},{"location":"patterns/explain-code/#script-header","title":"script header","text":"<p>Write a header at the top of your script.</p> <p>At a minimum, the header should identify who wrote the script, when they wrote it, and why they wrote it. This is also where many authors will define the license for the script.  </p> <p>I usually include a couple lines of repeating symbols to visually block the header and separate it from the rest of the script.  </p> <pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     \n    TITLE:  \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n</code></pre>"},{"location":"patterns/explain-code/#task-description","title":"task description","text":"<p>Write a line comment before each major task in your workflow.</p> <p>Describe what you are doing or why you are doing it. Use full sentences and correct punctuation (start each comment with a capital letter and end each comment with a period).  </p> <p>I usually include a line of repeating symbols above and below the task description to help visually separate the code into discrete chunks.  </p> <pre><code>// -------------------------------------------------------------\n//  To illustrate a task description.\n// -------------------------------------------------------------\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/explain-symbology/","title":"explain symbology","text":"<p>PATTERNS</p>"},{"location":"patterns/explain-symbology/#explain-layer-symbology","title":"explain layer symbology","text":"<p>Methods for defining what colors in palettes mean on your map.  </p> <p>more forthcoming </p>"},{"location":"patterns/explain-symbology/#define-colors-with-legend","title":"define colors with legend","text":"<p>These methods take some or all of the following arguments.</p> ARGUMENT DESCRIPTION \u201ctitle\u201d Label for the legend. Must be a string. Often a short description of image will do. viz The viz dictionary that defines how to visualize (display) the data. class_labels A list of names for each color in the palette that define the classes or categories of the data. \u201cposition-on-map\u201d Where to place the legend. Must be a string. Composed as \u201crow - column\u201d, where rows are \u201cbottom\u201d, \u201cmiddle\u201d, or \u201ctop\u201d and columns are \u201cleft\u201d, \u201ccenter\u201d, \u201cright\u201d. For example, \u201cbottom-right\u201d. There is no \u201cmiddle-center\u201d."},{"location":"patterns/explain-symbology/#image-with-continuous-data","title":"image with continuous data","text":"<p>If the image contains continuous or cyclical data, place a snapshot of the color gradient on the Map with labels that identify the minimum, maximum, and midpoint data value mapped to the color gradient. </p> <pre><code>// Make legend from image with continuous data. \n\nvar legend_continuous = geo.iCart.legendContinuous(\n  \"title\", \n  viz, \n  \"position-on-map\"\n  )\n;\n\n// Add legend to Map.  \n\nMap.add(legend_continuous);\n</code></pre>"},{"location":"patterns/explain-symbology/#from-image-with-nominal-data","title":"from image with nominal data","text":"<p>If the image contains nominal (discrete) data, place a symbol dictionary that defines each swatch of the palette with a label, or name for the class.     </p> <pre><code>// Make legend from image with nominal data.\n\nvar legend_nominal = geo.iCart.legendNominal(\n  \"title\", \n  viz, \n  class_labels, \n  \"position-on-map\"\n  )\n;\n\n// Add legend to Map.  \n\nMap.add(legend_nominal);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/export/","title":"export data","text":"<p>PATTERNS</p>"},{"location":"patterns/export/#export-data","title":"export data","text":"<p>Earth Engine does not permanently store the data objects that you make in your workflows unless you specifically ask it to do so. The patterns below deal with two different scenarios:  </p> <ol> <li>exporting data to a cloud asset</li> <li>exporting data to a cloud drive</li> </ol>"},{"location":"patterns/export/#to-cloud-asset","title":"to cloud asset","text":"<p>Whenever you pan your Map or zoom in and out of your Map, Earth Engine will run through all the steps required to make your data layers at the scale and extent that you are requesting.  </p> <p>Because of this, it is common to get to the point in a workflow where two things happen:  </p> <ol> <li> <p>Earth Engine starts to balk at the amount of work you are asking it to do and throws time out or tile errors.  </p> </li> <li> <p>You get impatient waiting for Earth Engine to process a long workflow just to zoom in and out and pan around your map. (When the slippy map gets sticky, it is like watching a game or movie that keeps buffering.)  </p> </li> </ol> <p>At this point, I tend to export my data as an asset so that I can just call the result directly. This is analogous to saving a copy of your data in the cloud. The asset will have a cloud address that you can then use to gather the data back into your workflow with a constructor like <code>ee.Image()</code>.   </p> <p>Please note that when you export data as cloud assets, you are no longer storing it as a variable. So these patterns do not begin by declaring a variable. They simply execute a function.   </p>"},{"location":"patterns/export/#export-fc","title":"export fc","text":"<p>This method will create a task that will export a feature collection as a Google Earth Engine asset. You will need to go to the task tab and run the task. When it is complete, you can access the asset through the asset tab. Open the asset (double-click) and then copy the asset id. You can then use this address in a data gathering pattern for vector data.</p> <pre><code>geo.fcExport.toCloudAsset(fc, \"asset_name\");\n</code></pre> <p> ARGUMENT DESCRIPTION fc A feature collection to export. \u201casset_name\u201d A name for the asset. <p></p>"},{"location":"patterns/export/#export-image","title":"export image","text":"<p>This method will create a task that will export an image as a Google Earth Engine asset. You again will need to go to the task tab and run the task. When it is complete, you can access the asset through the asset tab. Open the asset (double-click) and then copy the asset id. You can then use this address in a data gathering pattern for raster data.</p> <pre><code>geo.iExport.toCloudAsset(\n  image, \n  \"asset_name\",\n  extent, \n  \"pyramiding\"\n);\n</code></pre> <p> ARGUMENT DESCRIPTION image An image to export. \u201casset_name\u201d A name for the asset. extent The area of interest or study region to define the bounds of the image. \u201cpyramiding\u201d The method for generating pyramid layers to display in slippy map. Use \u201cmode\u201d for boolean, categorical, and object rasters and \u201cmean\u201d for field rasters. <p></p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/filter-collections/","title":"filter collections","text":"<p>PATTERNS</p>"},{"location":"patterns/filter-collections/#filter-collections","title":"filter collections","text":"<p>Image and feature collections often include more data than you need. As a result, both tend to follow this pattern: </p> <p> <pre><code>graph LR\n\n  step01(\"Access collection from cloud\") ;\n  step02(\"Filter collection\") ;\n\n  step01 --&gt; step02\n\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000 ;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>A filter is a method of asking a true or false question about the content of a collection and then only keeping the records where the answer is true. In other GIS, these are called selections or queries which are often written in SQL, which follows a similar logic but employs a different syntax.  </p> <p>In Earth Engine, you can filter collections in three ways:  </p> <ul> <li>by time, </li> <li>by location, </li> <li>by attribute. </li> </ul>"},{"location":"patterns/filter-collections/#filter-by-time","title":"filter by time","text":"<p>An image collection represents a time series when it contains images that capture the same region of space at different moments in time. The date associated with each image will be a property of the image. Earth Engine provides several different methods to filter the collection by defining a temporal interval, or a window of time defined by a start and end date.</p>"},{"location":"patterns/filter-collections/#filter-by-calendar-range","title":"filter by calendar range","text":"<p>This method allows you to choose a calendar unit for a temporal interval. </p> <pre><code>var select_by_calendar = ic.filter(\n  ee.Filter.calendarRange(start, end, \"unit\")\n  )\n;\n</code></pre>"},{"location":"patterns/filter-collections/#filter-by-date-range","title":"filter by date range","text":"<p>This method defines a temporal interval with a start and end date. The start_date and end_date must be strings in the format: <code>\"YYYY-MM-DD\"</code>.  </p> <pre><code>var select_by_date = ic.filter(\n  ee.Filter.date(\"start_date,\" \"end_date\")\n  )\n;\n</code></pre>"},{"location":"patterns/filter-collections/#filter-by-location","title":"filter by location","text":"<p>This involves making spatial comparisons between two layers. One layer is a collection of things (features, images) that has more things than you need. The other layer is a geometry, feature, or feature collection that defines your place of interest. These filters work by comparing the location of things in the first collection with the location of the place of interest in the second layer.   </p>"},{"location":"patterns/filter-collections/#filter-by-bounds","title":"filter by bounds","text":"<p>One of the most common spatial filters tests for overlap between items in the collection and the place of interest. Any item in the collection that overlaps the place of interest will pass through the filter and the rest of the things will be filtered out. Even things that only overlap the place of interest on the very edge will still pass through the filter and remain in the collection. The diagram below shows this by passing items 7, 13, 19 through the filter. You can think of the items in this collection as either individual images (image collection) or individual features (feature collection).   </p> <p></p> <p>It is sometimes helpful to think of this as a fork filter, because this filter does not alter the shape of the items in the collection. The filter does not cut them, as a knife would, and the collective shape of the items that pass through the filter does not match the shape of the place of interest.  </p> <p>The syntax for this method in Earth Engine looks a little clunky because you first call <code>.filter()</code> on the collection that you want to filter (called c for collection in the code snippet), which then takes <code>ee.Filter.bounds()</code> as an argument, which itself takes the place of interest object as an argument.  </p> <pre><code>graph LR\n\n  input[\"collection\"] ;\n  method(\"&lt;b&gt;.filter()&lt;/b&gt;\") ;\n  output[/\"collection_filter_bounds\"/]  ;\n\n  input --&gt; method --&gt; output\n\n  arg[\"ee.Filter.bounds()\"] ;\n\n  arg --o method\n\n  arg2[\"place_of_interest\"] ;\n\n  arg2 --o arg\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg; \n  class arg2 arg;</code></pre> <pre><code>var collection_filter_bounds = collection.filter(ee.Filter.bounds(place_of_interest));\n</code></pre> <p>Because this method is very commonly used to filter both image and feature collections but has such wonky syntax, Earth Engine provides an alternative expression to call the method that is a bit simpler to write. In the snippet below, c is the collection to filter and place_of_interest is the object that is being used to test for overlap it. </p> <pre><code>var collection_filter_bounds = collection.filterBounds(place_of_interest);\n</code></pre> <p>The main advantage of learning to write the first, clunky syntax is that you can use it to include the filter in AND methods (see below).  </p>"},{"location":"patterns/filter-collections/#check-results","title":"check results","text":"<p>After applying a filter, it is good practice to quickly check to see if the filter reduced the collection and by how much.    </p> <pre><code>print(\n  \"collection before:\",\n  collection.size(),\n  \"collection after:\"\n  collection_filter_bounds.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#full-pattern","title":"full pattern","text":"<p>Here is the full pattern for filtering by overlap.  </p> <pre><code>// Filter feature collection for overlap with fork. \n\nvar collection_filter_bounds = collection.filterBounds(fork);\n\n// Check filtered result.  \n\nprint(\n  \"collection before:\",\n  collection.size(),\n  \"collection after:\"\n  collection_filter_bounds.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#other-spatial-filters","title":"other spatial filters","text":"<p>The <code>.filterBounds()</code> method is a generally fast method to filter by location, but sometimes you may not want to keep features that only overlap the boundary of the place of interest. To help in these cases, I wrote a custom method that allows you to filter features in one collection based on their spatial relationship to features in another collection (place of interest).      </p> <pre><code>var fc_spatial_filter = geo.fcFilter.spatial('spatialRelationship', collection, place_of_interest);\n</code></pre> <p>You may choose one of three spatial relationships.  </p> SPATIAL RELATIONSHIP DESCRIPTION \u201ccontainedIn\u201d Returns features in collection that are contained by place of interest. \u201cdisjoint\u201d Returns features in collection that do not touch place of interest. \u201cintersects\u201d Returns features in collection that touch a place of interest."},{"location":"patterns/filter-collections/#filter-by-attribute","title":"filter by attribute","text":"<p>These methods allow you to filter a collection based on property values of items in the collection. They work for both image collections and feature collections. The filter essentially asks a true/falsw question about the properties of the collection and returns the elements of the collection where the answer is true. </p> <p></p>"},{"location":"patterns/filter-collections/#filter-by-attribute_1","title":"filter by attribute","text":"<pre><code>var collection_filtered = collection.filter(\n  ee.Filter.eq('property', 'value')\n);\n</code></pre>"},{"location":"patterns/filter-collections/#check-filter-results","title":"check filter results","text":"<pre><code>print(\n  \"collection before:\",\n  collection.size(),\n  \"collection after:\"\n  collection_filtered.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#full-pattern_1","title":"full pattern","text":"<pre><code>// Filter by attribute  \n\nvar collection_filtered = collection.filter(\n  ee.Filter.eq('property', 'value')\n);\n\n// Check filtered result.  \n\nprint(\n  \"collection before:\",\n  c.size(),\n  \"collection after:\"\n  c_filtered.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#other-criteria","title":"other criteria","text":"<p>There are a number of filters that follow the same pattern as above and take property and attribute value as arguments. The <code>ee.Filter.eq()</code> and <code>ee.Filter.neq()</code> can take either a string or number as the value argument. The other filters listed below typically take a number.  </p> <pre><code>ee.Filter.eq('property', 'value')        // Equal to\n</code></pre> <pre><code>ee.Filter.neq('property', 'value')       // Not equal to\n</code></pre> <pre><code>ee.Filter.gt('property', 0)              // greater than\n</code></pre> <pre><code>ee.Filter.gte('property', 0)            // greater than or equal to\n</code></pre> <pre><code>ee.Filter.lt('property', 0)             // less than\n</code></pre> <pre><code>ee.Filter.lte('property', 0)            // less than or equal to\n</code></pre>"},{"location":"patterns/filter-collections/#filter-fc-by-logical-criteria","title":"filter FC by logical criteria","text":"<p>These patterns are similar to logical comparisons in raster but work with vector data. They can be particularly helpful to filter a feature collection by location using features in more than one other collection or to filter a feature collection by both location and by attribute.   </p>"},{"location":"patterns/filter-collections/#and-by-location","title":"AND by location","text":"<pre><code>var fc_filter_and = fc.filter(\n  ee.Filter.and(\n    ee.Filter.bounds(A),\n    ee.Filter.bounds(B)\n  )\n);\n\nprint(\n  \"collection before:\",\n  fc.size(),\n  \"collection after:\",\n  fc_filter_and.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#and-by-location-and-by-attribute","title":"AND by location and by attribute","text":"<pre><code>var fc_filter_amd = fc.filter(\n  ee.Filter.and(\n    ee.Filter.bounds(A),\n    ee.Filter.eq(\"class\", 1)\n  )\n);\n\nprint(\n  \"collection before:\",\n  fc.size(),\n  \"collection after:\",\n  fc_filter_and.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#or-by-location","title":"OR by location","text":"<pre><code>var fc_filter_or = fc.filter(\n  ee.Filter.or(\n    ee.Filter.bounds(A),\n    ee.Filter.bounds(B)\n  )\n);\n\nprint(\n  \"collection before:\",\n  fc.size(),\n  \"collection after:\",\n  fc_filter_and.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#or-by-location-or-by-attribute","title":"OR by location or by attribute","text":"<pre><code>var fc_filter_or = fc.filter(\n  ee.Filter.or(\n    ee.Filter.bounds(A),\n    ee.Filter.eq(\"class\", 2)\n  )\n);\n\nprint(\n  \"collection before:\",\n  fc.size(),\n  \"collection after:\",\n  fc_filter_and.size()\n);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/focal-operations/","title":"focal (neighborhood) operations","text":"<p>PATTERNS</p>"},{"location":"patterns/focal-operations/#focal-operations","title":"focal operations","text":"<p>Focal operations use a moving window to carry out a computation based on values in the neighborhood of a focal cell. The window moves systematically across the raster, performing calculations for each pixel.    </p> <p></p> <p>The result of each neighborhood calculation is stored in the output raster pixel that corresponds with the location of the focal pixel in the input raster. The shape and size of the moving window is defined by a kernel.  The example below uses a square, 3 x 3 pixel kernel to compute the average neighborhood value for a focal pixel.  </p> <p> </p>"},{"location":"patterns/focal-operations/#scale-of-analysis","title":"scale of analysis","text":"<p>;</p> <p>source</p>"},{"location":"patterns/focal-operations/#object-rasters-from-clusters","title":"Object rasters from clusters","text":"<p>more soon </p>"},{"location":"patterns/focal-operations/#make-objects-from-clusters","title":"make objects from clusters","text":"<p>This method uses uses either a \u2018plus\u2019 or \u2018square\u2019 moving window to clump pixels that:</p> <ol> <li>have the same value and</li> <li>touch on adjacent sides (\u2018plus\u2019 window) and/or corners (\u2018square\u2019 window).  </li> </ol> <p>It returns an image with the original band(s) and a new band called \u2018labels\u2019 that identifies contiguous regions with unique integer values. It is usually helpful to select the \u2018labels\u2019 band and visualize it with <code>.randomVisualizer()</code>. </p> <p>The method works relatively quickly, but has two important quirks that result from Earth Engine\u2019s architecture:  </p> <ol> <li>It cannot identify objects that are larger than 1024 pixels.  </li> <li>The scale of analysis is determined by zoom level. Because of this, the results will change as you zoom in and out of the output layer.  </li> </ol> <p>Here is the basic pattern.  </p> <pre><code>var objects_from_clusters = geo.iFocal.makeObjectsFromClusters(image, 'kernel');  \n\nMap.addLayer(objects_from_clusters.select(\"labels\").randomVisualizer(), {}, \"4.1. Objects from clusters\";\n</code></pre> ARGUMENT DESCRIPTION image Input image with a band that contains a boolean or nominal (class) raster. If image contains more than one band, select the band that identifies the classes that you want to cluster. \u2018kernel\u2019 Either \u2018plus\u2019 or \u2018square\u2019. A \u2018square\u2019 will clump pixels that touch at corners, while a \u2018plus\u2019 will only clump pixels that share a side."},{"location":"patterns/focal-operations/#object-area-from-clusters","title":"object area from clusters","text":"<p>This method calculates the area of distinct objects with a square (3x3 pixel) moving window. It is similar to the method described above, but differs in two ways:  </p> <ol> <li>It can only use a \u2018square\u2019 window (so pixels will be clustered if they touch on corners).</li> <li>It returns an image with only one band, named \u2018area\u2019, that stores the area (square meters) of the object in each pixel of the object.  </li> </ol> <p>It suffers from the same two quirks described above (limited size and changes with zoom level).</p> <p>Here is the basic pattern:</p> <pre><code>var object_area_clusters = geo.iFocal.objectAreaFromClusters(image, \"band\");\n</code></pre> <p>The table below describes the arguments.  </p> ARGUMENTS DESCRIPTION image An input image. \u201cband\u201d The band name with boolean or class values to cluster. <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/gather-raster-data/","title":"gather raster data","text":"<p>PATTERNS</p>"},{"location":"patterns/gather-raster-data/#gather-raster-data","title":"gather raster data","text":"<p>One of the first things you will usually do with Earth Engine is gather some data from the cloud. Before we get too deep into this, we should review the basic templates for storing geographic data (geographic data models) and how they are implemented in Earth Engine.     </p>"},{"location":"patterns/gather-raster-data/#raster-data-model","title":"raster data model","text":"<p>A raster stores geographic data with a grid of pixels. Each pixel, or cell in the grid, stores a value as a digital number. The data type defines the length of binary numbers used to store the digital number. In the diagram below, the values shown on the left can be stored as a 8 bit unsigned integer, or byte, data type shown on the right. </p> <p></p>"},{"location":"patterns/gather-raster-data/#image-data-object","title":"image data object","text":"<p>In Earth Engine, the raster model underlies the image data object, where an image is composed of one or more bands and each band is a raster.  </p> <p></p>"},{"location":"patterns/gather-raster-data/#accessing-images-from-cloud","title":"accessing images from cloud","text":"<p>The diagram below shows a typical pattern for accessing cloud data.</p> <p> <pre><code>\ngraph LR\n\n  step01(\"Construct from address\") ;\n  step02(\"Inspect data object\") ;\n\n  step01 --&gt; step02\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>The pattern is to first construct the object and then immediately inspect the properties of the object.  </p>"},{"location":"patterns/gather-raster-data/#construct-image-from-address","title":"construct image from address","text":"<p>Use the <code>ee.Image()</code> method to construct an image from the cloud. This method takes the address for the data asset as an argument.   </p> <p> <pre><code>graph LR\n  step02(\"ee.Image()\") ;\n  step03[/\"image\"/]  ;\n  arg01[\"'address/of/cloud/data'\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; \n</code></pre> <p></p> <p>To adapt the snippet below, you will just need to replace <code>'address/of/cloud/data'</code> with the data address. The address must be a string.  </p> <pre><code>var image = ee.Image('address/of/cloud/data');\n</code></pre>"},{"location":"patterns/gather-raster-data/#inspect-data-properties","title":"inspect data properties","text":"<p>After constructing or altering a data object, I usually want to quickly familiarize myself the properties of the data. To do this, use the <code>print()</code> method to print the properties of the data object to the Console.  </p> <pre><code>print(\n    \"A helpful label\",\n    image\n    )\n;\n</code></pre> <p>To adapt the snippet below, replace <code>\"A helpful label\"</code> with a label that describes the image you are working with. This label must be a string. As necessary, replace <code>image</code> in the following line with the name of the variable that contains the image data.  </p>"},{"location":"patterns/gather-raster-data/#full-pattern","title":"full pattern","text":"<p>Here are the two parts of the pattern together.</p> <pre><code>var image = ee.Image('address/of/cloud/data');\n\nprint(\n    \"A helpful label\",\n    image\n    )\n;\n</code></pre>"},{"location":"patterns/gather-raster-data/#image-management","title":"image management","text":"<p>These patterns deal with common data management tasks associated with images.  </p>"},{"location":"patterns/gather-raster-data/#compile-from-other-images","title":"compile from other images","text":"<p>You can compile a new image by bringing together one or more bands from other images. This can be helpful for making RGB composites, charts, and other workflows.  </p> <p>The general pattern starts with an image (named \u201cA\u201d below) and calls the <code>.addBands()</code> method to add bands from another image (\u201cB\u201d) to the output image.  </p> <pre><code>var output_image = A.addBands(B);\n\nprint(\"Image with added bands\", output_image);\n</code></pre> <p>To make an RGB composite, you will typically want to add bands from two other images. You can do this by chaining the pattern.</p> <pre><code>var rgb_stack = A.addBands(B).addBands(C);\n\nprint(\"RGB stack\", rgb_stack);\n</code></pre>"},{"location":"patterns/gather-raster-data/#rename-bands","title":"rename band(s)","text":"<p>This method will change the name of one or more bands in an image. The new band name must be a string in a list and the length of the list should match the number of bands in the image.   </p> <pre><code>var image_with_band_renamed = image.rename([\"new_band_name\"]);\n</code></pre>"},{"location":"patterns/gather-raster-data/#image-collection-data-object","title":"image collection data object","text":"<p>In Earth Engine, an image collection is what it sounds like: a collection of images. Earth Engine often uses these raster data objects to store satellite observations, because most satellites observe a region of the earth\u2019s surface (often called a scene) at a moment in time and then return to this scene at regular intervals to create a time series. In these cases, an image collection provides a way to store all the different scenes observed at all the different times by a satellite mission.    </p> <p>image forthcoming </p> <p>Image collections are also useful for storing high-resolution rasters as a set of small tiles, or images with relatively small geographic extent, that can be stitched together into larger images as needed. For example, Earth Engine will often store Lidar products and high resolution imagery as image collections. </p> <p></p>"},{"location":"patterns/gather-raster-data/#construct-from-address","title":"construct from address","text":"<p>Use the <code>ee.ImageCollection()</code> method to construct an image collection from the cloud. The method takes the cloud address as an argument.  </p> <p> <pre><code>graph LR\n  step02(\"ee.ImageCollection()\") ;\n  step03[/\"ic\"/]  ;\n  arg01[\"'address/of/cloud/data'\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; </code></pre> <p></p> <p>Here is the pattern in javascript:</p> <pre><code>var ic = ee.ImageCollection('address/of/cloud/data');\n</code></pre>"},{"location":"patterns/gather-raster-data/#inspect-data","title":"inspect data","text":"<p>After constructing an ic object, I tend to use a <code>print()</code> method to learn a couple things about the data.  </p> <pre><code>print(\n    \"------------------\",\n    \"collection\",\n    \"------------------\",\n    ic,                 // Consider commenting out this line to make script run faster.\n    \"------------------\",\n    \"size\",\n    \"------------------\",\n    ic.size(),          // Consider commenting out this line to make script run faster. \n    \"------------------\",\n    \"first image\",\n    \"------------------\",\n    ic.first(),\n    \"------------------\",\n    \"number of bands\",\n    \"------------------\",\n    ic.first().bandNames().length(),\n    \"------------------\",\n    \"band names\",\n    \"------------------\",\n    ic.first().bandNames()\n    )\n;\n</code></pre> <p>The <code>ic.size()</code> method tells me how many images the collection contains. If the collection is huge, this method can take a while to run, so often I will comment out this line after I have looked at the result to help make the script run faster on subsequent runs.  </p> <p>The <code>ic.first()</code> method tells me some details about the first image in the collection and usually the other images in the collection will have the same band names and property keys.  </p> <p>The <code>ic.first().bandNames().length()</code> method tells me how many bands the first image in the collection contains, while <code>ic.first().bandNames()</code> tells me the name of each band.  </p>"},{"location":"patterns/gather-raster-data/#inspectcollection-helper","title":"inspectCollection helper","text":"<p>It can be a pain to update the name of the image collection (ic) each time it is called in the snippet above. So if you would like to print all of the items shown above, you can just call this method from the geo module.  </p> <p><pre><code>geo.icGather.inspectCollection(label, ic);\n</code></pre> Please note that this method simply prints some metadata to the Console, so you cannot store it as a variable.  </p> <p>The method takes the following arguments.</p> ARGUMENT DESCRIPTION label A label to print to Console. Must be a string. ic Name of image collection to inspect."},{"location":"patterns/gather-raster-data/#select-bands","title":"select band(s)","text":"<p>Images in a collection may contain multiple bands and often you only need to work with data in a subset of these bands. The pattern below will select one band from each image.  </p> <pre><code>var select_band = ic.select(\"band_name\");\n</code></pre> <p>You can also select more than one band.  </p> <pre><code>var select_bands = ic.select(\"band_name\", \"band_name_2\");\n</code></pre> <p>And you can also rename one or more bands if you provide two lists. The first list identifies the bands to select and the second list defines new names for each band. The two lists must be the same length. </p> <pre><code>var select_bands = ic.select([\"band_name\", \"band_name_2\"], [\"new_band_name\", \"new_namd_name_2\"]);\n</code></pre>"},{"location":"patterns/gather-raster-data/#select-first-image-in-collection","title":"select first image in collection","text":"<p>This method will select the first image in the collection. It functions like a conversion tool, in the sense that the input is a collection and the output is an image.  </p> <pre><code>var select_first_image = ic.first();\n</code></pre>"},{"location":"patterns/gather-raster-data/#merge-collections","title":"merge collections","text":"<p>This pattern merges two collections. It takes a deck of cards and adds another deck of cards to it to make a tall stack. Use this method with some caution; if you merge two collections with different band names together, it will complicate filters and local operations.  </p> <pre><code>var output_merged = ic_A.merge(ic_B);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/gather-vector-data/","title":"gather vector data","text":"<p>PATTERNS</p>"},{"location":"patterns/gather-vector-data/#gather-vector-data","title":"gather vector data","text":"<p>Points and polylines and polygons, oh my.  </p> <p>more forthcoming </p>"},{"location":"patterns/gather-vector-data/#accessing-data-from-cloud","title":"accessing data from cloud","text":"<p>The general pattern for acquiring vector data from the cloud is quite similar to the one for raster data.   </p> <p> <pre><code>graph LR\n\n  step01(\"Construct from address\") ;\n  step02(\"Inspect data object\") ;\n\n  step01 --&gt; step02\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p>"},{"location":"patterns/gather-vector-data/#construct-fc-from-address","title":"construct fc from address","text":"<pre><code>var fc = ee.FeatureCollection(\"address/of/cloud/data\");\n</code></pre>"},{"location":"patterns/gather-vector-data/#inspect-data","title":"inspect data","text":"<p>Working with vector data in Earth Engine can be a little challenging because you never really get to see the data as a table. You can, however, try to piece together the basic structure of the table by asking a set of questions about the data with the <code>print()</code> method.   </p>"},{"location":"patterns/gather-vector-data/#how-many-rows-in-table","title":"how many rows in table?","text":"<p>This method will print the number of features in the collection to the Console, which is the same as the number of rows in a table. </p> <pre><code>print(\n  \"fc size\",\n  fc.size()\n);\n</code></pre> <p>It is often helpful to know how many features the collection contains at the start as a way to monitor the results of your filters in subsequent steps.  </p>"},{"location":"patterns/gather-vector-data/#what-is-first-row-of-table","title":"what is first row of table?","text":"<p>This method will print the first row of the table as a dictionary to the Console.  </p> <pre><code>print(\n  \"fc first row\",\n  fc.first()\n);\n</code></pre> <p>The keys of the dictionary are the column names of the table. The values in the dictionary are the values for the first row of the table. Often, the first row is arbitrary and you may not even know where this feature is in the world. But your goal here is to understand the data schema:  </p> <ul> <li>what are the column names that define the categories of attributes stored in the table?  </li> <li>what is the format of the column names and attribute values? Are they text or numbers? If text, are they all caps, title case, all lower?  </li> </ul> <p>This information is usually quite helpful when you need to filter the collection in subsequent steps.  </p>"},{"location":"patterns/gather-vector-data/#what-are-all-unique-values-of-a-target-column","title":"what are all unique values of a target column?","text":"<p>This method will print all the unique values for a target column that you specify with the \u201cproperty_name\u201d argument. You usually find the column name use the <code>fc.first()</code> method shown above.  </p> <pre><code>print(\n  \"FC unique values for target category\",\n  fc.aggregate_array('property_name').distinct().sort()\n);\n</code></pre> <p>This information usually facilitates filter by attribute methods. (I often copy and paste attributes from this list to avoid typos).     </p>"},{"location":"patterns/gather-vector-data/#full-pattern","title":"full pattern","text":"<p>Here is the full pattern for constructing and inspecting feature collections.  </p> <pre><code>// Gather fc data from address.\n\nvar fc = ee.FeatureCollection(\"address/of/cloud/data\");\n\n// Inspect the table.  \n\nprint(\n  \"FC NAME\",\n  \"number of rows:\",\n  fc.size(),\n  \"first row of table:\",\n  fc.first(),\n  \"unique values for target column:\",\n  fc.aggregate_array('column_name').distinct().sort()\n);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/javascript/","title":"javascript","text":"<p>PATTERNS</p>"},{"location":"patterns/javascript/#javascript","title":"JavaScript","text":"<p>Here are some basic patterns for writing in JavaScript.</p>"},{"location":"patterns/javascript/#comments","title":"comments","text":"<p>Use comments to explain your code.</p> <pre><code>// Line comments start with two forward slashes. Like this line. \n\n/* Multi-line comments start with a forward slash and a star,\nand end with a star and a forward slash. */ \n</code></pre>"},{"location":"patterns/javascript/#variables","title":"variables","text":"<p>Use variables to contain (hold, store) data. </p> <pre><code>// Write a statement using the keyword var.\n\nvar hello = 'Hello world';    \n\n// Statements should end in a semi-colon, or else the Code Editor complains.\n\nvar test = \"I feel incomplete...\"\n\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n// !! Variable names cannot contain spaces or - dashes - !!\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n// Use underscores to separate words in variable names.\n\nvar this_is_called_snake_case = 'Hello, snake!';\n\n// Or use capitalizations to separate words:\n\nvar thisIsCalledCamelCase = 'Hello, camel!';\n</code></pre>"},{"location":"patterns/javascript/#print-to-console","title":"print to console","text":"<p>Use print function to print contents of variables and objects to console. </p> <pre><code>// Use parenthesis to pass arguments to print function.  \n\nprint(hello);\n\n// Use commas to pass multiple arguments. \n\nprint('Print test', hello);\n</code></pre>"},{"location":"patterns/javascript/#strings","title":"strings","text":"<p>Use strings to store text (character strings). </p> <pre><code>// Use single quotes to define string.\n\nvar hello = 'Hello world!'  // This is a string. \n\n// You can also use double quotes to enclose string.\n\nvar obi_one = \"Hello there\";\n\n// Just do not mix them.\n\nvar cranky = \"Hello Newman';  // This will throw an error. You will need to match the quotation marks to fix it. \n</code></pre> <p>A string has a set of methods that work with that type of data.</p> <pre><code>// Use a period and parentheses to call a string method.\n\nprint(\n  hello,                  // Original object that contains a string.\n  hello.slice(0,2),       // Keep the first through third characters of the string.\n  hello.concat('!'),      // Add an exclamation point after the string.\n  hello.toUpperCase()     // Change the case to all upper. \n  )\n;\n</code></pre>"},{"location":"patterns/javascript/#numbers","title":"numbers","text":"<p>Use numbers to store numerical data. </p> <pre><code>// These are both numbers. \n\nvar integer = 12;\nvar decimal = 11.987654321;\n\nprint(integer, decimal);              // Print number variables to Console\n\n// You can call some number methods with dot notation.\n\nprint(decimal.toFixed(4));  \n\n// Or call Javascript Math method that take number object as argument.\n\nprint(Math.round(decimal));           // Round decimal number to integer.\nprint(Math.floor(decimal));           // Round decimal number DOWN to nearest integer.\nprint(Math.ceil(decimal));            // Round decimal number UP to nearest integer.\n</code></pre>"},{"location":"patterns/javascript/#lists","title":"lists","text":"<p>Use lists to store a set of data. </p> <pre><code>// Use square brackets to define a list.\n\nvar some_vt_towns = ['Middlebury', 'New Haven', 'Bristol'];\n\n// Use square brackets after lists to select items.\n\nprint(some_vt_towns, some_vt_towns[0]);\n\n// Call list methods with dot notation.  \n\nprint(some_vt_towns.reverse());\n</code></pre>"},{"location":"patterns/javascript/#dictionaries","title":"dictionaries","text":"<p>Use dictionaries to store keys and values. </p> <pre><code>// Use curly brackets (or braces) to define dictionaries.\n\nvar midd = {\n  \"name\": \"Middlebury\",  // Dictionaries are composed of key:value pairs.\n  \"pop_2010\": 8496,\n  \"pop_2020\": 9152\n};\n\nprint(\"Middlebury\", midd);\n\n// Use dot notation to call the value(s) of a key.\n\nprint(midd.name);\n</code></pre>"},{"location":"patterns/javascript/#functions","title":"functions","text":"<p>Write functions to make chunks of code reuseable. </p> <pre><code>// A simple function the takes a string as an argument.  \n\nvar i_love_function = function(some_string) {\n  return 'I love '.concat(some_string).concat('!');\n};\n\nprint(i_love_function('maps'));\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/local-operations/","title":"local operations","text":"<p>PATTERNS</p>"},{"location":"patterns/local-operations/#local-operations","title":"local operations","text":"<p>Local overlay methods compare values at pixels in one or more rasters.    </p> <p></p>"},{"location":"patterns/local-operations/#masks","title":"masks","text":"<p>Masks act like masking tape when you paint. When you mask pixels in a raster before displaying the raster as a map layer, all the pixels with the mask will remain transparent (they will not be displayed with a color). Similarly, when you mask pixels of an input raster in an operation, the masked pixels will be excluded from the computation.  </p> <p>Typically, workflows with masks involve three steps.    </p> <p> <pre><code>graph LR\n  step01(\"Make mask\")\n  step02(\"Apply mask\") ;\n  step03(\"Paint (display as layer)\") ;\n  step04(\"Transform (input in operation)\") ;\n\n\n  step01 --&gt; step02\n  step02 --&gt; step03\n  step02 --&gt; step04\n\n\n  classDef steps fill:#C9C3E6,stroke-width:1px,stroke: #00000000, color:#000000; \n\n\n\n  class step01 steps; \n  class step02 steps;\n  class step03 steps;\n  class step04 steps; </code></pre> <p></p>"},{"location":"patterns/local-operations/#mask-pixels","title":"mask pixels","text":"<p>This pattern uses another raster, typically a Boolean raster as a mask on another raster. </p> <p>Any pixel with the value 0 in the mask acts like masking tape and prevents numbers in the output raster from being painted at that location. Masked values will not be displayed with colors when you place the raster layer on a Map. Masked values in an input raster will also be ignored in any subsequent operation.    </p> <p></p> <p> <pre><code>graph LR\n  input[image]\n  method(\".updateMask()\") ;\n  output[/\"image_with_mask\"/]  ;\n  arg01[\"mask&lt;br&gt;boolean_raster\"] ;\n\n  input --&gt; method\n  method --&gt; output\n  arg01 --o method\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg01 arg; </code></pre> <p></p> <pre><code>var image_with_mask = image.updateMask(boolean_image);\n</code></pre>"},{"location":"patterns/local-operations/#self-mask-pixels","title":"self mask pixels","text":"<p>If you want to ignore pixels that store the value 0 in an raster, you can self-mask. This is not technically a local operation because it only involves one raster, but I wanted to keep the mask operations together. </p> <p></p> <p> <pre><code>graph LR\n  input[image]\n  method(\".selfMask()\") ;\n  output[/\"image_with_mask\"/]  ;\n\n  input --&gt; method\n  method --&gt; output\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;</code></pre> <p></p> <pre><code>var image_with_mask = image.selfMask();\n</code></pre>"},{"location":"patterns/local-operations/#unmask","title":"unmask","text":"<p>If you are working with a masked image, you can remove the mask and populate all the masked locations with a constant. Again, this is not technically a local operation because it only involves one raster, but I wanted to keep the mask operations together. </p> <p></p> <p> <pre><code>graph LR\n  input[\"image_with_mask\"]\n  method(\".unmask()\") ;\n  output[/\"image_without_mask\"/]  ;\n  arg[\"constant\"]\n\n  input --&gt; method\n  method --&gt; output\n  arg --o method  \n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg</code></pre> <p></p> <pre><code>var image_without_mask = image_with_mask.unmask();\n</code></pre> <p>In Earth Engine, <code>unmask()</code> will replace masked values with 0 by default (This makes the method the inverse of <code>selfMask()</code>. You can include an argument (a number in the parantheses) to specify a different constant.   </p>"},{"location":"patterns/local-operations/#logical-comparisons","title":"logical comparisons","text":"<p>The diagram below illustrates three common logical comparisons between two regions: A, B. Going from left to right, the first picture shows the two regions. The second picture shows where either region A or region B are present (or true), called the union of the two. The third picture shows where both region A and region B are present, called the intersection of the two. The fourth and final picture shows where region A is present but not region B. In this last case, region B acts like an eraser or knife that cuts out the portion of region A that it touches. Sometimes this last case is called the difference or subtraction of two sets.    </p> <p></p> <p>The patterns below describe how each logical comparison shown above can be implemented with raster data models.  </p>"},{"location":"patterns/local-operations/#union","title":"union","text":"<p>The <code>.or()</code> method takes two rasters as inputs and kicks out a boolean raster that represents their union: pixels in the output raster are true if they are true (not 0) in either raster A or raster B.  </p> <p></p> <p>The inputs are commonly boolean rasters, as illustrated in the above diagram, but the method will work with nominal (class) data, returning a boolean raster.  </p> <p></p> <p>The order of the inputs (which raster is image_A versus image_B) does not really matter. The main thing to remember here is that any masked pixels will be excluded from this operation. So it is good practice to triple-check your inputs to see if you are using a mask on pixels that should be zeros so that you do not inadvertently erase locations that are true in one layer but masked in another.  </p> <pre><code>var image_union = image_A.or(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#intersection","title":"intersection","text":"<p>The <code>and()</code> method takes two rasters as inputs and kicks out a boolean raster that represents their intersection: pixels in the output raster are true (not 0) if they are true (not zero) in both raster A and raster B.  </p> <p></p> <p>Like the <code>or</code> operation, the inputs are commonly boolean rasters, but the method will work with nominal (class) data, returning a boolean raster as shown below.  </p> <p></p> <p>The order of inputs again does not really matter here. And because this operation is like a knife that cuts and alters the shapes of inputs, this method is less sensitive to masks, unlike the <code>or()</code> method.</p> <pre><code>var image_intersection = image_A.and(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#not","title":"not","text":"<p>In Earth Engine, finding locations that are in raster A but not in raster B is a little tricky. The workflow involves inverting the binary of raster_B and then multiplying it against raster_A.   </p> <p></p> <pre><code>var image_A_not_B = image_A.multiply(image_B_inverted_binary);\n</code></pre>"},{"location":"patterns/local-operations/#map-arithmetic","title":"map arithmetic","text":"<p>As the diagram at the top of this page illustrates, a common type of local overlay operation performs arithmetic operations (addition, subtraction, multiplication, and division) with two rasters.  </p>"},{"location":"patterns/local-operations/#addition","title":"addition","text":"<p>The <code>.add()</code> method performs addition between values in corresponding pixels of two rasters. The order (which raster is A versus B) does not matter. The main thing to remember is that any pixel that is masked will be excluded from the operation (so that output pixel will remain masked).  </p> <p></p> <pre><code>var image_A_add_B = image_A.add(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#subtraction","title":"subtraction","text":"<p>The <code>.subtract()</code> method performs subtraction between values in corresponding pixels of two rasters. The order matters here: you subtract image_B from image_A. Masked pixels in either raster will remain masked in the output.  </p> <p></p> <pre><code>var image_A_subtract_B = image_A.subtract(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#multiplication","title":"multiplication","text":"<p>The <code>.multiply()</code> method performs multiplication between values in corresponding pixels of two rasters. The order does not matter here. Masked pixels do matter and will remain masked. </p> <p>Multiplication is often used with a boolean raster as a method to erase values in another image, because 0 will convert to 0 and 1 will retain the original value.   </p> <p></p> <pre><code>var image_A_subtract_B = image_A.multiply(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#division","title":"division","text":"<p>The <code>.divide()</code> method performs division between values in corresponding pixels of the two rasters. The order does matter here because you divide the values in image_A by the values in image_B. Masked pixels in either image again remain masked in the output.  </p> <p></p> <pre><code>var image_A_divide_B = image_A.divide(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#spectral-indices","title":"spectral indices","text":"<p>Spectral indices are derived from local operations that compare values in two or more spectral bands. There are many, many different indices. Below I describe two indices that we will use in tutorial 9 and problem 9.  </p>"},{"location":"patterns/local-operations/#ndvi","title":"NDVI","text":"<p>The normalized difference vegetation index (NDVI) is a measure of the health of vegetation. It is calculated by comparing reflectance of near infrared (NIR) light and red light.  </p> <p> </p> <p>This takes advantage of the difference in the spectral signatures of healthy versus stressed or dead vegetation; specifically, healthy vegetation will have higher reflectance in the NIR band due to cell structure and lower reflectance in red bands due to absorption by chlorophyll.  </p> <p></p> <p>NDVI values will range from -1 to 1. Although results will vary by region, year, and instrument, here are some ballpark numbers to help interpret NDVI values:  </p> <ul> <li>0 or less: water </li> <li>0 - 0.15: impervious surfaces, rock, sand, or snow  </li> <li>0.15 - 0.33: sparse and/or stressed vegetation  </li> <li>0.33 - 0.66: moderatly healthy vegetation</li> <li>0.66 - 1: dense and/or healthy vegetation</li> </ul>"},{"location":"patterns/local-operations/#nbr","title":"NBR","text":"<p>The normalized burn ratio (NBR) is a measure of the severity of a fire. It is calculated by comparing reflectance of near infrared (NIR) and shortwave infrared (SWIR) light. </p> <p> </p> <p>source</p> <p>This takes advantage of differences in the spectral signatures of healthy and burned vegetation.</p> <p></p>"},{"location":"patterns/local-operations/#awesome-spectral-indices-module","title":"awesome spectral indices module","text":"<p>Although you can compute most spectral indices from scratch in Earth Engine, I appreciate using a module developed by Dave Montero Loaiza that is\u2026 pretty\u2026 awesome.  </p> <p>Here are the steps for using his module.  </p>"},{"location":"patterns/local-operations/#load-module","title":"load module","text":"<pre><code>// ------------------------------------------------------------------------\n//  Load spectral indices module.  \n// ------------------------------------------------------------------------\n\nvar spectral = require(\"users/dmlmont/spectral:spectral\");\n\nprint(\n  \"SPECTRAL INDICES\", \n  spectral.indices\n);\n</code></pre>"},{"location":"patterns/local-operations/#define-parameters","title":"define parameters","text":"<p>This will depend on which data product you are using from the Earth Engine Data catalog and based on this table from Dave\u2019s github docs.   </p> <p>Please note: this pattern is set up to work directly from the image starter scripts for Landsat and Sentinel. That is why the input image is called <code>output</code>. If you are trying to compare indices at two different snapshots in time, you may have changed the name of your image and will need to insert a line that temporarily renames your image. Otherwise EE will likely throw a \u201cLine ###: output is not defined\u201d error message.  </p> <pre><code>// Temporarily rename the input image to work with pattern.\n\nvar output = target_input;  // Change \"target_input\" to the name of image you want to use as the input. \n</code></pre>"},{"location":"patterns/local-operations/#l5-l7","title":"L5 &amp; L7","text":"<p>For Landsat 5 or 7 Surface Reflectance, use this pattern:</p> <pre><code>// ------------------------------------------------------------------------\n//  Define parameters for Landsat 5 or 7 Surface Reflectance. \n// ------------------------------------------------------------------------\n\nvar parameters = {\n    \"B\": output.select(\"SR_B1\"),\n    \"G\": output.select(\"SR_B2\"),\n    \"R\": output.select(\"SR_B3\"),\n    \"N\": output.select(\"SR_B4\"),\n    \"S1\": output.select(\"SR_B5\"),\n    \"S2\": output.select(\"SR_B7\"),\n    \"T\": output.select(\"SR_B6\")\n};\n</code></pre>"},{"location":"patterns/local-operations/#l8-l9","title":"L8 &amp; L9","text":"<p>For Landsat 8 or 9, use this pattern:</p> <pre><code>// ------------------------------------------------------------------------\n//  Define parameters for Landsat 8 or 9 Surface Reflectance. \n// ------------------------------------------------------------------------\n\nvar parameters = {\n    \"A\": output.select(\"SR_B1\"),\n    \"B\": output.select(\"SR_B2\"),\n    \"G\": output.select(\"SR_B3\"),\n    \"R\": output.select(\"SR_B4\"),\n    \"N\": output.select(\"SR_B5\"),\n    \"S1\": output.select(\"SR_B6\"),\n    \"S2\": output.select(\"SR_B7\"),\n    \"T1\": output.select(\"SR_B10\"),\n    \"T2\": output.select(\"SR_B11\")\n};\n</code></pre>"},{"location":"patterns/local-operations/#s2","title":"S2","text":"<p>For Sentinel 2, use this pattern:</p> <pre><code>// ------------------------------------------------------------------------\n//  Define parameters for Sentinel 2 Surface Reflectance. \n// ------------------------------------------------------------------------\n\nvar parameters = {\n    \"A\": output.select(\"B1\"),\n    \"B\": output.select(\"B2\"),\n    \"G\": output.select(\"B3\"),\n    \"R\": output.select(\"B4\"),\n    \"RE1\": output.select(\"B5\"),\n    \"RE2\": output.select(\"B6\"),\n    \"RE3\": output.select(\"B7\"),\n    \"N\": output.select(\"B8\"),\n    \"N2\": output.select(\"B8A\"),\n    \"WV\": output.select(\"B9\"),\n    \"S1\": output.select(\"B11\"),\n    \"S2\": output.select(\"B12\")\n};\n</code></pre>"},{"location":"patterns/local-operations/#compute-spectral-indices","title":"compute spectral indices","text":"<p>You can compute one or more indices with this pattern. This example computes NDVI, NBR, and MNDWI. Each index will be stored as a new band in the output image.  </p> <pre><code>// ------------------------------------------------------------------------\n//  Compute spectral index or indices.\n// ------------------------------------------------------------------------\n\nvar output_si = spectral.computeIndex(output,[\"NDVI\", \"NBR\"], parameters);\n\nprint(\n  \"IMAGE WITH SPECTRAL INDICES\",\n  output_si);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/map-raster-layers/","title":"map raster as layers","text":"<p>PATTERNS</p>"},{"location":"patterns/map-raster-layers/#map-raster-layers","title":"map raster layers","text":"<p>Any geographic information system will provide methods for displaying data as a map layer.  </p> <p>To understand these patterns, it will be helpful to review some basic concepts of data visualization.  </p>"},{"location":"patterns/map-raster-layers/#data-values-vs-display-values","title":"data values vs. display values","text":"<p>When you visualize data, you map data values to display values. Two things often happen by default:  </p> <ol> <li>The data type of the digital numbers defines the range of values that get mapped to the display values.</li> <li>The relationship between data values and display values is linear.  </li> </ol> <p></p> <p>The reason that the displayed values in the example above have such poor contrast is a result of the mismatch between the possible data values defined by the data type and the actual data values stored in the raster.  </p> <p>A histogram is one way to compare the possible and actual data values of a raster. </p> <p></p> <p>A common strategy to improve the contrast of an image is to stretch the display values over the range of actual data values by setting the linear map to begin and end at the minimum and maximum actual data value, respectively. This is usually called stretch enhancement.   </p> <p></p>"},{"location":"patterns/map-raster-layers/#display-image-as-layer","title":"display image as layer","text":"<p>The diagram below shows a general pattern to display an image as a map layer with Earth Engine. The first two tasks \u2013 print min &amp; max value and chart histogram \u2013 are methods to identify the range of actual data values in the image and how they are distributed, respectively. The middle task \u2013 define viz dictionary \u2013 is a method for storing the min and max values for stretch enhancements. The last task \u2013 display data as map layer \u2013 draws the result on the Map.  </p> <p> <pre><code>graph LR\n\n  step01(\"Print min &amp; max value\") ;\n  step02(\"Chart histogram\") ;\n  step03(\"Define viz dictionary\")  ;\n  step04(\"display data as map layer\") ;\n\n  step01 --&gt; step03 \n  step02 --&gt; step03 \n  step03 --&gt; step04\n\n  classDef task fill:#C3D3E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n  class step03 task;\n  class step04 task;\n</code></pre> <p></p>"},{"location":"patterns/map-raster-layers/#print-min-max-value-of-image","title":"print min &amp; max value of image","text":"<p>Print the min and max data value of a raster image to use as min and max values in viz dictionary.   </p> <pre><code>var output_min_max = geo.iCart.iMinMax(image, scale, aoi);\n\nprint(\"Min &amp; max value of image\", output_min_max);\n</code></pre> ARGUMENT DESCRIPTION image The name of the variable that contains the image data to process. scale The scale of analysis. If possible, use the scale (resolution) of the input image. If this runs really slow (or times out), then increase the scale of analysis by a factor of 2 or more. aoi The area of interest or the geographic footprint of the image."},{"location":"patterns/map-raster-layers/#chart-histogram-of-data-values","title":"chart histogram of data values","text":"<p>See how your data are distributed between the minimum and maximum data value by charting a histogram.</p> <pre><code>var output_histogram = geo.iCart.iHistogram(image, scale, aoi);\n\nprint(\"Image histogram\", output_histogram);\n</code></pre> ARGUMENT DESCRIPTION input_image The name of the variable that contains the image data to process. scale The scale of analysis. If possible, use the scale (resolution) of the input image. If this runs really slow (or times out), then increase the scale of analysis by a factor of 2 or more. aoi An area of interest or the geographic footprint of the image."},{"location":"patterns/map-raster-layers/#histogram-for-spectral-indices","title":"histogram for spectral indices","text":"<p>Many spectral indices, particularly normalized difference indices, will output results that range from -1 to 1. However, there are often some pixels that for various reasons lie outside this range in either direction. To chart a histogram for these images, you will need to adapt the pattern above by placing a <code>.clamp()</code> on the image. </p> <pre><code>var output_histogram = geo.iCart.iHistogram(image.clamp(-1, 1), scale, aoi);\n\nprint(\"Image histogram\", output_histogram);\n</code></pre> <p>The clamp method has two arguments (min, max) and redefines the range of values in the image so that they all fall within this range. (For this reason, you will generally see \u2018bookends\u2019 on either side of a histogram charted from a clamped image.)  </p>"},{"location":"patterns/map-raster-layers/#get-aoi-from-map-extent","title":"get AOI from Map extent","text":"<p>If you are working with a global dataset or an image that has been flattened from a collection, the chart histogram pattern will likely throw errors and tell you it cannot work on an unbounded image. You can work around this with the helper below from the geo module. It will retrieve an area of interest (AOI) from the current geographic extent of the Map window.  </p> <pre><code>var aoi = geo.uiMap.getAOIfromMapExtent();\n</code></pre>"},{"location":"patterns/map-raster-layers/#get-nominal-scale-helper","title":"get Nominal scale helper","text":"<p>Sometimes you may be working with an image and realize that you do not know the native image scale. The helper below from the geo module will retrieve the nominal scale of the image. This is the scale at the equator of the image dataset and should be interpreted with some caution, but it can be helpful as a starting point for defining the scale for the <code>geo.iCart.iHistogram()</code> and <code>geo.iCart.iMinMax()</code> methods described above.  </p> <pre><code>var scale = geo.iCart.getNominalScaleFromImage(image);\n\nprint(\"IMAGE SCALE\", scale);\n</code></pre>"},{"location":"patterns/map-raster-layers/#define-raster-viz-dictionary","title":"define raster viz dictionary","text":"<p>For raster data, store the viz dictionary as a variable and then call this variable when you add the map layer. </p> <p>Here is a common pattern to visualize single-band images with grayscale:</p> <pre><code>var single_viz = \n    {\n        min: [],        \n        max: [],        \n    }\n;\n</code></pre> <p>Here is a common pattern to visualize single-band images with color (this includes both color gradient layers and nominal layers where a unique color displays each unique class):</p> <pre><code>var single_viz = \n    {\n        min: [],        \n        max: [],        \n        palette: [],    \n    }\n;\n</code></pre> <p>If your image data represents nominal data with integers, you can quickly visualize this data with random colors using the <code>.randomVisualizer()</code> method on the image and calling an empty dictionary for the viz parameters.    </p> <pre><code>Map.addLayer(image.randomVisualizer(), {}, \"Nominal Classes\");\n</code></pre> <p>This pattern is most useful for quick visualizations, when the color used to display the class does not matter too much. If you want to be able to control which color displays each class, then you should use the single band image with color pattern described earlier and make sure that the length (number of) integer values in your class set equals the length of colors in your palette.   </p>"},{"location":"patterns/map-raster-layers/#add-map-layer","title":"add map layer","text":"<p><code>Map.addLayer()</code> method will display data as a map layer.    </p> <pre><code>Map.addLayer(data,viz,\"Layer Name\",show,opacity);\n</code></pre> <p>The <code>Map.addLayer()</code> method takes the following arguments: </p> ARGUMENT DESCRIPTION data The name of the variable that contains the data that you wish to display. viz The viz dictionary that defines how to visualize (display) the data. layer name A string that provides a label for the data in the list of layers. show A boolean argument to control whether or not the layer is displayed when first loaded. opacity A decimal number between 0 and 1 to adjust the opacity of the layer."},{"location":"patterns/map-raster-layers/#complete-pattern","title":"complete pattern","text":"<p>Here is a complete pattern for the simple case of single-band grayscale images.</p> <pre><code>// Print min and max values of image. \n\nprint(\"Min &amp; max value of image\", geo.iCart.iMinMax(image, scale, aoi));\n\n// Chart histogram of actual data values.\n\nprint(\"Image histogram\", geo.iCart.iHistogram(image, scale, aoi));\n\n// Define viz dictionary. \n\nvar single_viz = \n    {\n        min: [],        \n        max: [],        \n    }\n;\n\n// Add map layer. \n\nMap.addLayer(image,single_viz,\"Layer Name\");\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/map-vector-layers/","title":"map vector as layers","text":"<p>PATTERNS</p>"},{"location":"patterns/map-vector-layers/#map-vector-layers","title":"map vector layers","text":"<p>Earth Engine is primarily a tool for visualizing raster data. This means two things:  </p> <ul> <li>you can choose a color to display vector data, but not much else;</li> <li>if you want to control more than just the color, you will need to convert your vector data into an image. </li> </ul>"},{"location":"patterns/map-vector-layers/#simple-viz-with-color","title":"simple viz with color","text":"<p>Similar to raster data, you use the <code>Map.addLayer()</code> method to display a feature collection as a map layer. This method takes the same five data objects described previously, but the viz dictionary here is much simpler: it can only contain a <code>color</code> key. Because of this, I usually write the dictionary directly into the statement.    </p> <pre><code>Map.addLayer(fc, {color: 'white'}, \"Layer Name\");\n</code></pre>"},{"location":"patterns/map-vector-layers/#paint-strokes-without-fill","title":"paint strokes without fill","text":"<p>Sometimes it is helpful to draw just the outlines (strokes) of features on a map, leaving the fills (interiors) completely transparent. This is particularly helpful with cadastre (property) lines and other boundaries of human geography.  </p> <p>The method below allows you to paint the strokes of features in a collection with a color and weight (thickness) of your choice and store the output as an RGB image. (An RGB image has three bands that combine to make colors).  </p> <p>You can then add the rgb image to the map as a layer, using empty curly brackets <code>{}</code> as a placeholder for the viz dictionary. You do not need to define the viz parameters because the data type is a byte (0-255) and Earth Engine will display the three bands (red, green, blue) correctly by default.  </p> <pre><code>var strokes = geo.fcCart.paintStrokes(fc, \"white\", 0.5);\n\nMap.addLayer(strokes, {}, \"Feature outlines\");\n</code></pre> <p>If you then add the <code>strokes</code> layer on top of the other layers on the Map, you will be able to see the underlying layer through the transparent interiors of the features in the collection.  </p>"},{"location":"patterns/map-vector-layers/#paint-nominal-values-with-colors","title":"paint nominal values with colors","text":"<p>If you have a feature collection with nominal data (classes, categories) and you would like to display each class with a unique color, then this pattern should work:</p> <p> <pre><code>graph LR\n\n  step01(\"Convert fc to nominal image\") ;\n  step02(\"Display image as layer\") ;\n\n  step01 --&gt; step02\n\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000 ;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/proximity-operations/","title":"proximity operations","text":"<p>PATTERNS</p>"},{"location":"patterns/proximity-operations/#proximity-operations","title":"proximity operations","text":"<p>Proximity operations concern questions of distance, how near (or far) places are from each other.  </p> <p>more soon </p>"},{"location":"patterns/proximity-operations/#a-short-illustration","title":"a short illustration","text":"<p>I find the proximity methods in earth engine to be a little confusing, so I made the app below to illustrate how some important concepts. The text below walks you through how to build the map layers in the app. </p> <p> </p> <p>open app in new tab</p>"},{"location":"patterns/proximity-operations/#00-start-a-script","title":"00 start a script","text":"<p>This workflow draws on methods in the geo module, so you will need to load that module after you write a script header. </p> <pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   Jeff Howarth   \n    DATE:     10/7/2024  \n    TITLE:    On distance with web mercator\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n</code></pre>"},{"location":"patterns/proximity-operations/#01-proximity-with-vector","title":"01 proximity with vector","text":"<p>The first part of the script demonstrates proximity methods with vector. We start by constructing and drawing a test point in the center of Youngman\u2019s Field. </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. Proximity with vector. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Gather Test point\n// -------------------------------------------------------------\n\nvar test_point = ee.FeatureCollection(\"projects/ee-patterns/assets/t05/youngman_center\");\n\n// -------------------------------------------------------------\n//  1.2 Set Map center, zoom, and base layer. \n// -------------------------------------------------------------\n\nMap.centerObject(test_point, 19);\nMap.setOptions('HYBRID');\n\n// -------------------------------------------------------------\n//  1.3 Add test point layer. \n// -------------------------------------------------------------\n\nMap.addLayer(test_point, {color: 'yellow'}, \"1.3 Test Point\", false);\n</code></pre> <p>We then use the vector tool <code>geo.fcProximity.bufferByDistance()</code> to buffer the point by 50 yards and add the result as a layer to the Map.  </p> <pre><code>// -------------------------------------------------------------\n//  1.4 Buffer the point by 50 yards (45.72 meters)\n// -------------------------------------------------------------\n\nvar d = 45.72;\n\nvar test_buffer = geo.fcProximity.bufferByDistance(test_point, d);\n\n// -------------------------------------------------------------\n//  1.5 Add layer to Map.\n// -------------------------------------------------------------\n\nMap.addLayer(test_buffer, {color: \"red\"}, \"1.3 Test vector buffer 50 yards\", false);\n</code></pre> <p>Notice how the buffer lines up pretty well with the goal lines that are 50 yards from center field.   </p>"},{"location":"patterns/proximity-operations/#02-proximity-with-raster","title":"02 proximity with raster","text":"<p>Now we can try to reproduce this simple buffer using raster methods. The first step involves converting the test point feature collection to a boolean image and displaying the result as a Map layer.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. Proximity with raster.\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n// 2.1 Convert test point to a Boolean image.\n// -------------------------------------------------------------\n\nvar image_boolean_test = geo.fcConvert.toBooleanImage(test_point);\n\n// -------------------------------------------------------------\n// 2.2 Display test point image. \n// -------------------------------------------------------------\n\nMap.addLayer(image_boolean_test, {min:0, max:1}, \"2.2 Test point Image\", false);\n</code></pre> <p>The next step is to use <code>geo.iFocal.iDistance()</code> to calculate the euclidean distance from all non-zero pixels in the test point image. At this point, we will use the coordinate reference system for web mercator. </p> <pre><code>// -------------------------------------------------------------\n//  2.3. Calculate euclidean distance from test point.\n// -------------------------------------------------------------\n\nvar crs = \"EPSG: 3857\";  // web mercator\n\nvar distance_image_test = geo.iFocal.iDistance(image_boolean_test, d, crs, \"euclidean\", \"pixels\");\n\n// -------------------------------------------------------------\n//  2.4. Define viz parameters\n// -------------------------------------------------------------\n\nvar viz_euc = {min:0, max: d, palette: geo.iPalettes.iDistance.inferno.reverse()};\n\n// -------------------------------------------------------------\n//  2.5. Display euclidean distance as layer on Map.\n// -------------------------------------------------------------\n\nMap.addLayer(distance_image_test,  viz_euc, \"2.5 Euc distance\", false);\n</code></pre> <p>In a last step, we can create a raster version of a buffer by applying a threshold of 50 yards to the distance image that results in a Boolean image. And then add this result to the Map as a layer.   </p> <pre><code>// -------------------------------------------------------------\n// 2.6 Threshold euclidean distance image at 50 yards. \n// -------------------------------------------------------------\n\nvar distance_image_test_threshold = distance_image_test.lte(d).selfMask();\n\n// -------------------------------------------------------------\n// 2.7 Add threshold image as layer to Map. \n// -------------------------------------------------------------\n\nMap.addLayer(distance_image_test_threshold, {min:0, max:1}, '2.7 Threshold Distance at 50 Yards', false);\n</code></pre>"},{"location":"patterns/proximity-operations/#reflection","title":"reflection","text":"<p>You just made a 50 yard buffer around a point in the center of Youngman Field with vector and raster methods. How do they differ? What do you think causes their difference?  </p>"},{"location":"patterns/proximity-operations/#03-crs-matters","title":"03 crs matters","text":"<p>Go back to section 2.3 and replace the crs variable with this:</p> <pre><code>var crs = \"EPSG: 32145\";    // VT State Plane (NAD83)\n</code></pre> <p>Then run your script and compare the results to the vector method. Why do you think crs matters for raster proximity methods? Do they also matter for vector methods?  </p>"},{"location":"patterns/proximity-operations/#vector-methods","title":"vector methods","text":""},{"location":"patterns/proximity-operations/#buffer-by-distance","title":"buffer by distance","text":"<p>This method takes a feature collection and distance (in meters) as arguments. The result is a buffer around each feature in the collection; the buffer defines the zone that is within the specified distance to each feature in the collection.  </p> <pre><code>var fc_buffer = geo.fcProximity.bufferByDistance(fc, distance);\n</code></pre>"},{"location":"patterns/proximity-operations/#raster-methods","title":"raster methods","text":""},{"location":"patterns/proximity-operations/#make-distance-raster","title":"make distance raster","text":"<p>This method makes an image that represents the distance of each pixel from all non-zero (and unmasked) pixels in the input image. </p> <pre><code>var crs = \"EPSG: 32145\";    // VT State Plane (NAD83)\n\nvar image_distance = geo.iFocal.iDistance(image_input, radius, crs, \"model\", \"units\");\n</code></pre> <p>The method takes four arguments:  </p> ARGUMENT DESCRIPTION image_input Input image to calculate distance to all non-zero but unmasked cells. Often a boolean or an object image. radius The radius of the distance kernel. This defines the size of the moving window used to calculate distance. It can not be greater than 255. crs A coordinate reference system as a string that provides the EPSG definition. \u201cmodel\u201d Defines the model of distance employed. Must be a string and one of the following: \u201ceuclidean\u201d, \u201cmanhattan\u201d, \u201cchebyshev\u201d. \u201cunits\u201d Defines the system of measurement for the distance kernel, either \u201cpixels\u201d or \u201cmeters\u201d. Must be a string. <p></p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"patterns/reclassify/","title":"reclassify raster","text":"<p>PATTERNS</p>"},{"location":"patterns/reclassify/#reclassify-raster","title":"reclassify raster","text":"<p>These methods purposefully reclassify the values in a raster. </p>"},{"location":"patterns/reclassify/#boolean-raster","title":"Boolean raster","text":"<p>This pattern asks a true or false question about each value in the input raster and returns a 1 if true and 0 if false in the corresponding pixel of the output raster.   </p> <p></p> <p> <pre><code>graph LR\n  input[image]\n  method(\".gt()\") ;\n  output[/\"image_boolean\"/]  ;\n  arg1[\"number\"]  ;\n\n  input --&gt; method\n  method --&gt; output\n  arg1 --o method\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg1 arg;</code></pre> <p></p> <pre><code>var image_boolean = image.gt(number);  \n</code></pre> <p>The table below lists some of the common methods to ask true or false questions about a raster. Each takes a number as an argument. Some technical folks will use the verb threshold to describe methods that use greater than or less than methods to produce boolean rasters.  </p> <p> METHOD DESCRIPTION <code>.eq()</code>, <code>.neq()</code> Equal to, not equal to <code>.gt()</code> <code>.gte()</code> Greater than, greater than or equal to <code>.lt()</code> <code>.lte()</code> Less than, less than or equal to <p></p>"},{"location":"patterns/reclassify/#reclassify-by-defined-breaks","title":"Reclassify by defined breaks","text":"<p>This method reclassifies values in the input raster based on user-defined breaks. This is useful when the input values represent a field model and when the intervals between breaks are not equal.  </p> <p>The workflow can be a little confusing, but the basic idea is that you are using two or more threshold values to define a correspond set of boolean rasters that you then add together. The workflow below assumes that you are storing your thresholds as a list with two items.  </p> <p> <pre><code>graph LR\n  input[input]\n  method(\".gte()\") ;\n  output[/\"image_boolean\"/]  ;\n  arg1[\"threshold[0]\"]  ;\n\n  arg1 --o method\n  input --&gt; method\n  method --&gt; output\n\n  method2(\".gte()\") ;\n  output2[/\"image_boolean\"/]  ;\n  arg2[\"threshold[1]\"]  ;\n\n  input --&gt; method2\n  method2 --&gt; output2\n  arg2 --o method2\n\n  method3(\".add()\") ;\n  output3[\"output_reclass\"]\n\n  output --&gt; method3 \n  output2 --&gt; method3\n  method3 --&gt; output3\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg1 arg;\n\n  class method2 op;\n  class output2 in-out;\n  class arg2 arg;\n\n  class method3 op;\n  class output3 in-out;\n\n</code></pre> <p></p> <p>The figure below illustrates this workflow for a simple example that reclassifies an input raster (left) with two defined breaks: 0 and 2.  </p> <p></p> <p>The code snippet below shows the pattern for EE with javascript. The first step isolates the band in the image to reclassify. The second step defines the breaks as a list of thresholds. The third step chains together the workflow illustrated in the flowchart and diagram above. Notice that the <code>.gte()</code> argument calls an item from the threshold list, where <code>threshold[0]</code> is the first item in the list and <code>threshold[1]</code> is the second item.   </p> <pre><code>// ------------------------------------------------------------------------\n//  Reclassify by defined breaks. \n// ------------------------------------------------------------------------\n\n// Isolate band if necessary\n\nvar output = input.select(\"band_name\");\n\n// Define thresholds to reclassify a raster.\n\nvar thresholds = [0, 2];\n\n// Make binaries for each threshold and add together. \n\nvar output_reclassed = output.gte(thresholds[0])\n  .add(output.gte(thresholds[1]))\n;\n</code></pre> <p>The output raster will contain three values as follows:</p> NEW VALUE FROM OLD VALUE TO OLD VALUE 0 min value in raster just less than 0 1 0 just less than 2 2 2 max value in raster <p>To add additional breaks, you will need to:  </p> <ol> <li>add one or more values to the list of thresholds,  </li> <li>add a corresponding number of <code>.add(output.gte(thresholds[#]))</code> lines to the routine.    </li> </ol> <p>For example, the pattern below uses four preliminary thresholds that are often applied to NDVI images. The result will be an image with five classes that range from 0 to 4.  </p> <pre><code>// ------------------------------------------------------------------------\n//  Reclassify by defined breaks. \n// ------------------------------------------------------------------------\n\n// Isolate band if necessary\n\nvar output = input.select(\"band_name\");\n\n// Define thresholds to reclassify a raster.\n\nvar thresholds = [0, 0.15, 0.33, 0.66];\n\n// Make binaries for each threshold and add together. \n\nvar output_reclassed = output.gte(thresholds[0])\n  .add(output.gte(thresholds[1]))\n  .add(output.gte(thresholds[2]))\n  .add(output.gte(thresholds[3]))\n;\n</code></pre>"},{"location":"patterns/reclassify/#reclassify-by-equal-intervals","title":"Reclassify by equal intervals","text":"<p>This method assigns raster values into equal interval classes. The method divides each value in a raster by the interval number and then rounds down to the nearest integer (finds the floor). The integers in the output are ordinal but arbitrary class numbers. </p> <p></p> <p> <pre><code>graph LR\n  method(\"geo.iReclass.equalInterval()\") ;\n  output[/\"image_reclassified\"/]  ;\n  arg1[\"image\"]  ;\n  arg2[\"interval\"]  ;\n\n  method --&gt; output\n  arg1 --o method\n  arg2 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class method op;\n  class output in-out;\n  class arg1 arg;\n  class arg2 arg;</code></pre> <p></p> <pre><code>var image_reclassified = geo.iReclass.equalInterval(image, interval);\n</code></pre>"},{"location":"patterns/reclassify/#remap-old-values-to-new-values","title":"Remap old values to new values","text":"<p>This method assigns integer values in the input raster to new integer values in the output raster based on transition rules defined by two lists. The first list defines the set of original values in the input raster. The second list defines the set of new values to be stored in the output raster. The order of the two lists determines the transition. The two lists must be the same length (have the same number of values).</p> <p></p> <p> <pre><code>graph LR\n  input[\"image\"] ;\n  method(\".remap()\") ;\n  output[/\"image_remapped\"/]  ;\n  arg1[\"[original values]\"]  ;\n  arg2[\"[new values]\"]  ;\n\n  input --&gt; method  \n  method --&gt; output\n  arg1 --o method\n  arg2 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out;\n  class method op;\n  class output in-out;\n  class arg1 arg;\n  class arg2 arg;</code></pre> <p></p> <pre><code>var image_remapped = image.remap(\n    [0,1,2,3,4],            // Original values\n    [1,0,0,0,1]             // New values \n    )                       // Lengths of two lists must be equal.\n  ;\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/scalar-operations/","title":"scalar operations","text":"<p>PATTERNS</p>"},{"location":"patterns/scalar-operations/#scalar-operations","title":"scalar operations","text":"<p>Uniformly change the values of all data in a raster object by adding, subtracting, multiplying, or dividing the raster by a constant.   </p>"},{"location":"patterns/scalar-operations/#add","title":"add","text":"<p>Add each pixel value by constant. For example, pattern below adds by one.  </p> <pre><code>var image_add_constant = image.add(1)\n</code></pre>"},{"location":"patterns/scalar-operations/#subtract","title":"subtract","text":"<p>Subtract each pixel value by constant. For example, pattern below subtracts by 1.</p> <pre><code>var image_subtract_constant = image.subtract(1)\n</code></pre>"},{"location":"patterns/scalar-operations/#multiply","title":"multiply","text":"<p>Multiply each pixel value by constant. For example, pattern below multiplies by 2.</p> <pre><code>var image_multiply_constant = image.multiply(2)\n</code></pre>"},{"location":"patterns/scalar-operations/#divide","title":"divide","text":"<p>Divide each pixel value by constant. For example, pattern below divides by 2.</p> <pre><code>var image_divide_constant = image.divide(2)\n</code></pre>"},{"location":"patterns/scalar-operations/#problem-types","title":"problem types","text":"<p>Here are a few types of problems that can be solved with scalar operations.  </p>"},{"location":"patterns/scalar-operations/#change-value-units","title":"change value units","text":"<p>A common example is when you need to change the units of your data. For example, to change elevation data from centimeters to meters you divide all elevation values by the number 100 (scalar).   </p> <p> <pre><code>graph LR\n  input[\"image_cm\"] ;\n  method(\".divide()\") ;\n  output[/\"image_m\"/]  ;\n  arg1[\"100\"]  ;\n\n\n  input --&gt; method  \n  method --&gt; output\n  arg1 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out;\n  class method op;\n  class output in-out;\n  class arg1 arg;</code></pre> <p></p> <pre><code>var image_m = image_cm.divide(100);\n</code></pre> <p>The table below lists some common types of unit conversions and their pattern context.</p> CONTEXT INPUT UNITS OUTPUT UNITS METHOD TERRAIN cm m <code>.divide(100)</code> TERRAIN ft m <code>.multiply(3.28084)</code> SLOPE degrees percent <code>.divide(180).multiply(Math.PI).tan().multiply(100)</code>"},{"location":"patterns/scalar-operations/#vertical-exaggeration","title":"vertical exaggeration","text":"<p>Another common example is when you want to apply vertical exaggeration to a terrain operation by multiplying the elevation values by a constant, usually called the z-factor. For example, by multiplying elevation by 2, you will exaggerate the terrain, making every location appear twice as high as it \u2018really\u2019 is. It is often helpful to exaggerate terrain when visualizing micro-topography at large scales or macro-topography at small scales. </p> <p> <pre><code>graph LR\n  input[\"image_m\"] ;\n  method(\".multiply()\") ;\n  output[/\"image_m_ve_2\"/]  ;\n  arg1[\"2\"]  ;\n\n\n  input --&gt; method  \n  method --&gt; output\n  arg1 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out;\n  class method op;\n  class output in-out;\n  class arg1 arg;</code></pre> <p></p> <pre><code>var image_m_ve_2 = image_m.multiply(2);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/terrain/","title":"terrain","text":"<p>PATTERNS</p>"},{"location":"patterns/terrain/#terrain","title":"terrain","text":"<p>These methods derive topographic attributes of terrain from raster elevation data. Most terrain operations characterize attributes of a surface with focal (neighborhood) operations.</p> <p>Before we get too deep into these methods, it is helpful to understand some general concepts about terrain analysis with raster data models.  </p>"},{"location":"patterns/terrain/#change-in-elevation","title":"change in elevation","text":""},{"location":"patterns/terrain/#concepts","title":"concepts","text":"<p>Slope describes how the vertical dimension of space changes with respect to the  horizontal dimension. Many of us first learn about slope as \u201crise over run\u201d which can be expressed as a percentage. Most GIS will compute slope as a percentage or in degrees. Earth Engine calculates slope in degrees and then, if you would like to find the percent slope for your application, it leaves it to you to convert from degrees to percentage with scalar operations.  </p> <p></p> <p>A raster model will define \u201crun\u201d based on distance between the centers of cells. As a result, the distance between two adjacent cells that share a side will be the same as the length of a pixel side, or the scale of the raster.   </p> <p></p> <p>In raster analysis, a common slope computation employs a neighborhood operation with a kernel that resembles a \u201cplus\u201d sign. The crosspiece of the plus computes the difference in z-values (elevation) for the x dimension, while the post of the plus computes the difference in z-values for the y dimension. The change in elevation with respect to change in distance can be found by dividing by the distance across the crosspiece or post (which will both be double the cell size). The degree of slope is then found through some trigonometry.</p> <p></p> <p>Because the slope calculation directly compares changes in elevation with changes in distance, the units of the z-values must be the same as the units of the xy values. In Earth Engine, the xy units will generally be meters. Therefore, accurate slope computations require elevation data in meters.   </p>"},{"location":"patterns/terrain/#decision-flow","title":"decision flow","text":"<p>The workflow for slope analysis will often depend on the data you are using and your purpose. I tend to think through some version of the flowchart depicted below. The </p> <p> <pre><code>graph TD\n\n  q1&gt;\"Do z-units = xy units?\"] ;\n  q2&gt;\"Is your purpose to visualize slope shading?\"] ;\n  q3&gt;\"Does your application require slope in percent?\"] ;  \n  step01(\"Change units \\n\\n APPLY SCALAR\") ;\n  step02(\"Consider changing z-factor \\n\\n APPLY SCALAR\") ;\n  step03(\"Derive slope\") ;\n  step04(\"Convert slope units\") ;\n  step05(&amp;#128526);\n\n  q1-- NO --&gt;step01 --&gt; q2\n  q1-- YES --&gt;q2\n  q2-- YES --&gt;step02\n  q2-- NO --&gt;step03\n  step02 --&gt; step03\n  step03 --&gt; q3\n  q3-- YES --&gt; step04  \n  q3 -- NO --&gt; step05\n  step04 --&gt; step05\n\n\n\n  classDef task fill:#DDE6C3,stroke-width:0px,color:#000000;\n  classDef check fill:#C3D1E6, stroke-width:0px,color:#000000;  \n  classDef done fill:#FFFFFF, stroke-width:0px,color:#000000;  \n\n\n  class q1 check; \n  class q2 check; \n  class q3 check; \n  class step01 task;\n  class step02 task;\n  class step03 task;\n  class step04 task;\n  class step05 done; \n</code></pre> <p></p>"},{"location":"patterns/terrain/#slope-method","title":"slope method","text":"<p>Derive slope of a surface in degrees from elevation in meters. </p> <p>Call the <code>ee.Terrain.slope</code> method with the elevation data (with z-units meters) as the argument.  </p> <p> <pre><code>graph LR\n  step02(\"ee.Terrain.slope()\") ;\n  step03[/\"image_slope\"/]  ;\n  arg01[\"image_elevation_meters\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; </code></pre> <p></p> <pre><code>var image_slope = ee.Terrain.slope(image_elevation_meters);\n</code></pre>"},{"location":"patterns/terrain/#direction-of-change","title":"direction of change","text":""},{"location":"patterns/terrain/#concepts_1","title":"concepts","text":"<p>Closely related to slope, aspect reports the direction of change, or the steepest downhill direction of a pixel. </p> <p>Like slope, aspect is derived with a kernel that computes change in elevation in both x- and y- dimensions, but rather than reporting the steepness of the slope, aspect reports the direction, generally expressed as an azimuthal angle from North 0.  </p> <p> </p>"},{"location":"patterns/terrain/#aspect-method","title":"aspect method","text":"<p>In Earth Engine, the aspect method closely resembles the pattern for slope. </p> <p> <pre><code>graph LR\n  step02(\"ee.Terrain.aspect()\") ;\n  step03[/\"image_aspect\"/]  ;\n  arg01[\"image_elevation_meters\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; </code></pre> <p></p> <pre><code>var image_aspect = ee.Terrain.aspect(image_elevation_meters);\n</code></pre> <p>Because the method directly compares changes in z-values to changes in x- and y- values, the units for elevation must match the units for x- and y- dimensions. Practically, this means the elevation units must be meters.  </p> <p>The output aspect image reports the direction of slope in degrees. Completely flat pixels (with no slope direction) receive the value 0. It is often good practice to mask these pixels so as not to confuse them with north-facing locations.  </p>"},{"location":"patterns/terrain/#analytic-hillshading","title":"analytic hillshading","text":""},{"location":"patterns/terrain/#concepts_2","title":"concepts","text":"<p>Shaded relief is a method to visualize a three-dimensional surface by creating the illusion of highlights and shadows thrown by sunlight on a terrain. Before computers, cartographers created shaded relief by hand (manual shaded relief) in a workflow that blended science and art. Most GIS software now provide a method to automate shaded relief, called analytic hillshading, that simplifies the shading illusion. </p> <p>The method assumes that the illumination source (sun) is an infinite distance from Earth. As a result, the illumination rays travel and reach the Earth\u2019s surface in parallel.  </p> <p></p> <p>The angle of the illumination rays depends on the sun\u2019s position, which is determined by two coordinates. The solar azimuth angle defines the sun\u2019s position on the horizon in degrees from North. It is often most effective to put the illumination source above the northwest horizon, even though in the northern hemisphere it would be unusual to find the sun in this part of the sky. An interesting fact about the illusion of shaded relief is that placing the illumination source in the southern sky will make the landscape appear inverted: mountain ridges look like valleys and creeks look like ridge lines. Because of this, many analytic hillshade tools in GIS will use 315 as the starting solar azimuth angle. You can then adjust this \u00b1 30 degrees depending on the orientation of ridges and valleys in the area of interest, while taking care not to invert the landscape by pushing the sun too far.  </p> <p>The second solar coordinate the defines the sun\u2019s position above the horizon, or how high the sun hangs in the sky. Many GIS call this the zenith angle, but in Earth Engine it is called elevation. If the sun is directly overhead, the zenith angle is 90 and the sun approaches 0 as it nears the horizon. By default, many GIS go with the Goldilocks solution and set the zenith angle at 45. It is often good to start here and then adjust based on your terrain. Lowering the zenith angle can be helpful on flat terrain, while raising the angle can be helpful in more rugged landscapes.       </p> <p></p> <p>The brightness of the reflected ray is determined by the local incidence angle from the surface normal (perpendicular to the surface). When the incidence angle is near 0, the rays directly strike the surface and reflect at their brightest power. Because most GIS will store the output of the analytic hillshade method as a byte data type (0-255), the brightest pixels will have the data value 255. In a grayscale palette, this value will be displayed white. As the incidence angle increases, the rays strike the surface obliquely, the brightness values decrease, and the display values change from white to gray. As the angle exceeds 90, the brightness values change from gray to black.</p> <p> </p>"},{"location":"patterns/terrain/#hillshade-operation","title":"hillshade operation","text":"<p>In Earth Engine, the <code>ee.Terrain.hillshade()</code> method takes three arguments to output a hillshade image.  </p> <p> <pre><code>graph LR\n  step02(\"ee.Terrain.hillshade()\") ; \n  step03[/\"image_hs\"/]  ;\n  arg01[\"image_elevation_meters\"] ;\n  arg02[\"azimuth angle\"] ;\n  arg03[\"zenith angle\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n  arg02 --o step02\n  arg03 --o step02\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg;\n  class arg02 arg; \n  class arg03 arg; </code></pre> <p></p> <pre><code>var image_hs = ee.Terrain.hillshade(image_elevation_meters, azimuth, zenith);\n</code></pre>"},{"location":"patterns/terrain/#deviation-from-mean-elevation","title":"deviation from mean elevation","text":"<p>Description forthcoming </p> <pre><code>var image_dme = geo.iTerrain.devFromMeanElev(image, 10);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/ui-design/","title":"ui design","text":"<p>PATTERNS </p>"},{"location":"patterns/ui-design/#user-interface-design","title":"user interface design","text":""},{"location":"patterns/ui-design/#layouts","title":"layouts","text":""},{"location":"patterns/ui-design/#map-with-side-bar-layout","title":"map with side bar layout","text":"<pre><code>// -------------------------------------------------------------\n//  Make Map with Side Bar Layout\n// -------------------------------------------------------------\n\n// Initialize side bar.\n\nvar side_bar = ui.Panel({\n  layout: ui.Panel.Layout.flow('vertical'),\n  style: {width: \"20%\"}\n});\n\n// Initialize new map.\n\nvar right_Map = ui.Map();\n\n// Initialize layout with side bar and map\n\nvar layout = ui.SplitPanel(\n  {\n    firstPanel: side_bar,\n    secondPanel: right_Map, \n    orientation: 'horizontal',\n    wipe: false\n  }\n);\n\n// Add layout to root. \n\nui.root.clear();\nui.root.setLayout(ui.Panel.Layout.flow('horizontal'));\nui.root.add(layout);\n</code></pre>"},{"location":"patterns/ui-design/#swipe-map-with-side-bar-layout","title":"swipe map with side bar layout","text":"<pre><code>// -------------------------------------------------------------\n//  Make Swipe Map with Side Bar Layout\n// -------------------------------------------------------------\n\n// Initialize side bar.\n\nvar side_bar = ui.Panel({\n  layout: ui.Panel.Layout.flow('vertical'),\n  style: {width: \"20%\"}\n});\n\n// Initialize two new maps.\n\nvar left_Map = ui.Map();\nvar right_Map = ui.Map();\n\n// Initialize swipe map with left and right maps.\n\nvar swipe_map = ui.SplitPanel(          // Initialize split panel.\n  left_Map,                             // Put on left side of panel.\n  right_Map,                            // Put on right side of panel.\n  'horizontal',                         // Arrange split in horizontal direction.\n  true                                  // Make a WIPE transition.\n  )\n;\n\n// Link maps together.\n\nui.Map.Linker([\n    left_Map, \n    right_Map\n  ])\n;\n\n// Initialize a panel to hold swipe map.\n\nvar swipe_map_panel = ui.Panel(\n  {\n    widgets: [swipe_map]\n  });\n\n// Initialize layout with side bar and swipe map\n\nvar layout = ui.SplitPanel(\n  {\n    firstPanel: side_bar,\n    secondPanel: swipe_map_panel, \n    orientation: 'horizontal',\n    wipe: false\n  }\n);\n\n// Add layout to root. \n\nui.root.clear();\nui.root.setLayout(ui.Panel.Layout.flow('horizontal'));\nui.root.add(layout);\n</code></pre>"},{"location":"patterns/ui-design/#add-labels-for-maps","title":"add labels for maps","text":"<pre><code>// -------------------------------------------------------------\n//  Make left and right map labels.\n// -------------------------------------------------------------\n\nvar style_label_map = \n  {\n    fontSize: '18px',\n    fontWeight: 'bold',\n    fontFamily: 'Helvetica, sans-serif',\n  }\n;\n\nvar label_map_left = ui.Label({\n  value: 'label for left map',\n  style: style_label_map,\n  }\n);\n\nlabel_map_left.style().set({\n  position: 'bottom-left',\n});\n\nvar label_map_right = ui.Label({\n  value: 'label for right map',\n  style: style_label_map,\n  }\n);\n\nlabel_map_right.style().set({\n  position: 'bottom-right',\n});\n\nleft_Map.add(label_map_left);\nright_Map.add(label_map_right);\n</code></pre>"},{"location":"patterns/ui-design/#add-title","title":"add title","text":"<pre><code>// -------------------------------------------------------------\n//  Add Title\n// -------------------------------------------------------------\n\nvar style_title = \n  {\n    fontSize: '24px',\n    fontWeight: 'bold',\n    fontFamily: 'Helvetica, sans-serif',\n    whiteSpace: 'wrap'\n  }\n;\n\nvar title = ui.Label({\n  value: \"Layout title\",\n  style: style_title,\n  }\n);\n\nside_bar.add(title);\n</code></pre>"},{"location":"patterns/ui-design/#add-subtitle","title":"add subtitle","text":"<pre><code>// -------------------------------------------------------------\n//  Add Subtitle\n// -------------------------------------------------------------\n\nvar style_subtitle = \n  {\n    fontSize: '18px',\n    fontWeight: 'bold',\n    fontFamily: 'Helvetica, sans-serif',\n    color: 'OliveDrab',\n    whiteSpace: 'pre'\n  }\n;\n\nvar subtitle = ui.Label({\n  value: \"Place\\n(start-end)\",\n  style: style_subtitle,\n  }\n);\n\nside_bar.add(subtitle);\n</code></pre>"},{"location":"patterns/ui-design/#add-documentation","title":"add documentation","text":"<pre><code>// -------------------------------------------------------------\n//  Add documentation.\n// -------------------------------------------------------------\n\nvar style_docs = \n  {\n    fontSize: '12px',\n    fontFamily: 'Helvetica, sans-serif',\n    position: 'bottom-right'\n  }\n;\n\nvar docs = ui.Label({\n  value: 'more information',\n  style: style_docs,\n  targetUrl: 'link to google doc'       // Change sharing to \"Anyone with the link\"\n  }\n);\n\nside_bar.add(docs);\n</code></pre>"},{"location":"patterns/ui-design/#add-credits","title":"add credits","text":"<pre><code>// -------------------------------------------------------------\n//  Add credits \n// -------------------------------------------------------------\n\nvar style_credits = \n  {\n    fontSize: '10px',\n    fontFamily: 'Helvetica, sans-serif',\n    position: 'bottom-right'\n  }\n;\n\nvar credits = ui.Label({\n  value: 'Your Name',\n  style: style_credits,\n  targetUrl: 'link to portfolio or online presence'\n  }\n);\n\nside_bar.add(credits);\n</code></pre>"},{"location":"patterns/ui-design/#add-interactivity","title":"add interactivity","text":"<p>These patterns provide tools that allow the user to interact with the layout.  </p>"},{"location":"patterns/ui-design/#select-places-of-interest","title":"select places of interest","text":"<pre><code>// -------------------------------------------------------------\n//  Select places of interest\n// -------------------------------------------------------------\n\n//  Make dictionary of places of interest. \n\nvar places = {\n\n// \"Place name\": [longitude, latitude, zoom]\n  \"Atwater Lot\": [-73.17655, 44.01282, 18],\n  \"Full Extent\": [-73.17661, 44.01243, 14],\n\n};\n\nvar select = ui.Select({\n  items: Object.keys(places),\n  placeholder: \"Choose a location\",\n  onChange: function(key) {\n\n    // This will recenter the map to the place of interest. \n\n    left_Map.setCenter(places[key][0], places[key][1], places[key][2]);\n\n  }\n});\n\n// Add the widget to the side bar.\n\nside_bar.add(select);\n</code></pre>"},{"location":"patterns/ui-design/#layer-visibility-checkbox","title":"layer visibility checkbox","text":"<pre><code>// -------------------------------------------------------------\n//  Checkbox for layer visibility.\n// -------------------------------------------------------------\n\n// Initialize a checkbox with a label and check the box by default. \n\nvar checkbox = ui.Checkbox('Label', true);\n\n// Define what happens when you check the box. \n\ncheckbox.onChange(function(checked) {\n\n  // Show or hide the first map layer (controlled by index) based on the checkbox's value.\n\n  left_Map.layers().get(0).setShown(checked);\n  right_Map.layers().get(0).setShown(checked);\n});\n\n// Add the checkbox to the side panel.  \n\nside_bar.add(checkbox);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/vector-operations/","title":"vector operations","text":"<p>PATTERNS </p>"},{"location":"patterns/vector-operations/#vector-operations","title":"vector operations","text":"<p>Vector operations work with tables of geometries and often attributes. </p>"},{"location":"patterns/vector-operations/#transform-geometries","title":"transform geometries","text":"<p>These methods create new geometries based on the input geometries of feature collections.    </p> <p>More to come.</p>"},{"location":"patterns/vector-operations/#bounding-box","title":"bounding box","text":"<pre><code>var fc_bounds = geo.fcGeometry.boundingBox(fc);\n\nMap.addLayer(fc_bounds, {color: 'cyan'}, \"Bounding box\", false);\n</code></pre>"},{"location":"patterns/vector-operations/#centroid","title":"centroid","text":"<pre><code>var fc_centroid = geo.fcGeometry.centroidPoint(fc);\n\nMap.addLayer(fc_centroid, {color: 'yellow'}, \"Centroid point\", false);\n</code></pre>"},{"location":"patterns/vector-operations/#convex-hull","title":"convex hull","text":"<pre><code>var fc_convex_hull = geo.fcGeometry.convexHullPolygon(fc);\n\nMap.addLayer(fc_convex_hull, {color: 'magenta'}, \"Convex hull\", false);\n</code></pre>"},{"location":"patterns/vector-operations/#multipart-vs-single-part-geometries","title":"multipart vs. single part geometries","text":"<p>These methods change the form of the geometries liked to rows in a table. The picture below illustrates several concepts. The leftmost frame (A) shows a table with a singlepart geometry; a single polygon linked to each row in the table. The center frame (B) shows a table linked to multipart geometry (multipart geometry can link two or more polygons to a single row of attributes). The rightmost frame (C) shows another table with multipart geometries; four polygons associated with one row.   </p> <p></p> <p>Operations are shown laterally. Moving from A to B is a dissolve operation (singlepart \u2192 multipart), while moving from B to A is an explode operation (multipart \u2192 singlepart). Note the asymmetry between moves on the right side. From B to C is another dissolve, but from C to B is not possible.  </p>"},{"location":"patterns/vector-operations/#dissolve-by-attribute","title":"dissolve by attribute","text":"<p>This will dissolve a feature collection into multipart features that share a common attribute. </p> <pre><code>// -------------------------------------------------------------\n//  Dissolve by attribute\n// -------------------------------------------------------------\n\nvar output_dissolve = geo.fcGeometry.dissolveByAttribute(fc, \"property\");\n\nprint(\"DISSOLVE\", fc.first(), output_dissolve.first());\n</code></pre> <p>Using the illustration at the top of this section, the snippet below will transform A into B. </p> <pre><code>var B = geo.fcGeometry.dissolveByAttribute(A, \"GRADE\");\n</code></pre> <p>Please note that the property name is literal (and case sensitive), so when working with HOLC data you would need to specify \u201cholc_grade\u201d to transform A to B and \u201ccity\u201d to transform B to C. </p>"},{"location":"patterns/vector-operations/#vector-overlay","title":"vector overlay","text":"<p>Vector overlay operations compare locations between two vector layers. In Earth Engine, the vector layers are generally features in a feature collection.  </p> <p>more soon </p>"},{"location":"patterns/vector-operations/#clip-by-region","title":"clip by region","text":"<p><code>geo.fcOverlay.clipByRegion()</code> is a knife method that takes two arguments. </p> ARGUMENT DESCRIPTION fc_dough A vector dataset (feature collection) with features that you want to cut. fc_cutter A vector dataset (feature collection) with features that you want to use as the knife to cut the dough. <p>The output is a feature collection that retains that attributes but alters the geometry of the dough.  </p> <pre><code>var fc_clip = geo.fcOverlay.clipByRegion(fc_dough, fc_cutter);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/zonal-operations/","title":"zonal operations","text":"<p>PATTERNS</p>"},{"location":"patterns/zonal-operations/#zonal-operations","title":"zonal operations","text":"<p>Zonal operations analyze pixel values in one layer based on zones (regions) defined by another layer. In Earth Engine, the zones are often (but not always) defined by features in a feature collection.   </p> <p>more soon </p>"},{"location":"patterns/zonal-operations/#zonal-area","title":"zonal area","text":"<p>These methods use the zones defined by the geometry of a feature collection to compute the area of each class in a nominal or boolean layer.  </p>"},{"location":"patterns/zonal-operations/#area-of-classes","title":"area of classes","text":"<p>This method returns a dictionary that reports the total area (in square meters) of each class (integer value) in the input raster.  </p> <pre><code>var area_of_classes = geo.iZonal.areaClasses(image, scale, region, \"band_name\");\n\nprint(\n    \"Area (square meters)\",\n    area_of_classes\n);\n</code></pre> <p>The table below describes the arguments.  </p> ARGUMENT DESCRIPTION image The boolean or nominal (class) image to compute the area for each unique pixel value. scale The pixel scale for analysis to troubleshoot TIME OUT errors. It can be helpful to first run at a coarse resolution and then increase resolution (make number smaller) as appropriate. region Feature collection with one or more features that define the area of analysis or study region. \u201cband_name\u201d The band name in the image with the integer values that identify the classes to compute the area of."},{"location":"patterns/zonal-operations/#area-of-classes-as-percent-of-region","title":"area of classes as percent of region","text":"<p>This method returns a dictionary that reports the total area of each class (integer value) in the input raster as a percent of the region. It takes the output from <code>.areaClasses()</code> (above) as the input and returns a dictionary. </p> <pre><code>var class_percent_of_region = geo.iZonal.classPercentRegion(area_of_classes);\n\nprint(\n  \"Area (percent of region)\",\n  class_percent_of_region\n  )\n;\n</code></pre>"},{"location":"patterns/zonal-operations/#complete-pattern","title":"complete pattern","text":"<p>Here is the complete pattern for calculating the area of raster classes and their percent area of a region.  </p> <pre><code>var area_of_classes = geo.iZonal.areaClasses(image, scale, region, \"band_name\");\n\nprint(\n    \"Area (square meters)\",\n    area_of_classes\n);\n\nvar class_percent_of_region = geo.iZonal.classPercentRegion(area_of_classes);\n\nprint(\n  \"Area (percent of region)\",\n  class_percent_of_region\n  )\n;\n</code></pre>"},{"location":"patterns/zonal-operations/#zonal-statistics","title":"zonal statistics","text":"<p>This method calculates a statistic of image values within a zone of analysis defined by one or more features in a feature collection. The output of the method is a feature collection with a new column that contains the statistic.  </p> <p></p> <pre><code>var fc_zonal_stat = geo.iZonal.zonalStats(dough, cutter, \"statistic\", scale);\n</code></pre> <p>The method takes four arguments that are defined in the table below.  </p> ARGUMENTS DESCRIPTION dough The image with pixel values to be analyzed. cutter The feature collection with one or more features that define the zones of analysis. \u201cstatistic\u201d The statistic to calculate within each zone of analysis. Must be a string from these options: \u201csum\u201d, \u201cmax\u201d, \u201cmin\u201d, \u201cmean\u201d, \u201ccount\u201d, \u201cvariety\u201d (\u201ccount\u201d reports the number of pixels, while \u201cvariety\u201d reports the number of unique pixel values). scale The scale of analysis. Should be set to raster scale (pixel size) of dough. If you encounter time out errors that prevent you from displaying output layer, you can try to resolve by changing the scale of analysis, though this will introduce rounding errors."},{"location":"patterns/zonal-operations/#clip-by-region","title":"clip by region","text":"<p>This is a knife method that will use the zones of a feature collection to clip a raster. The result is similar to a mask operation, but here you use a vector dataset to cut rather than a raster dataset. The engineers at Google warn that <code>.clip()</code> is more computationally expensive than <code>.updateMask()</code> and can be particularly slow with complex geometries.   </p> <pre><code>var output_clip = input.clip(cutter);\n</code></pre>"},{"location":"patterns/zonal-operations/#chart-zonal-statistic-by-class","title":"chart zonal statistic by class","text":"<p>This pattern calculates a zonal static where (1) a nominal (classified, categorical, object) image defines the cutter (rather than a feature collection) and (2) the output is a chart (rather than a feature collection).  </p> <p>As a method for calculating zonal statistics, the underlying spatial concept is to use one layer (the cutter image) to define zones for statistical analysis of a dough image. Because the output is a chart, there are a few more inputs, so you will need to fill out a dictionary to use the method.  </p> <pre><code>// ---------------------------------------------------------------------\n//  Chart a zonal statistic with a class layer.  \n// ---------------------------------------------------------------------\n\n// Define chart arguments. \n\nvar chart_arguments = {\n  data_image: dough_image,                          \n  class_image: cutter_image,                       \n  aoi: area_or_interest,                          \n  reducer: statistic,\n  scale: analysis_scale,\n  title: chart_title,\n  class_labels: labels_that_define_cutters,\n  palette: palette_for_cutters,\n  ha_label: label_for_horizontal_axis\n\n\n};\n\nvar myChart = geo.uiChart.makeBarChartByClass(chart_arguments);\n</code></pre> <p>The table below defines each key in the dictionary and describes rules of thumb.  </p> ARGUMENT DESCRIPTION data_image The dough image; a numeric image with values that you would like to summarize with a statistic. class_image The cutter image; an image with values that represent names or categories or classes, that you would like to use as zones of analysis. aoi A feature collection that defines an area of interest or study region. reducer The statistic that you would like to calculate within each cutter. Some common options are: <code>ee.Reducer.mean()</code>, <code>ee.Reducer.median()</code>, <code>ee.Reducer.min()</code>, <code>ee.Reducer.max()</code> scale The scale of analysis. Ideally, set to be the same resolution as your dough image. If you encounter TIME OUT errors, try to coarsen the scale. class_labels Names for the cutters in your class image. Must be a list of strings, where each string in the list defines a class. Ideally, you have one label per class value. The order of the labels in your list should match the order of the class values. This is similar to the labels of a nominal legend. title The title for the chart. Must be a string. palette The colors for each class in the chart. Must be a list of strings, where each string defines an html color. The length of this list should match the length of the class label list. This is similar to the palette of a nominal legend. ha_label A title for the horizontal axis of the chart. Must be a string. <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"starters/MODIS/","title":"MODIS","text":"<p>STARTERS </p>"},{"location":"starters/MODIS/#modis","title":"MODIS","text":"<p>Earth Engine provides a somewhat staggering number of different MODIS products as cloud assets. The sheer number of products available can make it a little confusing to navigate. This page aims to help by introducing some key concepts for working with MODIS.   </p>"},{"location":"starters/MODIS/#key-terms","title":"key terms","text":""},{"location":"starters/MODIS/#sensor-and-satellites","title":"sensor and satellites","text":"<p>The Moderate Resolution Imaging Spectrometer, or MODIS, is a sensor onboard two satellites:  </p> <ul> <li>Terra: originally called as EOS AM-1  </li> <li>Aqua: originally called EOS PM-1 </li> </ul>"},{"location":"starters/MODIS/#orbits","title":"orbits","text":"<p>These two satellites image Earth\u2019s entire surface once every 1-2 days. The video below shows the orbit of the Aqua satellite.   </p>"},{"location":"starters/MODIS/#bands","title":"bands","text":"<p>Compared to Landsat and Sentinel, MODIS bucks convention for band names. It also differs from other sensors by having a second NIR band (between NIR and SWIR1).     </p> BAND NUMBER BAND NAME BAND WIDTH (nm) B1 Red 620 - 670 B2 NIR 841 - 876 B3 Blue 459 - 479 B4 Green 545 - 565 B5 NIR2 1230 - 1250 B6 SWIR1 1628 - 1652 B&amp; SWIR2 2105 - 2155"},{"location":"starters/MODIS/#sr-snapshots","title":"SR snapshots","text":"<p>These scripts will help you get started making snapshots with two different MODIS surface reflectance (SR) products. The eight day composites help speed up processing times.  </p>"},{"location":"starters/MODIS/#daily-images","title":"daily images","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_MODIS_daily.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/17/2024\n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// // Map.centerObject(geometry, 6);\n\nMap.setOptions('hybrid');\n\n// ----------------------------------------------------------------------\n//  Combine Terra and Aqua daily collections. \n// ----------------------------------------------------------------------\n\n// Print metadata for spectral bands. \n\nprint(\"MODIS spectra\", geo.icMODIS.spectral_bands);\n\n// Gather collections of terra and aqua daily images. \n\nvar terra_1day = ee.ImageCollection(\"MODIS/061/MOD09GA\");\nvar aqua_1day = ee.ImageCollection(\"MODIS/061/MYD09GA\");\n\nprint(\n  \"MODIS\",\n  terra_1day.first(),\n  terra_1day.size(),\n  aqua_1day.first(),\n  aqua_1day.size()\n  )\n;\n\n// Combine daily collections. \n\nvar combineMODIS = terra_1day\n  .merge(aqua_1day)\n;\n\nprint(\n  \"TERRA, AQUA COMBINED\",\n  combineMODIS.size()\n  )\n;\n\n// ----------------------------------------------------------------------\n//  Filter \n// ----------------------------------------------------------------------\n\n// Define year and month of interest. \n\nvar yoi = 2021;\nvar moi = 8;\n\n// Filter collections by time and cloudy pixels.\n\nvar output = combineMODIS\n  .filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n  .filter(ee.Filter.calendarRange(moi, moi, \"month\"))\n  .map(geo.icMODIS.maskClouds_1day)                   // Mask cloudy pixels\n  .map(geo.icMODIS.renameSpectralBands)               // Rename bands because they have weird names.\n  .median()\n  .multiply(0.0001)                                   // Apply scalar after flattening collection.\n;\n\nprint(\"OUTPUTS\", output);\n\n\n// ----------------------------------------------------------------------\n// Display\n// ----------------------------------------------------------------------\n\nvar viz = {\n\n  bands: ['R', 'G', 'B'],\n  min: [0.01, 0.02, 0.0],\n  max: [0.25, 0.25, 0.175],\n  gamma: 1.2,\n\n};\n\nMap.addLayer(output, viz, 'MODIS imagery');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictionary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Get scale from map extent.\n\nvar scale =  Map.getScale();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(\n    select_band, \n    scale,\n    aoi                 \n);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/MODIS/#8-day-composites","title":"8 day composites","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_MODIS_8day_composites.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for MODIS collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\nMap.setOptions('hybrid');\n\n\n// ----------------------------------------------------------------------\n//  Combine Terra and Aqua daily collections. \n// ----------------------------------------------------------------------\n\n// Print metadata for spectral bands. \n\nprint(\"MODIS spectra\", geo.icMODIS.spectral_bands);\n\n// Gather collections of terra and aqua 8 day averages. \n\nvar terra_8day = ee.ImageCollection(\"MODIS/061/MOD09A1\");\nvar aqua_8day = ee.ImageCollection(\"MODIS/061/MYD09A1\");\n\nprint(\n  \"MODIS\",\n  terra_8day.first(),\n  terra_8day.size(),\n  aqua_8day.first(),\n  aqua_8day.size()\n  )\n;\n\n// Combine daily collections. \n\nvar combineMODIS = terra_8day\n  .merge(aqua_8day)\n;\n\nprint(\n  \"TERRA, AQUA COMBINED\",\n  combineMODIS.size()\n  )\n;\n\n// ----------------------------------------------------------------------\n//  Filter collection\n// ----------------------------------------------------------------------\n\n// Define year and month of interest. \n\nvar yoi = 2021;\nvar moi = 8;\n\n// Filter collections by time and cloudy pixels.\n\nvar output = combineMODIS\n  .filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n  .filter(ee.Filter.calendarRange(moi, moi, \"month\"))\n  .map(geo.icMODIS.maskClouds_8day)                   // Mask cloudy pixels\n  .map(geo.icMODIS.renameSpectralBands)               // Rename bands because they have weird names.\n  .median()\n  .multiply(0.0001)                                   // Apply scalar after flattening collection.\n;\n\nprint(\"OUTPUTS\", output);\n\n\n// ----------------------------------------------------------------------\n// Display\n// ----------------------------------------------------------------------\n\nvar viz = {\n\n  bands: ['R', 'G', 'B'],\n  min: [0.01, 0.02, 0.0],\n  max: [0.25, 0.25, 0.175],\n  gamma: 1.2,\n\n};\n\nMap.addLayer(output, viz, 'MODIS imagery');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictionary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Get scale from map extent.\n\nvar scale =  Map.getScale();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(\n    select_band, \n    scale,\n    aoi                 \n);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/MODIS/#sr-time-series","title":"SR time series","text":"<p>These scripts will help you get started with time series analysis. We use the eight-day composites to help speed up processing times.   </p>"},{"location":"starters/MODIS/#basic-time-series","title":"basic time series","text":"<p>The script below compiles a collection (rather than a flat image) and then charts all spectral bands over the duration of the collection. </p> <pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_MODIS_8day_time_series.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for MODIS time series. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\nMap.setOptions('hybrid');\n\n// ----------------------------------------------------------------------\n//  Combine Terra and Aqua daily collections. \n// ----------------------------------------------------------------------\n\n// Print metadata for spectral bands. \n\nprint(\"MODIS spectra\", geo.icMODIS.spectral_bands);\n\n// Gather collections of terra and aqua 8 day averages. \n\nvar terra_8day = ee.ImageCollection(\"MODIS/061/MOD09A1\");\nvar aqua_8day = ee.ImageCollection(\"MODIS/061/MYD09A1\");\n\nprint(\n  \"MODIS\",\n  terra_8day.first(),\n  terra_8day.size(),\n  aqua_8day.first(),\n  aqua_8day.size()\n  )\n;\n\n// Combine daily collections. \n\nvar combineMODIS = terra_8day\n  .merge(aqua_8day)\n;\n\nprint(\n  \"TERRA, AQUA COMBINED\",\n  combineMODIS.size()\n  )\n;\n\n// ----------------------------------------------------------------------\n//  Filter collection\n// ----------------------------------------------------------------------\n\n// Define year and month of interest. \n\nvar yoi = 2023;\n\n// Filter collections by time and cloudy pixels.\n\nvar output = combineMODIS\n  .filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n  .map(geo.icMODIS.maskClouds_8day)                   // Mask cloudy pixels\n  .map(geo.icMODIS.renameSpectralBands)               // Rename bands because they have weird names.\n;\n\nprint(\"OUTPUT COLLECTION\", output);\n\n\n// ----------------------------------------------------------------------\n//  Display image from collection as Map layer.  \n// ----------------------------------------------------------------------\n\nvar viz = {\n\n  bands: ['R', 'G', 'B'],\n  min: [0.01, 0.02, 0.0],\n  max: [0.25, 0.25, 0.175],\n  gamma: 1.2,\n\n};\n\n// Define display image \n\nvar display_image = output    // time series collection\n  .median()                   // flatten image\n  .multiply(0.0001)           // apply scalar for reflectance values  \n;          \n\nMap.addLayer(display_image, viz, 'MODIS imagery');\n\n\n// // ------------------------------------------------------------------------\n// //  Chart histogram for a selected Image band.  \n// // ------------------------------------------------------------------------\n\n// // Select a band in viz dictionary to chart. \n\n// var select_band = display_image.select(viz.bands[0]);\n\n// // Get AOI from map extent.\n\n// var aoi = geo.uiMap.getAOIfromMapExtent();\n\n// // Get scale from map extent.\n\n// var scale =  Map.getScale();\n\n// // Make and print histogram.\n\n// var histogram = geo.iCart.iHistogram(\n//     select_band, \n//     scale,\n//     aoi                 \n// );\n\n// print(\"Histogram of selected band\", histogram);\n\n// ------------------------------------------------------------------------\n//  Define regions of interest.  \n// ------------------------------------------------------------------------\n\n// Gather regions from a feature collection.  \n\nvar regions = ee.FeatureCollection(\"FAO/GAUL/2015/level2\");\n\n// Define a point of interest with geometry tools.\n\nvar geometry = ee.Geometry.Point([-119.72687261495858, 34.42223412451513]);\n\n// Select region of interest with poi.\n\nvar regions_select = regions.filterBounds(geometry);\n\n// ------------------------------------------------------------------------\n//  Display regions of interest as map layers.\n// ------------------------------------------------------------------------\n\nvar strokes = geo.fcCart.paintStrokes(regions, \"white\", 0.5);\n\nMap.addLayer(strokes, {}, \"Region outlines\");\n\nvar strokes_select = geo.fcCart.paintStrokes(regions_select, \"yellow\", 2);\n\nMap.addLayer(strokes_select, {}, \"Selected region outlines\");\n\n// -------------------------------------------------------------\n//  Initialize panel for time series chart. \n// -------------------------------------------------------------\n\nvar panel_chart = geo.icIntervals.initializePanelForChart('bottom-left');\n\nMap.add(panel_chart);\n\n// Define parameters for time series chart.\n\nvar parameters = {\n  collection: output,\n  reducer: ee.Reducer.mean(),\n  image_scale: 500,\n  // interval_unit: \"month\",          // Comment out to chart by default \"system:time_start\"\n  panel: panel_chart,\n  roi: regions_select\n};\n\n// Chart time series with parameters. \n\ngeo.icIntervals.chartTimeSeries(parameters);\n</code></pre>"},{"location":"starters/MODIS/#time-series-of-spectral-index","title":"time series of spectral index","text":"<p>The script below will compute a spectral index (NDVI) for each image in the time series and then chart the index over duration of the collection.    </p> <pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_MODIS_8day_time_series_with_ndvi.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for MODIS time series. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\nMap.setOptions('hybrid');\n\n// ----------------------------------------------------------------------\n//  Combine Terra and Aqua daily collections. \n// ----------------------------------------------------------------------\n\n// Print metadata for spectral bands. \n\nprint(\"MODIS spectra\", geo.icMODIS.spectral_bands);\n\n// Gather collections of terra and aqua 8 day averages. \n\nvar terra_8day = ee.ImageCollection(\"MODIS/061/MOD09A1\");\nvar aqua_8day = ee.ImageCollection(\"MODIS/061/MYD09A1\");\n\nprint(\n  \"MODIS\",\n  terra_8day.first(),\n  terra_8day.size(),\n  aqua_8day.first(),\n  aqua_8day.size()\n  )\n;\n\n// Combine daily collections. \n\nvar combineMODIS = terra_8day\n  .merge(aqua_8day)\n;\n\nprint(\n  \"TERRA, AQUA COMBINED\",\n  combineMODIS.size()\n  )\n;\n\n// ----------------------------------------------------------------------\n//  Filter collection\n// ----------------------------------------------------------------------\n\n\n// Filter collections by cloudy pixels.\n\nvar output = combineMODIS\n  // .filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n  .map(geo.icMODIS.maskClouds_8day)                   // Mask cloudy pixels\n//   .map(geo.icMODIS.maskWater_8day)                    // Mask water pixels. \n  .map(geo.icMODIS.renameSpectralBands)               // Rename bands because they have weird names.\n;\n\nprint(\"OUTPUT COLLECTION\", output);\n\n\n// ----------------------------------------------------------------------\n//  Display image from collection as Map layer.  \n// ----------------------------------------------------------------------\n\nvar viz = {\n\n  bands: ['R', 'G', 'B'],\n  min: [0.01, 0.02, 0.0],\n  max: [0.25, 0.25, 0.175],\n  gamma: 1.2,\n\n};\n\n// Define display image \n\nvar display_image = output    // time series collection\n  .median()                   // flatten image\n  .multiply(0.0001)           // apply scalar for reflectance values  \n;          \n\nMap.addLayer(display_image, viz, 'MODIS imagery', false);\n\n\n// // ------------------------------------------------------------------------\n// //  Chart histogram for a selected Image band.  \n// // ------------------------------------------------------------------------\n\n// // Select a band in viz dictionary to chart. \n\n// var select_band = display_image.select(viz.bands[0]);\n\n// // Get AOI from map extent.\n\n// var aoi = geo.uiMap.getAOIfromMapExtent();\n\n// // Get scale from map extent.\n\n// var scale =  Map.getScale();\n\n// // Make and print histogram.\n\n// var histogram = geo.iCart.iHistogram(\n//     select_band, \n//     scale,\n//     aoi                 \n// );\n\n// print(\"Histogram of selected band\", histogram);\n\n\n// ----------------------------------------------------------------------\n//  Calculate spectral index for each image in the collection.  \n// ----------------------------------------------------------------------\n\n// Write computation as a function.  \n\nvar computeND = function(image) {\n\n    var si = image.normalizedDifference(['N', 'R']).rename('NDVI');\n\n    return image.addBands(si);\n\n  };\n\n// Map function over the collection.  \n\nvar output_with_si = output.map(computeND);\n\nprint(\"MAP NDVI\", output.first(), output_with_si.first());\n\n// Display spectral index image from collection as layer on Map.\n\nvar display_image_si = output_with_si     // time series collection\n  .median()                               // flatten image\n  .select(\"NDVI\")\n; \n\nMap.addLayer(display_image_si, {min:-0.8, max:0.8, palette: geo.iPalettes.iDrought}, \"Image with spectral index\");\n\n// ------------------------------------------------------------------------\n//  Define regions of interest.  \n// ------------------------------------------------------------------------\n\n// Gather regions from a feature collection.  \n\nvar regions = ee.FeatureCollection(\"FAO/GAUL/2015/level2\");\n\n// Define a point of interest with geometry tools.\n\nvar geometry = ee.Geometry.Point([-119.72687261495858, 34.42223412451513]);\n\n// Select region of interest with poi.\n\nvar regions_select = regions.filterBounds(geometry);\n\n// ------------------------------------------------------------------------\n//  Display regions of interest as map layers.\n// ------------------------------------------------------------------------\n\nvar strokes = geo.fcCart.paintStrokes(regions, \"white\", 0.5);\n\nMap.addLayer(strokes, {}, \"Region outlines\");\n\nvar strokes_select = geo.fcCart.paintStrokes(regions_select, \"yellow\", 2);\n\nMap.addLayer(strokes_select, {}, \"Selected region outlines\");\n\n// -------------------------------------------------------------\n//  Initialize panel for time series chart. \n// -------------------------------------------------------------\n\nvar panel_chart = geo.icIntervals.initializePanelForChart('bottom-left');\n\nMap.add(panel_chart);\n\n// Define parameters for time series chart.\n\nvar parameters = {\n  collection: output_with_si.select('NDVI'),\n  reducer: ee.Reducer.mean(),\n  image_scale: 500,\n  // interval_unit: \"month\",          // Comment out to chart by default \"system:time_start\"\n  panel: panel_chart,\n  roi: regions_select\n};\n\n// Chart time series with parameters. \n\ngeo.icIntervals.chartTimeSeries(parameters);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"starters/NAIP/","title":"NAIP","text":"<p>STARTERS </p>"},{"location":"starters/NAIP/#naip","title":"NAIP","text":"<p>Earth Engine provides images collected from the National Agricultural Imagery Program (NAIP) as cloud assets.</p> <p>The starter script below will help you quickly filter and mosaic this collection for an area of interest.  </p>"},{"location":"starters/NAIP/#naip_1","title":"NAIP","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:     \n    DATE:       \n    TITLE:  NAIP starter \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n\n// -------------------------------------------------------------\n//  Define AOI from point with 10km buffer.\n// -------------------------------------------------------------\n\nvar geometry = ee.FeatureCollection(\n        [ee.Feature(\n            ee.Geometry.Point([-73.16875, 44.01336]),\n            {\n              \"system:index\": \"0\"\n            })]);\n\nvar aoi = geo.fcProximity.bufferByDistance(geometry, 10000);\n\nMap.centerObject(geometry, 15);\n\n// -------------------------------------------------------------\n//  Get year of interest.\n// -------------------------------------------------------------\n\nvar year_list = geo.icNAIP.yearList(\n    aoi,        \n    4       // Change to 3 if you would like to include earliest images that lack NIR band.  \n);\n\nvar yoi = year_list.get(0);   // This gets the first year in the year list.\n\n// var yoi = year_list.get(year_list.length().subtract(1));  // This gets the last year.\n\n// print(\"Year of interest\", yoi);\n\n// -------------------------------------------------------------\n//  Filter NAIP image collection by aoi, year, and number of bands.\n// -------------------------------------------------------------\n\nvar ic = ee.ImageCollection(\"USDA/NAIP/DOQQ\")\n  .filterBounds(aoi)\n  .filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n  .map(geo.icNAIP.setNumberOfBands)\n  .filter(ee.Filter.eq(\"number_of_bands\", 4))\n  ;\n\n// geo.icGather.inspectCollection(\"NAIP Collection\", ic);\n\n// -------------------------------------------------------------\n//  Mosaic image collection.\n// -------------------------------------------------------------\n\nvar ic_mosaic = geo.icFlatten.mosaicToImage(ic);\n\n// print(\"Mosaic\", ic_mosaic);\n\n// -------------------------------------------------------------\n//  Define viz dictionaries.\n// -------------------------------------------------------------\n\nvar rgb_viz_natural = \n    {\n        bands:  ['R', 'G', 'B'],      \n        min:    [0, 0, 0],        \n        max: [255, 255, 255],\n        gamma: [1,1,1]    \n    }\n;\n\nvar rgb_viz_false = \n    {\n        bands:  ['N', 'R', 'G'],      \n        min:    [0, 0, 0],        \n        max: [255, 255, 255],\n        gamma: [1,1,1]    \n    }\n;\n\n// -------------------------------------------------------------\n//  Refine viz dictionaries with histogram.\n// -------------------------------------------------------------\n\n// To refine natural image.\nvar histogram = geo.iCart.iHistogramRGB(ic_mosaic, rgb_viz_natural);\n\n// // To refine false image.\n// var histogram = geo.iCart.iHistogramRGB(ic_mosaic, rgb_viz_false);\n\nprint(histogram);\n\n// -------------------------------------------------------------\n//  Display as Map layers. \n// -------------------------------------------------------------\n\nMap.addLayer(ic_mosaic,rgb_viz_false,\"Earliest False Color\",true);\nMap.addLayer(ic_mosaic,rgb_viz_natural,\"Earliest Natural Color \",true);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"starters/landsat/","title":"Landsat","text":"<p>STARTERS </p>"},{"location":"starters/landsat/#landsat","title":"Landsat","text":"<p>Earth Engine provides a number of different Landsat products as cloud assets.</p> <p>The starter scripts on this page will help you quickly find and process collection 2, tier 1, level 2, surface reflectance data for a place and time of interest.  </p> <p>Since that was a mouthful, let\u2019s define some key terms first.</p>"},{"location":"starters/landsat/#key-terms","title":"key terms","text":""},{"location":"starters/landsat/#collections","title":"collections","text":"<p>There have been two major reprocessing efforts by USGS to improve data quality. Collection 2 is the most recent and has the best geolocation accuracy which improves time series analyses.    </p>"},{"location":"starters/landsat/#tiers","title":"tiers","text":"<p>Within a collection, Tier 1 data have the highest radiometric and positional quality. USGS recommends using Tier 1 data for all time-series analysis.  </p>"},{"location":"starters/landsat/#levels","title":"levels","text":"<p>The level of data processing applied to products.    </p> <ul> <li> <p>Level-1 includes processing to improve locational accuracy of data.  </p> </li> <li> <p>Level-2 products are built from Level 1, but also provide atmospheric correction to create surface reflectance and surface temperature products. Level-2 science products also include spectral indices derived from surface reflectance products.  </p> </li> <li> <p>Level-3 products are built from Level-2 products and include Analysis Ready Data (ARD), including Fractional Snow Covered Area and Burned Area, and Scene-based Inputs, including Provisional Actual Evapotranspiration.   </p> </li> </ul>"},{"location":"starters/landsat/#orbit","title":"orbit","text":"<p>This video visualizes the path of Landsat 8 around the globe. Please note that some details about satellite orbits differ between Landsat missions.</p>"},{"location":"starters/landsat/#spectral-bands","title":"spectral bands","text":"<p>The chart below compares the bands of each mission with respect to spectral and spatial resolution.</p> <p> </p>"},{"location":"starters/landsat/#mother-of-landsat","title":"mother of landsat","text":"<p>Please read Virginia Tower Norwood\u2019s biography.   </p>"},{"location":"starters/landsat/#prereqs","title":"prereqs","text":"<p>To thoughtfully use the starter scripts below, you should be able to answer these questions:  </p> <ul> <li>what is surface reflectance and how does this differ from other Landsat products available through Earth Engine catalog? </li> <li>what is the mission duration (start and end of image collection)?  </li> <li>what is the recurrence time of each scene (how may days between images)?  </li> <li>how does the satellite orbit affect the time difference between neighboring scenes?   </li> <li>what time of day is the scene captured as an image?  </li> <li>what portion of the EM spectrum does each band measure?  </li> <li>what is the spatial resolution of each band?  </li> </ul>"},{"location":"starters/landsat/#snapshots","title":"snapshots","text":"<p>These scripts will help you get started making snapshots from Landsat collections.  </p>"},{"location":"starters/landsat/#landsat-5","title":"Landsat 5","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L5.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/4/2024\n//\n//  Starter for Landsat 5 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ------------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ------------------------------------------------------------------------\n\nvar geometry = \n    ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ------------------------------------------------------------------------\n//  Filter and flatten image collection.   \n// ------------------------------------------------------------------------\n\nvar output = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2')\n  .filterBounds(geometry)\n  // .filter(ee.Filter.calendarRange(1995, 1995, 'year'))\n  .filter(ee.Filter.calendarRange(1, 3, 'month'))\n  // .filter(ee.Filter.calendarRange(1, 1, 'day_of_year'))\n  .filter(ee.Filter.lt('CLOUD_COVER', 20))\n  .map(geo.icLandsat.scale_L5)\n  .map(geo.icLandsat.cloudMask_L5)\n  .median()\n;\n\nprint(\"Landsat 5 image\", output);\n\n// ------------------------------------------------------------------------\n//  Display layer on Map.\n// ------------------------------------------------------------------------\n\nvar viz = {\n  bands: ['SR_B3', 'SR_B2', 'SR_B1'],\n  min: [0.0, 0.0, 0.0],\n  max: [0.3, 0.3, 0.3],\n};\n\nMap.addLayer(output, viz, 'Landsat 5 image');\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictinary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(select_band, 30, aoi);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/landsat/#landsat-7","title":"Landsat 7","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L7.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/4/2024\n//\n//  Starter for Landsat 7 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ------------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ------------------------------------------------------------------------\n\nvar geometry = \n    ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ------------------------------------------------------------------------\n//  Filter and flatten image collection.   \n// ------------------------------------------------------------------------\n\nvar output = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2')\n  .filterBounds(geometry)\n  // .filter(ee.Filter.calendarRange(2000, 2000, 'year'))     // January 1999\u2013April 2022\n  .filter(ee.Filter.calendarRange(1, 3, 'month'))\n  // .filter(ee.Filter.calendarRange(1, 1, 'day_of_year'))\n  // .filter(ee.Filter.lt('CLOUD_COVER', 20))\n  .map(geo.icLandsat.scale_L7)\n  .map(geo.icLandsat.cloudMask_L7)\n  .median()\n;\n\nprint(\"Landsat 7 image\", output);\n\n// ------------------------------------------------------------------------\n//  Display as layer on Map.\n// ------------------------------------------------------------------------\n\nvar viz = {\n  bands: ['SR_B3', 'SR_B2', 'SR_B1'],\n  min: [0.0, 0.0, 0.0],\n  max: [0.3, 0.3, 0.3]\n};\n\nMap.addLayer(output, viz, 'Landsat 7 image');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictinary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(select_band, 30, aoi);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/landsat/#landsat-8","title":"Landsat 8","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L8.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/4/2024\n//\n//  Starter for Landsat 8 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ------------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ------------------------------------------------------------------------\n\nvar geometry = \n    ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ----------------------------------------------------------------------\n//  Filter and flatten image collection. \n// ----------------------------------------------------------------------\n\nvar output = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n  .filterBounds(geometry)\n  // .filter(ee.Filter.calendarRange(2015, 2015, 'year'))\n  .filter(ee.Filter.calendarRange(1, 3, 'month')) \n  // .filter(ee.Filter.calendarRange(1, 1, 'day_of_year')) \n  // .filter(ee.Filter.lt('CLOUD_COVER',20))\n  .map(geo.icLandsat.scale_L8)\n  .map(geo.icLandsat.cloudMask_L8)\n  .median()\n;\n\nprint(\"Landsat 8 image\", output);\n\n// ----------------------------------------------------------------------\n//  Display as layer on Map.\n// ----------------------------------------------------------------------\n\nvar viz = {\n  bands: ['SR_B4', 'SR_B3', 'SR_B2'],\n  min: [0.0, 0.0, 0.0],\n  max: [0.25, 0.25, 0.25],\n};\n\nMap.addLayer(output, viz, 'Landsat 8 image');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictinary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(select_band, 30, aoi);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/landsat/#landsat-9","title":"Landsat 9","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L9.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/4/2024\n//\n//  Starter for Landsat 9 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ------------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ------------------------------------------------------------------------\n\nvar geometry = \n    ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n\n// ----------------------------------------------------------------------\n//  Filter and flatten image collection.\n// ----------------------------------------------------------------------\n\nvar output = ee.ImageCollection(\"LANDSAT/LC09/C02/T1_L2\")\n  .filterBounds(geometry)\n  // .filter(ee.Filter.calendarRange(2022, 2022, 'year'))\n  .filter(ee.Filter.calendarRange(1, 3, 'month')) \n  // .filter(ee.Filter.calendarRange(1, 1, 'day_of_year')) \n  // .filter(ee.Filter.lt('CLOUD_COVER',20))\n  .map(geo.icLandsat.scale_L9)\n  .map(geo.icLandsat.cloudMask_L9)\n  .median()\n;\n\nprint(\"Landsat 9 image\", output);\n\n// ----------------------------------------------------------------------\n//  Display image as layer on Map.\n// ----------------------------------------------------------------------\n\nvar viz = {\n  bands: ['SR_B4', 'SR_B3', 'SR_B2'],\n  min: [0.0, 0.0, 0.0],\n  max: [0.25, 0.25, 0.25],\n};\n\nMap.addLayer(output, viz, 'Landsat 9 image');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictinary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(select_band, 30, aoi);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/landsat/#land-surface-temperature","title":"Land Surface Temperature","text":"<p>Sofia Ermida wrote and shared a super helpful module that makes it relatively easy to compute land surface temperature (LST) from Landsat collections. The script below outlines a basic pattern for using her module.  </p> <pre><code>// Load module to compute LST from Landsat.\n\nvar LandsatLST = require('users/sofiaermida/landsat_smw_lst:modules/Landsat_LST.js');\n\n// Define arguments for LST module. \n\nvar date_start = '2020-07-01';            // Filter collection by time start.\nvar date_end = '2024-09-01';              // Filter collection by time end.\nvar region = aoi;                         // Filter collection by location.\nvar use_ndvi = true;                      // Use NDVI in computation (true or false)\n\n// Compute LST from Landsat 9.  \n\nvar L9 = LandsatLST\n  .collection\n    (\n      'L9',                               // Landsat mission  - note this is a string 'L9'.\n      date_start,                         \n      date_end,                        \n      region,                               \n      use_ndvi                                \n    )\n;\n</code></pre> <p>Note that you call the Landsat mission with a string:  </p> <ul> <li><code>\"L9\"</code> calls Landsat 9  </li> <li><code>\"L8\"</code> calls Landsat 8  </li> <li><code>\"L7\"</code> calls Landsat 7   </li> <li><code>\"L5\"</code> calls Landsat 5   </li> </ul> <p>Sofia\u2019s script pulls data from both surface reflectance and top of atmosphere Landsat collections, so behind the scenes the string that you enter as an argument points to a set of instructions for working with that mission data that the module carries out. The underlying code is public-facing on her github site if you would like to understand in detail how it works. You can also read her article on the module if you would like to learn more.  </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"starters/sentinel/","title":"Sentinel","text":"<p>STARTERS </p>"},{"location":"starters/sentinel/#sentinel","title":"Sentinel","text":"<p>Earth Engine provides a number of different Sentinel products as cloud assets.</p>"},{"location":"starters/sentinel/#sentinel-2-msi","title":"Sentinel-2 MSI","text":"<p>The starter below will help you quickly find and process Level 1-C Harmonized Surface Reflectance data from the Sentinel 2 Multispectral Instrument (MSI). </p>"},{"location":"starters/sentinel/#prereqs","title":"prereqs","text":"<p>To thoughtfully use the starter script below, you should be able to answer these questions:</p> <ul> <li>what is surface reflectance and how does this differ from other Sentinel products available through Earth Engine catalog?</li> <li>why is harmonized data helpful for time series analysis?  </li> <li>what is the mission duration (start and end of image collection)?</li> <li>what is the recurrence time of each scene (how may days between images)?</li> <li>how does the satellite orbit affect the time difference between neighboring scenes?</li> <li>what time of day is the scene captured as an image?</li> <li>what portion of the EM spectrum does each band measure?</li> <li>what is the spatial resolution of each band?</li> </ul> <p>You can glean much of this info from these resources:  </p> <ul> <li>Earth Engine data catalog </li> <li>ESA Copernicus page </li> <li>Sentinel 2 on SentiWiki </li> </ul>"},{"location":"starters/sentinel/#spectral-bands","title":"spectral bands","text":"<p>The chart below shows how the MSI sensor on Sentinel compares to the sensors onboard the Landsat missions.  </p> <p></p>"},{"location":"starters/sentinel/#starter","title":"starter","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_S2.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/12/2023\n//\n//  Starter for harmonized Sentinel 2 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ----------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ----------------------------------------------------------------------\n\nvar geometry = \n    ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 9);\n\n// ----------------------------------------------------------------------\n//  Filter and flatten image collection.\n// ----------------------------------------------------------------------\n\nvar output = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n  .filterBounds(geometry)\n  // .filter(ee.Filter.calendarRange(2020, 2020, 'year'))\n  .filter(ee.Filter.calendarRange(1, 3, 'month')) \n  // .filter(ee.Filter.calendarRange(1, 30, 'day')) \n  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))\n  .map(geo.icSentinel.cloudMask_S2)\n  .map(geo.icSentinel.scale_S2)\n  .median()\n;\n\nprint(output);\n\n// ----------------------------------------------------------------------\n//  Display layer on Map. \n// ----------------------------------------------------------------------\n\n// Print list of band names for S2.\n\nprint(\n  \"S2 BAND LIST\",\n  geo.icSentinel.bands_S2\n);\n\n// Define viz parameters. \n\nvar viz = {\n  bands: ['B4', 'B3', 'B2'],\n  min: [0, 0, 0],\n  max: [0.2, 0.15, 0.1]\n};\n\n// Add layer to Map. \n\nMap.addLayer(output, viz, 'From Sentinel 2 Collection');\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictionary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Get scale from map extent.\n\nvar scale =  Map.getScale();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(\n    select_band, \n    scale,\n    aoi                 \n);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"}]}