{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ee pattern book","text":"<p>A collection of timeless problems of spatial analysis and image processing and how to solve them with Google Earth Engine.      </p> <p>Jeff Howarth Associate Professor of Geography  Geography Department Middlebury College Vermont, USA</p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"geo-module/","title":"geo module","text":"<p>The geo module is a collection of methods that I am writing and packaging in a way that will allow you to use the methods without having to write them from scratch. </p> <p>I wrote these methods for two reasons:    </p> <ol> <li> <p>Each represents a recurring task of geospatial analysis that is supported by other geographic information systems (like QGIS or ArcGIS).</p> </li> <li> <p>Each requires a chain of transformations to make in Earth Engine which can be conceptually confusing and technically difficult for novices to do.    </p> </li> </ol> <p>My hope is that providing ready-made methods may help you focus on how different methods of spatial analysis and cartography work conceptually in workflows without having to get bogged down in writing complicated task chains for common tools.  </p>"},{"location":"geo-module/#import-module","title":"import module","text":"<p>To use the module, create a container and require the module. </p> <pre><code>var geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n</code></pre> <p>The code block above will import the module and print the module\u2019s help dictionary and palette dictionary to the Console. The help dictionary lists all methods and url links to their docs. The palette dictionary lists all palettes in the module. You only need to import the module once in a script that calls a method or palette from the module. I usually place the above code snippet near the top of my script (under the header).  </p>"},{"location":"geo-module/#docs-in-eepatterns","title":"docs in eePatterns","text":"<p>A globe icon  identifies methods from module. </p> <p>In the METHODS documentation, the  symbol identifies a method that requires the geo module. To use any of these methods, you will need to include the import module in your script prior to calling the method. </p>"},{"location":"geo-module/#peak-under-hood","title":"peak under hood","text":"<p>Add module to your READER tray if you want to see the underlying code to any method.</p> <p>The module only hides the code from you if you do not want to see it. If you would like to look under the hood, I have made the code for the module public and you can add it to the READER tray of the IDE by clicking here. </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"intro/","title":"introduction","text":"<p>This book aims to help you create geospatial workflows with Google Earth Engine.  </p> <p>In general, these workflows grab geographic data stored in the cloud, alter it (with purpose), and then visualize the results as map layers.  </p> <p> <pre><code>graph LR\n  step01[(\"GEOGRAPHIC\\nDATA\\n\\n stored in cloud\")] ;\n  step02&gt;\"GEOSPATIAL WORKFLOW\\n\\n alter and visualize\"] ;\n\n  step01 --&gt; step02\n\n  classDef store fill:#4AA8A0,stroke-width:0px,color:#FFFFFF; \n  classDef transform fill:#4A92A8,stroke-width:0px,color:#FFFFFF;\n\n  class step01 store; \n  class step02 transform;\n\n</code></pre> <p></p> <p>To do this, we will use a web-based Integrated Development Environment (IDE) for the Earth Engine Javascript Application Programming Interface (API). That is a mouthful, but in practical terms it means that we will create workflows by writing scripts with javascript.   </p>"},{"location":"intro/#data-transformation","title":"data transformation","text":"<p>The basic element of all geospatial workflows is a three step process that Waldo Tobler called a cartographic transformation: you start with geographic data in a certain state (input), you do something to alter the data (method), and you store the result (output). Often but not always, one or more options (arguments) constrain how a method alters the input.   </p> <p> <pre><code>graph LR\n\n  input[\"INPUT\"] ;\n  method(\"METHOD\") ;\n  output[/\"OUTPUT\"/]  ;\n\n  input --&gt; method --&gt; output\n\n  arg[\"argument\"] ;\n\n  arg --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg; </code></pre> <p></p>"},{"location":"intro/#statements","title":"statements","text":"<p>With JavaScript, we transform geographic data by writing a statement. The syntax generally takes this form:</p> <pre><code>var output = input.method(argument);\n</code></pre> <p>The general pattern is that you start by defining a name for a container that you would like to make so that you can store the output. This container of data is called a variable that you create with the keyword <code>var</code>. You then say that this container will contain <code>=</code> what results from taking the input and applying a method to it <code>.</code> with one or more arguments <code>()</code>. A semicolon <code>;</code> punctuates a statement like a period (or wink ).  </p>"},{"location":"intro/#task-tree","title":"task tree","text":"<p>Workflows are a means to achieving an end. When you sit down to write a workflow, you have some goal state for the data in mind. Your problem is to figure out how to change the data from their original condition to the goal state in your head.  </p> <p>Most workflows can be decomposed into a task tree: at the top, a (big) problem  may be broken down into a sequence of smaller tasks, each of these tasks may be broken down into smaller subtasks.    </p> <pre><code>graph TD\n\n  L01(\"PROBLEM\") ;\n  L11[\"TASK 1\"] ;\n  L12[\"TASK 2\"] ;\n  L21[\"SUBTASK 1\"] ;\n  L22[\"SUBTASK 2\"] ;\n  L23[\"SUBTASK 3\"] ;\n  L24[\"SUBTASK 4\"] ;\n\n  L01 --- L11 \n  L01 --- L12\n  L11 --- L21\n  L11 --- L22\n  L12 --- L23\n  L12 --- L24\n\n  classDef L0 fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef L1 fill:#CCCCCC,stroke-width:0px,color:#000000;\n  classDef L2 fill:#000000,stroke-width:0px,color:#FFFFFF;  \n\n  class L01 L0; \n  class L11 L1;\n  class L12 L1;\n  class L21 L2;\n  class L22 L2;\n  class L23 L2;\n  class L24 L2;\n\n</code></pre> <p></p>"},{"location":"intro/#task-chain","title":"task chain","text":"<p>The lowest branches of the tree are individual transformations, the foundational elements of a workflow. Higher branches of the tree often require linking together two or more transformations as a task chain, where the output of one transformation becomes the input of another. </p> <p> <pre><code>graph LR\n  step01(\"INPUT\") ;\n  step02[\"METHOD\"] ;\n  step03(\"OUTPUT\")  ;\n  step04[\"METHOD_2\"] ;\n  step05(\"OUTPUT_2\")  ;\n  arg01(\"argument\") ;\n  arg02(\"argument_2\") ;\n\n  step01 --&gt; step02 --&gt; step03 --&gt; step04 --&gt; step05\n  arg01 --- step02\n  arg02 --- step04\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class step04 op;\n  class step05 in-out;\n  class arg01 arg;\n  class arg02 arg;\n\n</code></pre> <p></p>"},{"location":"intro/#summary","title":"summary","text":"<p>If this all sounds a bit wonky, do not worry too much. We will get to examples that illustrate all of this soon. For now, I just want you to know:  </p> <ol> <li>a workflow is a chain of input-method-output transformations </li> <li>you can think of a workflow visually (as a flow diagram) and verbally (as javascript).  </li> <li>visually, a workflow contains a vertical hierarchy of purpose (task tree) and a horizontal sequence of transformations (task chains). </li> </ol> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"three-t/","title":"the three Ts","text":"<p>Writing geospatial workflows brings together three domains:  </p> <ol> <li> <p>Thematic: the vocabulary, concepts, principles, theories, etc. of your application domain; the academic discipline, professional context, etc that defines the terms and beliefs of your inquiry.  </p> </li> <li> <p>Technical: the concepts and methods of the geographic information software that you are using to develop your workflows. For example, Google Earth Engine Javascript API, ArcGIS Pro, QGIS, GDAL, etc.</p> </li> <li> <p>Theoretical: the timeless concepts and methods of geospatial analysis and cartography; the body of knowledge that you need to understand to solve geospatial problems regardless of the thematic or technical domains that you are working in. </p> </li> </ol> <p>more soon</p>"},{"location":"three-t/#conceptual-models","title":"conceptual models","text":"<p>A key idea in geospatial workflows is that you can represent the world as a series of map layers for computation and comparison. So it is helpful to become familiar with the relatively small set of conceptual models that geospatial workflows tend to employ as instruments for representing the world as map layers.  </p> <p></p>"},{"location":"three-t/#data-models","title":"data models","text":"<p>When you develop geospatial workflows, your recurring task is to move between conceptual models and data models. In other words, you conceptualize a way to represent geography and then you implement this concept with a data model. </p> <p>more soon </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/RGB-composites/","title":"RGB composites","text":"<p>PATTERNS </p>"},{"location":"patterns/RGB-composites/#rgb-composites","title":"RGB composites","text":""},{"location":"patterns/RGB-composites/#additive-color-system","title":"additive color system","text":"<p>RGB composites use additive color to display raster data values in three bands at once. </p> <p>More soon.</p> <p>Use the RGB mixer below to create the colors by adding values in Red, Green, and Blue channels.  </p> <p> </p> <p>Open app in new browser window </p> <p>Here is the key for primary and secondary additive colors.  </p> <p> </p>"},{"location":"patterns/RGB-composites/#rgb-viz","title":"RGB viz","text":"<p>This is a basic pattern to visualize multi-band images as a combination of red, green, and blue channels.  </p> <pre><code>var rgb_viz = {\nbands:  ['red', 'green', 'blue'],      min:    [0, 0, 0],        max: [255, 255, 255],\ngamma: [1,1,1]    }\n;\n</code></pre> <p>The gamma property bends the function that maps display values to data values in order to lighten or darken the midtones of the image. Lowering the gamma value (towards 0) darkens the image, while raising the gamma value (towards 2) lightens the image.  </p> <p>The min, max, and gamma values can be adjusted separately for each band. </p>"},{"location":"patterns/RGB-composites/#natural-and-false-color","title":"natural and false color","text":"<p>A natural color image displays reflectance in the Red, Green, and Blue bands of the EM spectrum using the Red, Green, and Blue color channels, respectively. The result looks roughly similar to what we see when we have a window seat and the shade up. </p> <p>A false color image breaks this like-to-like mapping of the EM spectrum to additive color. For example, the near infrared (NIR) false color image displays reflectance in NIR, Red, and Green bands of the EM spectrum to the Red, Green, and Blue color channels. respectively. The result looks different from our experience, but is often helpful for distinguishing different types of vegetation and surfaces that otherwise look \u2018green\u2019 in natural color composites.  </p> <p>Importantly, a NIR false color image is just one example of a false color image. Many other false color images display reflectance in shortwave infrared (SWIR), sometimes called mid-range infrared, that are useful in wide range of applications. </p> <p>To better understand how false color images work, please read:</p> <ul> <li>Why is that Forest Red and that Cloud Blue? How to Interpret a False-Color Satellite Image </li> </ul> <p>This is an old but still helpful reference for exploring different band combinations for false color:  </p> <ul> <li>Landsat band combinations </li> </ul>"},{"location":"patterns/RGB-composites/#chart-spectral-signatures","title":"chart spectral signatures","text":"<p>To interpret and explain why false color images look the way they do, it can be helpful to chart the spectral signature of locations in an image.  </p> <p>If you add the appropriate pattern below to the end of a script that produces an image from a Landsat collection, you should be able to click on locations on the Map and chart the spectral signature of each location.    </p>"},{"location":"patterns/RGB-composites/#landsat-5","title":"Landsat 5","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from L5 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\nconfig.poi = ee.Geometry.Point(coords.lon, coords.lat);\nsamples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\npanel_chart.clear();\npanel_chart.add(geo.icLandsat.chartSpectralSignatureL5(\noutput,                             // Name of L5 image ('output' assumes you are using starter script).\nsamples\n));\n}\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#landsat-7","title":"Landsat 7","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from L7 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\nconfig.poi = ee.Geometry.Point(coords.lon, coords.lat);\nsamples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\npanel_chart.clear();\npanel_chart.add(geo.icLandsat.chartSpectralSignatureL7(\noutput,                             // Name of L7 image ('output' assumes you are using starter script).\nsamples\n));\n}\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#landsat-8","title":"Landsat 8","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from L8 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\nconfig.poi = ee.Geometry.Point(coords.lon, coords.lat);\nsamples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\npanel_chart.clear();\npanel_chart.add(geo.icLandsat.chartSpectralSignatureL8(\noutput,                             // Name of L8 image ('output' assumes you are using starter script).\nsamples\n));\n}\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#landsat-9","title":"Landsat 9","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from L9 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\nconfig.poi = ee.Geometry.Point(coords.lon, coords.lat);\nsamples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\npanel_chart.clear();\npanel_chart.add(geo.icLandsat.chartSpectralSignatureL9(\noutput,                             // Name of the L9 image ('output' assumes you are using starter script).\nsamples\n));\n}\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#modis","title":"MODIS","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from MODIS image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\nconfig.poi = ee.Geometry.Point(coords.lon, coords.lat);\nsamples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\npanel_chart.clear();\npanel_chart.add(geo.icMODIS.chartSpectralSignatureMODIS(\noutput,                             // Name of the MODIS image ('output' assumes you are using starter script).\nsamples\n));\n}\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre>"},{"location":"patterns/RGB-composites/#sentinel-2","title":"Sentinel 2","text":"<pre><code>// -------------------------------------------------------------\n//  Click to chart spectral signatures from S2 image.\n// -------------------------------------------------------------\n\nvar config = {};\nvar panel_chart = ui.Panel({style: {position: 'bottom-left'}});\nvar samples = [];\n\nMap.onClick(function(coords) {          // To embed in app, change \"Map\" to \"left_Map\" or \"right_Map\".\n\nconfig.poi = ee.Geometry.Point(coords.lon, coords.lat);\nsamples.push(ee.Feature(config.poi, {'sample': samples.length}));\n\npanel_chart.clear();\npanel_chart.add(geo.icSentinel.chartSpectralSignatureS2(\noutput,                             // Name of the S2 image ('output' assumes you are using starter script).\nsamples\n));\n}\n);\n\nMap.add(panel_chart);                   // To embed in app, change \"Map\" to \"side_bar\".\n</code></pre> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"patterns/composite-mosaic/","title":"flatten collections","text":"<p>PATTERNS</p>"},{"location":"patterns/composite-mosaic/#flatten-image-collections","title":"flatten image collections","text":"<p>Many workflows for image collections will include a step that transforms an image collection into a single image (and flattens the collection).  </p>"},{"location":"patterns/composite-mosaic/#composite-image","title":"composite image","text":"<p>If the collection represents a time series of satellite scenes, the workflow will often include a step that makes a composite image. This reduces the image collection to a single image.  </p> <p>Conceptually, composite methods are analogous to local operations for images because they perform calculations for each pixel across a stack of images. The main difference is that the stack of images in a collection can be quite large and not restricted to  comparisons of just two images.  </p> <p>diagram forthcoming </p>"},{"location":"patterns/composite-mosaic/#statistical-composites","title":"statistical composites","text":"<p>These methods calculate a statistic of all values at each pixel across a stack of all matching bands.  </p> <pre><code>var mean_collection = ic.mean();\n\nprint(\"Composite collection by mean\", mean_collection);\n</code></pre> <p>The example above calculates the mean value in each pixel across the stack of matching bands in the ic. Here are some other common statistical composites. </p> <pre><code>var median_collection = ic.median();\n\nprint(\"Composite collection by median\", median_collection);\n</code></pre> <pre><code>var max_collection = ic.max();\n\nprint(\"Composite collection by max\", max_collection);\n</code></pre> <pre><code>var min_collection = ic.min();\n\nprint(\"Composite collection by min\", min_collection);\n</code></pre> <pre><code>// Mode is the most common value at each pixel. \n\nvar mode_collection = ic.mode();\n\nprint(\"Composite collection by mode\", mode_collection);\n</code></pre>"},{"location":"patterns/composite-mosaic/#mosaic-image","title":"mosaic image","text":"<p>If the collection contains a set of small tiles, then a workflow will often include a step that makes a mosaic image. This is a common step in workflows with lidar products.  </p> <p></p> <p> <pre><code>graph LR\n\n  method(\"geo.icFlatten.mosaicToImage()\") ;\n  output[/\"ic_mosaic\"/]  ;\n\n  method --&gt; output\n\n  arg[\"ic\"] ;\n\n  arg --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg; </code></pre> <p></p> <pre><code>var ic_mosaic = geo.icFlatten.mosaicToImage(ic);\n\nprint(\"Mosaic\", ic_mosaic);\n</code></pre> <p>This method mosaics the tiles into a single image and gives the new image the same coordinate reference system as the first image in the collection. The crs defines the xy units of the image and this enables you to use the mosaic image as an input in terrain operations.  </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/convert-data/","title":"convert data","text":"<p>PATTERNS</p>"},{"location":"patterns/convert-data/#convert-data","title":"convert data","text":"<p>These methods change the models used to represent geographic data and include:</p> <ul> <li>vector to raster</li> <li>raster to vector</li> </ul>"},{"location":"patterns/convert-data/#vector-to-raster","title":"vector to raster","text":"<p>These methods typically convert feature collections to images. </p> <p>more soon </p>"},{"location":"patterns/convert-data/#any-fc-to-boolean-raster","title":"any FC to boolean raster","text":"<p>This method converts a feature collection into a boolean raster. </p> <pre><code>var image_boolean = geo.fcConvert.toBooleanImage(fc);\n</code></pre>"},{"location":"patterns/convert-data/#nominal-fc-to-integer-raster","title":"nominal FC to integer raster","text":"<p>This method converts a feature collection with text attributes to a single-band image. It essentially creates a list of unique text attributes from a table column (defined by \u201ccolumn_name\u201d) and matches each unique text attribute to a unique integer. The result is an image with integer pixel values. The method also prints a dictionary to the Console that reports the integer code for each unique attribute.   </p> <pre><code>var image_nominal = geo.fcConvert.toNominalImage(fc, \"column_name\");\n</code></pre>"},{"location":"patterns/convert-data/#numeric-fc-to-numeric-raster","title":"numeric FC to numeric raster","text":"<p>This method uses numeric attribute data in a feature collection to create a raster. </p> <pre><code>var image_numeric = geo.fcConvert.toNumericImage(fc, \"column_name\", \"reducer\");\n</code></pre> <p>The method takes three arguments that are defined in the table below.  </p> ARGUMENTS DESCRIPTION fc The feature collection to convert. \u201ccolumn_name\u201d The name of the column with the numeric data to populate the pixel values of the output raster. \u201creducer\u201d How you would like to handle cases where two of more features overlap. Essentially, what value do you want to populate a pixel with when there is more than one number? This must be a string and one of the following: \u201cmean\u201d, \u201cfirst\u201d, \u201cmax\u201d, \u201cmin\u201d."},{"location":"patterns/convert-data/#raster-to-vector","title":"raster to vector","text":"<p>These methods typically convert images to feature collections.  </p> <p>more soon </p>"},{"location":"patterns/convert-data/#make-objects-with-vectors","title":"make objects with vectors","text":"<p>This method identifies objects from rasters based on two conditions: </p> <p>(1) Pixels share the same value. (2) Pixels form contiguous regions that can be represented with a polygon.  </p> <p>It returns a feature collection of distinct regions and includes the area as an attribute of each feature.  </p> <pre><code>var objects_with_vectors = geo.iConvert.makeObjectsWithVectors(image, \"property\", scale, extent, \"unit\");\n</code></pre> ARGUMENTS DESCRIPTION image Input image with a band that represent boolean or nominal (class) raster to clump. \u201cproperty\u201d A description (as a string) of the boolean or class data used to clump. Flr example, \u201cclass\u201d. scale Scale of analysis to help troubleshoot TIME OUT errors. Often good practice to start relatively coarse and then increase resolution in later runs. extent The area of interest or study region to constrain analysis. \u201cunit\u201d Choose between \u201cacres\u201d, \u201csq_m\u201d, and \u201csq_km\u201d <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/customize-Map/","title":"customize Map","text":"<p>PATTERNS</p>"},{"location":"patterns/customize-Map/#customize-map","title":"customize Map","text":"<p>It is often helpful to customize the Map so that it centers and zooms on your area of interest and uses a base map that supports your purpose.  </p> <p>The diagram below shows a general pattern.</p> <p> <pre><code>graph LR\n\n  step01(\"Set map center and zoom\") ;\n  step02(\"Set base map style\") ;\n\n  step01 --&gt; step02\n\n  classDef task fill:#C3C8E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>It is good practice to set the map center and zoom level before setting the base map so that the base map does not need to redraw.</p>"},{"location":"patterns/customize-Map/#set-map-center-and-zoom","title":"set map center and zoom","text":"<p>Use a data object to center the map and to suggest an appropriate zoom level. </p> <pre><code>Map.centerObject(\nobject,             // data object to center the Map. \n16                  // zoom level to display the Map.\n);\n</code></pre>"},{"location":"patterns/customize-Map/#set-basemap-style","title":"set basemap style","text":"<p>Select a basemap that provides the most helpful reference information from your data. </p> <pre><code>Map.setOptions(\"HYBRID\");\n</code></pre> <p>Choose from the following options: </p> <p><pre><code>\"ROADMAP\" </code></pre> <pre><code>\"SATELLITE\" </code></pre> <pre><code>\"HYBRID\"\n</code></pre> <pre><code>\"TERRAIN\" </code></pre></p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/explain-code/","title":"explain code","text":"<p>PATTERNS</p>"},{"location":"patterns/explain-code/#explain-code","title":"explain code","text":"<p>Always write your code for two main audiences: </p> <ol> <li>a computer that will compile and execute your code;</li> <li>a person who will read your code and try to make sense of it. </li> </ol> <p>The second audience may be yourself in the future, when you return to a script that you wrote after some time has passed. It may be an instructor in this course who wants to help you troubleshoot something in your script that is not working. Or it may be someone you have never met who is looking to adapt and recycle parts of your script for a slightly different purpose. Whoever the reader may be, you should always aim to help people read your code by placing explanations directly in your workflow. </p> <p>The patterns below describe different ways to explain your code and make it more readable for a human audience. </p>"},{"location":"patterns/explain-code/#script-header","title":"script header","text":"<p>Write a header at the top of your script.</p> <p>At a minimum, the header should identify who wrote the script, when they wrote it, and why they wrote it. This is also where many authors will define the license for the script.  </p> <p>I usually include a couple lines of repeating symbols to visually block the header and separate it from the rest of the script.  </p> <pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     \n    TITLE:  \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n</code></pre>"},{"location":"patterns/explain-code/#task-description","title":"task description","text":"<p>Write a line comment before each major task in your workflow.</p> <p>Describe what you are doing or why you are doing it. Use full sentences and correct punctuation (start each comment with a capital letter and end each comment with a period).  </p> <p>I usually include a line of repeating symbols above and below the task description to help visually separate the code into discrete chunks.  </p> <pre><code>// -------------------------------------------------------------\n//  To illustrate a task description.\n// -------------------------------------------------------------\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/explain-symbology/","title":"explain symbology","text":"<p>PATTERNS</p>"},{"location":"patterns/explain-symbology/#explain-layer-symbology","title":"explain layer symbology","text":"<p>Methods for defining what colors in palettes mean on your map.  </p> <p>more forthcoming </p>"},{"location":"patterns/explain-symbology/#define-colors-with-legend","title":"define colors with legend","text":"<p>These methods take some or all of the following arguments.</p> ARGUMENT DESCRIPTION \u201ctitle\u201d Label for the legend. Must be a string. Often a short description of image will do. viz The viz dictionary that defines how to visualize (display) the data. class_labels A list of names for each color in the palette that define the classes or categories of the data. \u201cposition-on-map\u201d Where to place the legend. Must be a string. Composed as \u201crow - column\u201d, where rows are \u201cbottom\u201d, \u201cmiddle\u201d, or \u201ctop\u201d and columns are \u201cleft\u201d, \u201ccenter\u201d, \u201cright\u201d. For example, \u201cbottom-right\u201d. There is no \u201cmiddle-center\u201d."},{"location":"patterns/explain-symbology/#image-with-continuous-data","title":"image with continuous data","text":"<p>If the image contains continuous or cyclical data, place a snapshot of the color gradient on the Map with labels that identify the minimum, maximum, and midpoint data value mapped to the color gradient. </p> <pre><code>// Make legend from image with continuous data. \n\nvar legend_continuous = geo.iCart.legendContinuous(\n\"title\", viz, \"position-on-map\"\n)\n;\n\n// Add legend to Map.  \n\nMap.add(legend_continuous);\n</code></pre>"},{"location":"patterns/explain-symbology/#from-image-with-nominal-data","title":"from image with nominal data","text":"<p>If the image contains nominal (discrete) data, place a symbol dictionary that defines each swatch of the palette with a label, or name for the class.     </p> <pre><code>// Make legend from image with nominal data.\n\nvar legend_nominal = geo.iCart.legendNominal(\n\"title\", viz, class_labels, \"position-on-map\"\n)\n;\n\n// Add legend to Map.  \n\nMap.add(legend_nominal);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/export/","title":"export data","text":"<p>PATTERNS</p>"},{"location":"patterns/export/#export-data","title":"export data","text":"<p>Earth Engine does not permanently store the data objects that you make in your workflows unless you specifically ask it to do so. The patterns below deal with two different scenarios:  </p> <ol> <li>exporting data to a cloud asset</li> <li>exporting data to a cloud drive</li> </ol>"},{"location":"patterns/export/#to-cloud-asset","title":"to cloud asset","text":"<p>Whenever you pan your Map or zoom in and out of your Map, Earth Engine will run through all the steps required to make your data layers at the scale and extent that you are requesting.  </p> <p>Because of this, it is common to get to the point in a workflow where two things happen:  </p> <ol> <li> <p>Earth Engine starts to balk at the amount of work you are asking it to do and throws time out or tile errors.  </p> </li> <li> <p>You get impatient waiting for Earth Engine to process a long workflow just to zoom in and out and pan around your map. (When the slippy map gets sticky, it is like watching a game or movie that keeps buffering.)  </p> </li> </ol> <p>At this point, I tend to export my data as an asset so that I can just call the result directly. This is analogous to saving a copy of your data in the cloud. The asset will have a cloud address that you can then use to gather the data back into your workflow with a constructor like <code>ee.Image()</code>.   </p> <p>Please note that when you export data as cloud assets, you are no longer storing it as a variable. So these patterns do not begin by declaring a variable. They simply execute a function.   </p>"},{"location":"patterns/export/#export-fc","title":"export fc","text":"<p>This method will create a task that will export a feature collection as a Google Earth Engine asset. You will need to go to the task tab and run the task. When it is complete, you can access the asset through the asset tab. Open the asset (double-click) and then copy the asset id. You can then use this address in a data gathering pattern for vector data.</p> <pre><code>geo.fcExport.toCloudAsset(fc, \"asset_name\");\n</code></pre> <p> ARGUMENT DESCRIPTION fc A feature collection to export. \u201casset_name\u201d A name for the asset. <p></p>"},{"location":"patterns/export/#export-image","title":"export image","text":"<p>This method will create a task that will export an image as a Google Earth Engine asset. You again will need to go to the task tab and run the task. When it is complete, you can access the asset through the asset tab. Open the asset (double-click) and then copy the asset id. You can then use this address in a data gathering pattern for raster data.</p> <pre><code>geo.iExport.toCloudAsset(\nimage, \"asset_name\",\nextent, \"pyramiding\"\n);\n</code></pre> <p> ARGUMENT DESCRIPTION image An image to export. \u201casset_name\u201d A name for the asset. extent The area of interest or study region to define the bounds of the image. \u201cpyramiding\u201d The method for generating pyramid layers to display in slippy map. Use \u201cmode\u201d for boolean, categorical, and object rasters and \u201cmean\u201d for field rasters. <p></p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/filter-collections/","title":"filter collections","text":"<p>PATTERNS</p>"},{"location":"patterns/filter-collections/#filter-collections","title":"filter collections","text":"<p>Image and feature collections often include more data than you need. As a result, both tend to follow this pattern: </p> <p> <pre><code>graph LR\n\n  step01(\"Access collection from cloud\") ;\n  step02(\"Filter collection\") ;\n\n  step01 --&gt; step02\n\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000 ;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>A filter is a method of asking a true or false question about the content of a collection and then only keeping the records where the answer is true. In other GIS, these are called selections or queries which are often written in SQL, which follows a similar logic but employs a different syntax.  </p> <p>In Earth Engine, you can filter collections in three ways:  </p> <ul> <li>by time, </li> <li>by location, </li> <li>by attribute. </li> </ul>"},{"location":"patterns/filter-collections/#filter-by-time","title":"filter by time","text":"<p>An image collection represents a time series when it contains images that capture the same region of space at different moments in time. The date associated with each image will be a property of the image. Earth Engine provides several different methods to filter the collection by defining a temporal interval, or a window of time defined by a start and end date.</p>"},{"location":"patterns/filter-collections/#filter-by-calendar-range","title":"filter by calendar range","text":"<p>This method allows you to choose a calendar unit for a temporal interval. </p> <pre><code>var select_by_calendar = ic.filter(\nee.Filter.calendarRange(start, end, \"unit\")\n)\n;\n</code></pre>"},{"location":"patterns/filter-collections/#filter-by-date-range","title":"filter by date range","text":"<p>This method defines a temporal interval with a start and end date. The start_date and end_date must be strings in the format: <code>\"YYYY-MM-DD\"</code>.  </p> <pre><code>var select_by_date = ic.filter(\nee.Filter.date(\"start_date,\" \"end_date\")\n)\n;\n</code></pre>"},{"location":"patterns/filter-collections/#filter-by-location","title":"filter by location","text":"<p>This involves making spatial comparisons between two layers. One layer is a collection of things (features, images) that has more things than you need. The other layer is a geometry, feature, or feature collection that defines your place of interest. These filters work by comparing the location of things in the first collection with the location of the place of interest in the second layer.   </p>"},{"location":"patterns/filter-collections/#by-bounds","title":"by bounds","text":"<p>One of the most common spatial filters tests for overlap between items in the collection and the place of interest. Any item in the collection that overlaps the place of interest will pass through the filter and the rest of the things will be filtered out. Even things that only overlap the place of interest on the very edge will still pass through the filter and remain in the collection. The diagram below shows this by passing items 7, 13, 19 through the filter. You can think of the items in this collection as either individual images (image collection) or individual features (feature collection).   </p> <p></p> <p>It is sometimes helpful to think of this as a fork filter, because this filter does not alter the shape of the items in the collection. The filter does not cut them, as a knife would, and the collective shape of the items that pass through the filter does not match the shape of the place of interest.  </p> <p>The syntax for this method in Earth Engine looks a little clunky because you first call <code>.filter()</code> on the collection that you want to filter (called c for collection in the code snippet), which then takes <code>ee.Filter.bounds()</code> as an argument, which itself takes the place of interest object as an argument.  </p> <pre><code>graph LR\n\n  input[\"collection\"] ;\n  method(\"&lt;b&gt;.filter()&lt;/b&gt;\") ;\n  output[/\"collection_filter_bounds\"/]  ;\n\n  input --&gt; method --&gt; output\n\n  arg[\"ee.Filter.bounds()\"] ;\n\n  arg --o method\n\n  arg2[\"place_of_interest\"] ;\n\n  arg2 --o arg\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg; \n  class arg2 arg;</code></pre> <pre><code>var collection_filter_bounds = collection.filter(ee.Filter.bounds(place_of_interest));\n</code></pre> <p>Because this method is very commonly used to filter both image and feature collections but has such wonky syntax, Earth Engine provides an alternative expression to call the method that is a bit simpler to write. In the snippet below, c is the collection to filter and place_of_interest is the object that is being used to test for overlap it. </p> <pre><code>var collection_filter_bounds = collection.filterBounds(place_of_interest);\n</code></pre> <p>The main advantage of learning to write the first, clunky syntax is that you can use it to include the filter in AND methods (see below).  </p>"},{"location":"patterns/filter-collections/#check-results","title":"check results","text":"<p>After applying a filter, it is good practice to quickly check to see if the filter reduced the collection and by how much.    </p> <pre><code>print(\n\"collection before:\",\ncollection.size(),\n\"collection after:\"\ncollection_filter_bounds.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#full-pattern","title":"full pattern","text":"<p>Here is the full pattern for filtering by overlap.  </p> <pre><code>// Filter feature collection for overlap with fork. \n\nvar collection_filter_bounds = collection.filterBounds(fork);\n\n// Check filtered result.  \n\nprint(\n\"collection before:\",\ncollection.size(),\n\"collection after:\"\ncollection_filter_bounds.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#other-spatial-filters","title":"other spatial filters","text":"<p>The <code>.filterBounds()</code> method is a generally fast method to filter by location, but sometimes you may not want to keep features that only overlap the boundary of the place of interest. To help in these cases, I wrote a custom method that allows you to filter features in one collection based on their spatial relationship to features in another collection (place of interest).      </p> <pre><code>var fc_spatial_filter = geo.fcFilter.spatial('spatialRelationship', collection, place_of_interest);\n</code></pre> <p>You may choose one of three spatial relationships.  </p> SPATIAL RELATIONSHIP DESCRIPTION \u201ccontainedIn\u201d Returns features in collection that are contained by place of interest. \u201cdisjoint\u201d Returns features in collection that do not touch place of interest. \u201cintersects\u201d Returns features in collection that touch a place of interest."},{"location":"patterns/filter-collections/#filter-by-attribute","title":"filter by attribute","text":"<p>These methods allow you to filter a collection based on property values of items in the collection. They work for both image collections and feature collections. The filter essentially asks a true/falsw question about the properties of the collection and returns the elements of the collection where the answer is true. </p> <p></p>"},{"location":"patterns/filter-collections/#filter-by-attribute_1","title":"filter by attribute","text":"<pre><code>var collection_filtered = collection.filter(\nee.Filter.eq('property', 'value')\n);\n</code></pre>"},{"location":"patterns/filter-collections/#check-filter-results","title":"check filter results","text":"<pre><code>print(\n\"collection before:\",\ncollection.size(),\n\"collection after:\"\ncollection_filtered.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#full-pattern_1","title":"full pattern","text":"<pre><code>// Filter by attribute  \n\nvar collection_filtered = collection.filter(\nee.Filter.eq('property', 'value')\n);\n\n// Check filtered result.  \n\nprint(\n\"collection before:\",\nc.size(),\n\"collection after:\"\nc_filtered.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#other-criteria","title":"other criteria","text":"<p>There are a number of filters that follow the same pattern as above and take property and attribute value as arguments. The <code>ee.Filter.eq()</code> and <code>ee.Filter.neq()</code> can take either a string or number as the value argument. The other filters listed below typically take a number.  </p> <pre><code>ee.Filter.eq('property', 'value')        // Equal to\n</code></pre> <pre><code>ee.Filter.neq('property', 'value')       // Not equal to\n</code></pre> <pre><code>ee.Filter.gt('property', 0)              // greater than\n</code></pre> <pre><code>ee.Filter.gte('property', 0)            // greater than or equal to\n</code></pre> <pre><code>ee.Filter.lt('property', 0)             // less than\n</code></pre> <pre><code>ee.Filter.lte('property', 0)            // less than or equal to\n</code></pre>"},{"location":"patterns/filter-collections/#filter-fc-by-logical-criteria","title":"filter FC by logical criteria","text":"<p>These patterns are similar to logical comparisons in raster but work with vector data. They can be particularly helpful to filter a feature collection by location using features in more than one other collection or to filter a feature collection by both location and by attribute.   </p>"},{"location":"patterns/filter-collections/#and-by-location","title":"AND by location","text":"<pre><code>var fc_filter_and = fc.filter(\nee.Filter.and(\nee.Filter.bounds(A),\nee.Filter.bounds(B)\n)\n);\n\nprint(\n\"collection before:\",\nfc.size(),\n\"collection after:\",\nfc_filter_and.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#and-by-location-and-by-attribute","title":"AND by location and by attribute","text":"<pre><code>var fc_filter_amd = fc.filter(\nee.Filter.and(\nee.Filter.bounds(A),\nee.Filter.eq(\"class\", 1)\n)\n);\n\nprint(\n\"collection before:\",\nfc.size(),\n\"collection after:\",\nfc_filter_and.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#or-by-location","title":"OR by location","text":"<pre><code>var fc_filter_or = fc.filter(\nee.Filter.or(\nee.Filter.bounds(A),\nee.Filter.bounds(B)\n)\n);\n\nprint(\n\"collection before:\",\nfc.size(),\n\"collection after:\",\nfc_filter_and.size()\n);\n</code></pre>"},{"location":"patterns/filter-collections/#or-by-location-or-by-attribute","title":"OR by location or by attribute","text":"<pre><code>var fc_filter_or = fc.filter(\nee.Filter.or(\nee.Filter.bounds(A),\nee.Filter.eq(\"class\", 2)\n)\n);\n\nprint(\n\"collection before:\",\nfc.size(),\n\"collection after:\",\nfc_filter_and.size()\n);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/focal-operations/","title":"focal (neighborhood) operations","text":"<p>PATTERNS</p>"},{"location":"patterns/focal-operations/#focal-operations","title":"focal operations","text":"<p>Focal operations use a moving window to carry out a computation based on values in the neighborhood of a focal cell. The window moves systematically across the raster, performing calculations for each pixel.    </p> <p></p> <p>The result of each neighborhood calculation is stored in the output raster pixel that corresponds with the location of the focal pixel in the input raster. The shape and size of the moving window is defined by a kernel.  The example below uses a square, 3 x 3 pixel kernel to compute the average neighborhood value for a focal pixel.  </p> <p> </p>"},{"location":"patterns/focal-operations/#scale-of-analysis","title":"scale of analysis","text":"<p>;</p> <p>source</p>"},{"location":"patterns/focal-operations/#object-rasters-from-clusters","title":"Object rasters from clusters","text":"<p>more soon </p>"},{"location":"patterns/focal-operations/#make-objects-from-clusters","title":"make objects from clusters","text":"<p>This method uses uses either a \u2018plus\u2019 or \u2018square\u2019 moving window to clump pixels that:</p> <ol> <li>have the same value and</li> <li>touch on adjacent sides (\u2018plus\u2019 window) and/or corners (\u2018square\u2019 window).  </li> </ol> <p>It returns an image with the original band(s) and a new band called \u2018labels\u2019 that identifies contiguous regions with unique integer values. It is usually helpful to select the \u2018labels\u2019 band and visualize it with <code>.randomVisualizer()</code>. </p> <p>The method works relatively quickly, but has two important quirks that result from Earth Engine\u2019s architecture:  </p> <ol> <li>It cannot identify objects that are larger than 1024 pixels.  </li> <li>The scale of analysis is determined by zoom level. Because of this, the results will change as you zoom in and out of the output layer.  </li> </ol> <p>Here is the basic pattern.  </p> <pre><code>var objects_from_clusters = geo.iFocal.makeObjectsFromClusters(image, 'kernel');  Map.addLayer(objects_from_clusters.select(\"labels\").randomVisualizer(), {}, \"4.1. Objects from clusters\";\n</code></pre> ARGUMENT DESCRIPTION image Input image with a band that contains a boolean or nominal (class) raster. If image contains more than one band, select the band that identifies the classes that you want to cluster. \u2018kernel\u2019 Either \u2018plus\u2019 or \u2018square\u2019. A \u2018square\u2019 will clump pixels that touch at corners, while a \u2018plus\u2019 will only clump pixels that share a side."},{"location":"patterns/focal-operations/#object-area-from-clusters","title":"object area from clusters","text":"<p>This method calculates the area of distinct objects with a square (3x3 pixel) moving window. It is similar to the method described above, but differs in two ways:  </p> <ol> <li>It can only use a \u2018square\u2019 window (so pixels will be clustered if they touch on corners).</li> <li>It returns an image with only one band, named \u2018area\u2019, that stores the area (square meters) of the object in each pixel of the object.  </li> </ol> <p>It suffers from the same two quirks described above (limited size and changes with zoom level).</p> <p>Here is the basic pattern:</p> <pre><code>var object_area_clusters = geo.iFocal.objectAreaFromClusters(image, \"band\");\n</code></pre> <p>The table below describes the arguments.  </p> ARGUMENTS DESCRIPTION image An input image. \u201cband\u201d The band name with boolean or class values to cluster. <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/gather-raster-data/","title":"gather raster data","text":"<p>PATTERNS</p>"},{"location":"patterns/gather-raster-data/#gather-raster-data","title":"gather raster data","text":"<p>One of the first things you will usually do with Earth Engine is gather some data from the cloud. Before we get too deep into this, we should review the basic templates for storing geographic data (geographic data models) and how they are implemented in Earth Engine.     </p>"},{"location":"patterns/gather-raster-data/#raster-data-model","title":"raster data model","text":"<p>A raster stores geographic data with a grid of pixels. Each pixel, or cell in the grid, stores a value as a digital number. The data type defines the length of binary numbers used to store the digital number. In the diagram below, the values shown on the left can be stored as a 8 bit unsigned integer, or byte, data type shown on the right. </p> <p></p>"},{"location":"patterns/gather-raster-data/#image-data-object","title":"image data object","text":"<p>In Earth Engine, the raster model underlies the image data object, where an image is composed of one or more bands and each band is a raster.  </p> <p></p>"},{"location":"patterns/gather-raster-data/#accessing-images-from-cloud","title":"accessing images from cloud","text":"<p>The diagram below shows a typical pattern for accessing cloud data.</p> <p> <pre><code>\ngraph LR\n\n  step01(\"Construct from address\") ;\n  step02(\"Inspect data object\") ;\n\n  step01 --&gt; step02\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>The pattern is to first construct the object and then immediately inspect the properties of the object.  </p>"},{"location":"patterns/gather-raster-data/#construct-image-from-address","title":"construct image from address","text":"<p>Use the <code>ee.Image()</code> method to construct an image from the cloud. This method takes the address for the data asset as an argument.   </p> <p> <pre><code>graph LR\n  step02(\"ee.Image()\") ;\n  step03[/\"image\"/]  ;\n  arg01[\"'address/of/cloud/data'\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; \n</code></pre> <p></p> <p>To adapt the snippet below, you will just need to replace <code>'address/of/cloud/data'</code> with the data address. The address must be a string.  </p> <pre><code>var image = ee.Image('address/of/cloud/data');\n</code></pre>"},{"location":"patterns/gather-raster-data/#inspect-data-properties","title":"inspect data properties","text":"<p>After constructing or altering a data object, I usually want to quickly familiarize myself the properties of the data. To do this, use the <code>print()</code> method to print the properties of the data object to the Console.  </p> <pre><code>print(\n\"A helpful label\",\nimage\n)\n;\n</code></pre> <p>To adapt the snippet below, replace <code>\"A helpful label\"</code> with a label that describes the image you are working with. This label must be a string. As necessary, replace <code>image</code> in the following line with the name of the variable that contains the image data.  </p>"},{"location":"patterns/gather-raster-data/#full-pattern","title":"full pattern","text":"<p>Here are the two parts of the pattern together.</p> <pre><code>var image = ee.Image('address/of/cloud/data');\n\nprint(\n\"A helpful label\",\nimage\n)\n;\n</code></pre>"},{"location":"patterns/gather-raster-data/#compile-from-other-images","title":"compile from other images","text":"<p>You can compile a new image by bringing together one or more bands from other images. This can be helpful for making RGB composites, charts, and other workflows.  </p> <p>The general pattern starts with an image (named \u201cA\u201d below) and calls the <code>.addBands()</code> method to add bands from another image (\u201cB\u201d) to the output image.  </p> <pre><code>var output_image = A.addBands(B);\n\nprint(\"Image with added bands\", output_image);\n</code></pre> <p>To make an RGB composite, you will typically want to add bands from two other images. You can do this by chaining the pattern.</p> <pre><code>var rgb_stack = A.addBands(B).addBands(C);\n\nprint(\"RGB stack\", rgb_stack);\n</code></pre>"},{"location":"patterns/gather-raster-data/#image-collection-data-object","title":"image collection data object","text":"<p>In Earth Engine, an image collection is what it sounds like: a collection of images. Earth Engine often uses these raster data objects to store satellite observations, because most satellites observe a region of the earth\u2019s surface (often called a scene) at a moment in time and then return to this scene at regular intervals to create a time series. In these cases, an image collection provides a way to store all the different scenes observed at all the different times by a satellite mission.    </p> <p>image forthcoming </p> <p>Image collections are also useful for storing high-resolution rasters as a set of small tiles, or images with relatively small geographic extent, that can be stitched together into larger images as needed. For example, Earth Engine will often store Lidar products and high resolution imagery as image collections. </p> <p></p>"},{"location":"patterns/gather-raster-data/#construct-from-address","title":"construct from address","text":"<p>Use the <code>ee.ImageCollection()</code> method to construct an image collection from the cloud. The method takes the cloud address as an argument.  </p> <p> <pre><code>graph LR\n  step02(\"ee.ImageCollection()\") ;\n  step03[/\"ic\"/]  ;\n  arg01[\"'address/of/cloud/data'\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; </code></pre> <p></p> <p>Here is the pattern in javascript:</p> <pre><code>var ic = ee.ImageCollection('address/of/cloud/data');\n</code></pre>"},{"location":"patterns/gather-raster-data/#inspect-data","title":"inspect data","text":"<p>After constructing an ic object, I tend to use a <code>print()</code> method to learn a couple things about the data.  </p> <pre><code>print(\n\"------------------\",\n\"collection\",\n\"------------------\",\nic,                 // Consider commenting out this line to make script run faster.\n\"------------------\",\n\"size\",\n\"------------------\",\nic.size(),          // Consider commenting out this line to make script run faster. \n\"------------------\",\n\"first image\",\n\"------------------\",\nic.first(),\n\"------------------\",\n\"number of bands\",\n\"------------------\",\nic.first().bandNames().length(),\n\"------------------\",\n\"band names\",\n\"------------------\",\nic.first().bandNames()\n)\n;\n</code></pre> <p>The <code>ic.size()</code> method tells me how many images the collection contains. If the collection is huge, this method can take a while to run, so often I will comment out this line after I have looked at the result to help make the script run faster on subsequent runs.  </p> <p>The <code>ic.first()</code> method tells me some details about the first image in the collection and usually the other images in the collection will have the same band names and property keys.  </p> <p>The <code>ic.first().bandNames().length()</code> method tells me how many bands the first image in the collection contains, while <code>ic.first().bandNames()</code> tells me the name of each band.  </p>"},{"location":"patterns/gather-raster-data/#inspectcollection-helper","title":"inspectCollection helper","text":"<p>It can be a pain to update the name of the image collection (ic) each time it is called in the snippet above. So if you would like to print all of the items shown above, you can just call this method from the geo module.  </p> <p><pre><code>geo.icGather.inspectCollection(label, ic);\n</code></pre> Please note that this method simply prints some metadata to the Console, so you cannot store it as a variable.  </p> <p>The method takes the following arguments.</p> ARGUMENT DESCRIPTION label A label to print to Console. Must be a string. ic Name of image collection to inspect."},{"location":"patterns/gather-raster-data/#select-bands","title":"select band(s)","text":"<p>Images in a collection may contain multiple bands and often you only need to work with data in a subset of these bands. The pattern below will select one band from each image.  </p> <pre><code>var select_band = ic.select(\"band_name\");\n</code></pre> <p>You can also select more than one band.  </p> <pre><code>var select_bands = ic.select(\"band_name\", \"band_name_2\");\n</code></pre> <p>And you can also rename one or more bands if you provide two lists. The first list identifies the bands to select and the second list defines new names for each band. The two lists must be the same length. </p> <pre><code>var select_bands = ic.select([\"band_name\", \"band_name_2\"], [\"new_band_name\", \"new_namd_name_2\"]);\n</code></pre>"},{"location":"patterns/gather-raster-data/#select-first-image-in-collection","title":"select first image in collection","text":"<p>This method will select the first image in the collection. It functions like a conversion tool, in the sense that the input is a collection and the output is an image.  </p> <pre><code>var select_first_image = ic.first();\n</code></pre>"},{"location":"patterns/gather-raster-data/#rename-bands","title":"rename band(s)","text":"<p>This method will change the name of one or more bands in an image. The new band name must be a string in a list and the length of the list should match the number of bands in the image.   </p> <pre><code>var image_with_band_renamed = image.rename([\"new_band_name\"]);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/gather-vector-data/","title":"gather vector data","text":"<p>PATTERNS</p>"},{"location":"patterns/gather-vector-data/#gather-vector-data","title":"gather vector data","text":"<p>Points and polylines and polygons, oh my.  </p> <p>more forthcoming </p>"},{"location":"patterns/gather-vector-data/#accessing-data-from-cloud","title":"accessing data from cloud","text":"<p>The general pattern for acquiring vector data from the cloud is quite similar to the one for raster data.   </p> <p> <pre><code>graph LR\n\n  step01(\"Construct from address\") ;\n  step02(\"Inspect data object\") ;\n\n  step01 --&gt; step02\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p>"},{"location":"patterns/gather-vector-data/#construct-fc-from-address","title":"construct fc from address","text":"<pre><code>var fc = ee.FeatureCollection(\"address/of/cloud/data\");\n</code></pre>"},{"location":"patterns/gather-vector-data/#inspect-data","title":"inspect data","text":"<p>Working with vector data in Earth Engine can be a little challenging because you never really get to see the data as a table. You can, however, try to piece together the basic structure of the table by asking a set of questions about the data with the <code>print()</code> method.   </p>"},{"location":"patterns/gather-vector-data/#how-many-rows-in-table","title":"how many rows in table?","text":"<p>This method will print the number of features in the collection to the Console, which is the same as the number of rows in a table. </p> <pre><code>print(\n\"fc size\",\nfc.size()\n);\n</code></pre> <p>It is often helpful to know how many features the collection contains at the start as a way to monitor the results of your filters in subsequent steps.  </p>"},{"location":"patterns/gather-vector-data/#what-is-first-row-of-table","title":"what is first row of table?","text":"<p>This method will print the first row of the table as a dictionary to the Console.  </p> <pre><code>print(\n\"fc first row\",\nfc.first()\n);\n</code></pre> <p>The keys of the dictionary are the column names of the table. The values in the dictionary are the values for the first row of the table. Often, the first row is arbitrary and you may not even know where this feature is in the world. But your goal here is to understand the data schema:  </p> <ul> <li>what are the column names that define the categories of attributes stored in the table?  </li> <li>what is the format of the column names and attribute values? Are they text or numbers? If text, are they all caps, title case, all lower?  </li> </ul> <p>This information is usually quite helpful when you need to filter the collection in subsequent steps.  </p>"},{"location":"patterns/gather-vector-data/#what-are-all-unique-values-of-a-target-column","title":"what are all unique values of a target column?","text":"<p>This method will print all the unique values for a target column that you specify with the \u201cproperty_name\u201d argument. You usually find the column name use the <code>fc.first()</code> method shown above.  </p> <pre><code>print(\n\"FC unique values for target category\",\nfc.aggregate_array('property_name').distinct().sort()\n);\n</code></pre> <p>This information usually facilitates filter by attribute methods. (I often copy and paste attributes from this list to avoid typos).     </p>"},{"location":"patterns/gather-vector-data/#full-pattern","title":"full pattern","text":"<p>Here is the full pattern for constructing and inspecting feature collections.  </p> <pre><code>// Gather fc data from address.\n\nvar fc = ee.FeatureCollection(\"address/of/cloud/data\");\n\n// Inspect the table.  \n\nprint(\n\"FC NAME\",\n\"number of rows:\",\nfc.size(),\n\"first row of table:\",\nfc.first(),\n\"unique values for target column:\",\nfc.aggregate_array('column_name').distinct().sort()\n);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/javascript/","title":"javascript","text":"<p>PATTERNS</p>"},{"location":"patterns/javascript/#javascript","title":"JavaScript","text":"<p>Here are some basic patterns for writing in JavaScript.</p>"},{"location":"patterns/javascript/#comments","title":"comments","text":"<p>Use comments to explain your code.</p> <pre><code>// Line comments start with two forward slashes. Like this line. \n\n/* Multi-line comments start with a forward slash and a star,\nand end with a star and a forward slash. */ </code></pre>"},{"location":"patterns/javascript/#variables","title":"variables","text":"<p>Use variables to contain (hold, store) data. </p> <pre><code>// Write a statement using the keyword var.\n\nvar hello = 'Hello world';    // Statements should end in a semi-colon, or else the Code Editor complains.\n\nvar test = \"I feel incomplete...\"\n\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n// !! Variable names cannot contain spaces or - dashes - !!\n// !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n// Use underscores to separate words in variable names.\n\nvar this_is_called_snake_case = 'Hello, snake!';\n\n// Or use capitalizations to separate words:\n\nvar thisIsCalledCamelCase = 'Hello, camel!';\n</code></pre>"},{"location":"patterns/javascript/#print-to-console","title":"print to console","text":"<p>Use print function to print contents of variables and objects to console. </p> <pre><code>// Use parenthesis to pass arguments to print function.  \n\nprint(hello);\n\n// Use commas to pass multiple arguments. \n\nprint('Print test', hello);\n</code></pre>"},{"location":"patterns/javascript/#strings","title":"strings","text":"<p>Use strings to store text (character strings). </p> <pre><code>// Use single quotes to define string.\n\nvar hello = 'Hello world!'  // This is a string. \n\n// You can also use double quotes to enclose string.\n\nvar obi_one = \"Hello there\";\n\n// Just do not mix them.\n\nvar cranky = \"Hello Newman';  // This will throw an error. You will need to match the quotation marks to fix it. \n</code></pre> <p>A string has a set of methods that work with that type of data.</p> <pre><code>// Use a period and parentheses to call a string method.\n\nprint(\nhello,                  // Original object that contains a string.\nhello.slice(0,2),       // Keep the first through third characters of the string.\nhello.concat('!'),      // Add an exclamation point after the string.\nhello.toUpperCase()     // Change the case to all upper. \n)\n;\n</code></pre>"},{"location":"patterns/javascript/#numbers","title":"numbers","text":"<p>Use numbers to store numerical data. </p> <pre><code>// These are both numbers. \n\nvar integer = 12;\nvar decimal = 11.987654321;\n\nprint(integer, decimal);              // Print number variables to Console\n\n// You can call some number methods with dot notation.\n\nprint(decimal.toFixed(4));  // Or call Javascript Math method that take number object as argument.\n\nprint(Math.round(decimal));           // Round decimal number to integer.\nprint(Math.floor(decimal));           // Round decimal number DOWN to nearest integer.\nprint(Math.ceil(decimal));            // Round decimal number UP to nearest integer.\n</code></pre>"},{"location":"patterns/javascript/#lists","title":"lists","text":"<p>Use lists to store a set of data. </p> <pre><code>// Use square brackets to define a list.\n\nvar some_vt_towns = ['Middlebury', 'New Haven', 'Bristol'];\n\n// Use square brackets after lists to select items.\n\nprint(some_vt_towns, some_vt_towns[0]);\n\n// Call list methods with dot notation.  \n\nprint(some_vt_towns.reverse());\n</code></pre>"},{"location":"patterns/javascript/#dictionaries","title":"dictionaries","text":"<p>Use dictionaries to store keys and values. </p> <pre><code>// Use curly brackets (or braces) to define dictionaries.\n\nvar midd = {\n\"name\": \"Middlebury\",  // Dictionaries are composed of key:value pairs.\n\"pop_2010\": 8496,\n\"pop_2020\": 9152\n};\n\nprint(\"Middlebury\", midd);\n\n// Use dot notation to call the value(s) of a key.\n\nprint(midd.name);\n</code></pre>"},{"location":"patterns/javascript/#functions","title":"functions","text":"<p>Write functions to make chunks of code reuseable. </p> <pre><code>// A simple function the takes a string as an argument.  \n\nvar i_love_function = function(some_string) {\nreturn 'I love '.concat(some_string).concat('!');\n};\n\nprint(i_love_function('maps'));\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/local-operations/","title":"local operations","text":"<p>PATTERNS</p>"},{"location":"patterns/local-operations/#local-operations","title":"local operations","text":"<p>Local overlay methods compare values at pixels in one or more rasters.    </p> <p></p>"},{"location":"patterns/local-operations/#masks","title":"masks","text":"<p>Masks act like masking tape when you paint. When you mask pixels in a raster before displaying the raster as a map layer, all the pixels with the mask will remain transparent (they will not be displayed with a color). Similarly, when you mask pixels of an input raster in an operation, the masked pixels will be excluded from the computation.  </p> <p>Typically, workflows with masks involve three steps.    </p> <p> <pre><code>graph LR\n  step01(\"Make mask\")\n  step02(\"Apply mask\") ;\n  step03(\"Paint (display as layer)\") ;\n  step04(\"Transform (input in operation)\") ;\n\n\n  step01 --&gt; step02\n  step02 --&gt; step03\n  step02 --&gt; step04\n\n\n  classDef steps fill:#C9C3E6,stroke-width:1px,stroke: #00000000, color:#000000; \n\n\n\n  class step01 steps; \n  class step02 steps;\n  class step03 steps;\n  class step04 steps; </code></pre> <p></p>"},{"location":"patterns/local-operations/#mask-pixels","title":"mask pixels","text":"<p>This pattern uses another raster, typically a Boolean raster as a mask on another raster. </p> <p>Any pixel with the value 0 in the mask acts like masking tape and prevents numbers in the output raster from being painted at that location. Masked values will not be displayed with colors when you place the raster layer on a Map. Masked values in an input raster will also be ignored in any subsequent operation.    </p> <p></p> <p> <pre><code>graph LR\n  input[image]\n  method(\".updateMask()\") ;\n  output[/\"image_with_mask\"/]  ;\n  arg01[\"mask&lt;br&gt;boolean_raster\"] ;\n\n  input --&gt; method\n  method --&gt; output\n  arg01 --o method\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg01 arg; </code></pre> <p></p> <pre><code>var image_with_mask = image.updateMask(boolean_image);\n</code></pre>"},{"location":"patterns/local-operations/#self-mask-pixels","title":"self mask pixels","text":"<p>If you want to ignore pixels that store the value 0 in an raster, you can self-mask. This is not technically a local operation because it only involves one raster, but I wanted to keep the mask operations together. </p> <p></p> <p> <pre><code>graph LR\n  input[image]\n  method(\".selfMask()\") ;\n  output[/\"image_with_mask\"/]  ;\n\n  input --&gt; method\n  method --&gt; output\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;</code></pre> <p></p> <pre><code>var image_with_mask = image.selfMask();\n</code></pre>"},{"location":"patterns/local-operations/#unmask","title":"unmask","text":"<p>If you are working with a masked image, you can remove the mask and populate all the masked locations with a constant. Again, this is not technically a local operation because it only involves one raster, but I wanted to keep the mask operations together. </p> <p></p> <p> <pre><code>graph LR\n  input[\"image_with_mask\"]\n  method(\".unmask()\") ;\n  output[/\"image_without_mask\"/]  ;\n  arg[\"constant\"]\n\n  input --&gt; method\n  method --&gt; output\n  arg --o method  \n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg arg</code></pre> <p></p> <pre><code>var image_without_mask = image_with_mask.unmask();\n</code></pre> <p>In Earth Engine, <code>unmask()</code> will replace masked values with 0 by default (This makes the method the inverse of <code>selfMask()</code>. You can include an argument (a number in the parantheses) to specify a different constant.   </p>"},{"location":"patterns/local-operations/#logical-comparisons","title":"logical comparisons","text":"<p>The diagram below illustrates three common logical comparisons between two regions: A, B. Going from left to right, the first picture shows the two regions. The second picture shows where either region A or region B are present (or true), called the union of the two. The third picture shows where both region A and region B are present, called the intersection of the two. The fourth and final picture shows where region A is present but not region B. In this last case, region B acts like an eraser or knife that cuts out the portion of region A that it touches. Sometimes this last case is called the difference or subtraction of two sets.    </p> <p></p> <p>The patterns below describe how each logical comparison shown above can be implemented with raster data models.  </p>"},{"location":"patterns/local-operations/#union","title":"union","text":"<p>The <code>.or()</code> method takes two rasters as inputs and kicks out a boolean raster that represents their union: pixels in the output raster are true if they are true (not 0) in either raster A or raster B.  </p> <p></p> <p>The inputs are commonly boolean rasters, as illustrated in the above diagram, but the method will work with nominal (class) data, returning a boolean raster.  </p> <p></p> <p>The order of the inputs (which raster is image_A versus image_B) does not really matter. The main thing to remember here is that any masked pixels will be excluded from this operation. So it is good practice to triple-check your inputs to see if you are using a mask on pixels that should be zeros so that you do not inadvertently erase locations that are true in one layer but masked in another.  </p> <pre><code>var image_union = image_A.or(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#intersection","title":"intersection","text":"<p>The <code>and()</code> method takes two rasters as inputs and kicks out a boolean raster that represents their intersection: pixels in the output raster are true (not 0) if they are true (not zero) in both raster A and raster B.  </p> <p></p> <p>Like the <code>or</code> operation, the inputs are commonly boolean rasters, but the method will work with nominal (class) data, returning a boolean raster as shown below.  </p> <p></p> <p>The order of inputs again does not really matter here. And because this operation is like a knife that cuts and alters the shapes of inputs, this method is less sensitive to masks, unlike the <code>or()</code> method.</p> <pre><code>var image_intersection = image_A.and(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#not","title":"not","text":"<p>In Earth Engine, finding locations that are in raster A but not in raster B is a little tricky. The workflow involves inverting the binary of raster_B and then multiplying it against raster_A.   </p> <p></p> <pre><code>var image_A_not_B = image_A.multiply(image_B_inverted_binary);\n</code></pre>"},{"location":"patterns/local-operations/#map-arithmetic","title":"map arithmetic","text":"<p>As the diagram at the top of this page illustrates, a common type of local overlay operation performs arithmetic operations (addition, subtraction, multiplication, and division) with two rasters.  </p>"},{"location":"patterns/local-operations/#addition","title":"addition","text":"<p>The <code>.add()</code> method performs addition between values in corresponding pixels of two rasters. The order (which raster is A versus B) does not matter. The main thing to remember is that any pixel that is masked will be excluded from the operation (so that output pixel will remain masked).  </p> <p></p> <pre><code>var image_A_add_B = image_A.add(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#subtraction","title":"subtraction","text":"<p>The <code>.subtract()</code> method performs subtraction between values in corresponding pixels of two rasters. The order matters here: you subtract image_B from image_A. Masked pixels in either raster will remain masked in the output.  </p> <p></p> <pre><code>var image_A_subtract_B = image_A.subtract(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#multiplication","title":"multiplication","text":"<p>The <code>.multiply()</code> method performs multiplication between values in corresponding pixels of two rasters. The order does not matter here. Masked pixels do matter and will remain masked. </p> <p>Multiplication is often used with a boolean raster as a method to erase values in another image, because 0 will convert to 0 and 1 will retain the original value.   </p> <p></p> <pre><code>var image_A_subtract_B = image_A.multiply(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#division","title":"division","text":"<p>The <code>.divide()</code> method performs division between values in corresponding pixels of the two rasters. The order does matter here because you divide the values in image_A by the values in image_B. Masked pixels in either image again remain masked in the output.  </p> <p></p> <pre><code>var image_A_divide_B = image_A.divide(image_B);\n</code></pre>"},{"location":"patterns/local-operations/#spectral-indices","title":"spectral indices","text":"<p>Spectral indices are derived from local operations that compare values in two or more spectral bands. There are many, many different indices. Below I describe two indices that we will use in tutorial 9 and problem 9.  </p>"},{"location":"patterns/local-operations/#ndvi","title":"NDVI","text":"<p>The normalized difference vegetation index (NDVI) is a measure of the health of vegetation. It is calculated by comparing reflectance of near infrared (NIR) light and red light.  </p> <p> </p> <p>This takes advantage of the difference in the spectral signatures of healthy versus stressed or dead vegetation; specifically, healthy vegetation will have higher reflectance in the NIR band due to cell structure and lower reflectance in red bands due to absorption by chlorophyll.  </p> <p></p> <p>NDVI values will range from -1 to 1. Although results will vary by region, year, and instrument, here are some ballpark numbers to help interpret NDVI values:  </p> <ul> <li>0 or less: water </li> <li>0 - 0.15: impervious surfaces, rock, sand, or snow  </li> <li>0.15 - 0.33: sparse and/or stressed vegetation  </li> <li>0.33 - 0.66: moderatly healthy vegetation</li> <li>0.66 - 1: dense and/or healthy vegetation</li> </ul>"},{"location":"patterns/local-operations/#nbr","title":"NBR","text":"<p>The normalized burn ratio (NBR) is a measure of the severity of a fire. It is calculated by comparing reflectance of near infrared (NIR) and shortwave infrared (SWIR) light. </p> <p> </p> <p>source</p> <p>This takes advantage of differences in the spectral signatures of healthy and burned vegetation.</p> <p></p>"},{"location":"patterns/local-operations/#awesome-spectral-indices-module","title":"awesome spectral indices module","text":"<p>Although you can compute most spectral indices from scratch in Earth Engine, I appreciate using a module developed by Dave Montero Loaiza that is\u2026 pretty\u2026 awesome.  </p> <p>Here are the steps for using his module.  </p>"},{"location":"patterns/local-operations/#load-module","title":"load module","text":"<pre><code>// ------------------------------------------------------------------------\n//  Load spectral indices module.  \n// ------------------------------------------------------------------------\n\nvar spectral = require(\"users/dmlmont/spectral:spectral\");\n\nprint(\n\"SPECTRAL INDICES\", spectral.indices\n);\n</code></pre>"},{"location":"patterns/local-operations/#define-parameters","title":"define parameters","text":"<p>This will depend on which data product you are using from the Earth Engine Data catalog and based on this table from Dave\u2019s github docs.   </p> <p>Please note: this pattern is set up to work directly from the image starter scripts for Landsat and Sentinel. That is why the input image is called <code>output</code>. If you are trying to compare indices at two different snapshots in time, you may have changed the name of your image and will need to insert a line that temporarily renames your image. Otherwise EE will likely throw a \u201cLine ###: output is not defined\u201d error message.  </p> <pre><code>// Temporarily rename the input image to work with pattern.\n\nvar output = target_input;  // Change \"target_input\" to the name of image you want to use as the input. \n</code></pre>"},{"location":"patterns/local-operations/#l5-l7","title":"L5 &amp; L7","text":"<p>For Landsat 5 or 7 Surface Reflectance, use this pattern:</p> <pre><code>// ------------------------------------------------------------------------\n//  Define parameters for Landsat 5 or 7 Surface Reflectance. \n// ------------------------------------------------------------------------\n\nvar parameters = {\n\"B\": output.select(\"SR_B1\"),\n\"G\": output.select(\"SR_B2\"),\n\"R\": output.select(\"SR_B3\"),\n\"N\": output.select(\"SR_B4\"),\n\"S1\": output.select(\"SR_B5\"),\n\"S2\": output.select(\"SR_B7\"),\n\"T\": output.select(\"SR_B6\")\n};\n</code></pre>"},{"location":"patterns/local-operations/#l8-l9","title":"L8 &amp; L9","text":"<p>For Landsat 8 or 9, use this pattern:</p> <pre><code>// ------------------------------------------------------------------------\n//  Define parameters for Landsat 8 or 9 Surface Reflectance. \n// ------------------------------------------------------------------------\n\nvar parameters = {\n\"A\": output.select(\"SR_B1\"),\n\"B\": output.select(\"SR_B2\"),\n\"G\": output.select(\"SR_B3\"),\n\"R\": output.select(\"SR_B4\"),\n\"N\": output.select(\"SR_B5\"),\n\"S1\": output.select(\"SR_B6\"),\n\"S2\": output.select(\"SR_B7\"),\n\"T1\": output.select(\"SR_B10\"),\n\"T2\": output.select(\"SR_B11\")\n};\n</code></pre>"},{"location":"patterns/local-operations/#s2","title":"S2","text":"<p>For Sentinel 2, use this pattern:</p> <pre><code>// ------------------------------------------------------------------------\n//  Define parameters for Sentinel 2 Surface Reflectance. \n// ------------------------------------------------------------------------\n\nvar parameters = {\n\"A\": output.select(\"B1\"),\n\"B\": output.select(\"B2\"),\n\"G\": output.select(\"B3\"),\n\"R\": output.select(\"B4\"),\n\"RE1\": output.select(\"B5\"),\n\"RE2\": output.select(\"B6\"),\n\"RE3\": output.select(\"B7\"),\n\"N\": output.select(\"B8\"),\n\"N2\": output.select(\"B8A\"),\n\"WV\": output.select(\"B9\"),\n\"S1\": output.select(\"B11\"),\n\"S2\": output.select(\"B12\")\n};\n</code></pre>"},{"location":"patterns/local-operations/#compute-spectral-indices","title":"compute spectral indices","text":"<p>You can compute one or more indices with this pattern. This example computes NDVI, NBR, and MNDWI. Each index will be stored as a new band in the output image.  </p> <pre><code>// ------------------------------------------------------------------------\n//  Compute spectral index or indices.\n// ------------------------------------------------------------------------\n\nvar output_si = spectral.computeIndex(output,[\"NDVI\", \"NBR\"], parameters);\n\nprint(\n\"IMAGE WITH SPECTRAL INDICES\",\noutput_si);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/map-raster-layers/","title":"map raster as layers","text":"<p>PATTERNS</p>"},{"location":"patterns/map-raster-layers/#map-raster-layers","title":"map raster layers","text":"<p>Any geographic information system will provide methods for displaying data as a map layer.  </p> <p>To understand these patterns, it will be helpful to review some basic concepts of data visualization.  </p>"},{"location":"patterns/map-raster-layers/#data-values-vs-display-values","title":"data values vs. display values","text":"<p>When you visualize data, you map data values to display values. Two things often happen by default:  </p> <ol> <li>The data type of the digital numbers defines the range of values that get mapped to the display values.</li> <li>The relationship between data values and display values is linear.  </li> </ol> <p></p> <p>The reason that the displayed values in the example above have such poor contrast is a result of the mismatch between the possible data values defined by the data type and the actual data values stored in the raster.  </p> <p>A histogram is one way to compare the possible and actual data values of a raster. </p> <p></p> <p>A common strategy to improve the contrast of an image is to stretch the display values over the range of actual data values by setting the linear map to begin and end at the minimum and maximum actual data value, respectively. This is usually called stretch enhancement.   </p> <p></p>"},{"location":"patterns/map-raster-layers/#display-image-as-layer","title":"display image as layer","text":"<p>The diagram below shows a general pattern to display an image as a map layer with Earth Engine. The first two tasks \u2013 print min &amp; max value and chart histogram \u2013 are methods to identify the range of actual data values in the image and how they are distributed, respectively. The middle task \u2013 define viz dictionary \u2013 is a method for storing the min and max values for stretch enhancements. The last task \u2013 display data as map layer \u2013 draws the result on the Map.  </p> <p> <pre><code>graph LR\n\n  step01(\"Print min &amp; max value\") ;\n  step02(\"Chart histogram\") ;\n  step03(\"Define viz dictionary\")  ;\n  step04(\"display data as map layer\") ;\n\n  step01 --&gt; step03 \n  step02 --&gt; step03 \n  step03 --&gt; step04\n\n  classDef task fill:#C3D3E6,stroke-width:0px,color:#000000;\n\n  class step01 task; \n  class step02 task;\n  class step03 task;\n  class step04 task;\n</code></pre> <p></p>"},{"location":"patterns/map-raster-layers/#print-min-max-value-of-image","title":"print min &amp; max value of image","text":"<p>Print the min and max data value of a raster image to use as min and max values in viz dictionary.   </p> <pre><code>var output_min_max = geo.iCart.iMinMax(image, scale, aoi);\n\nprint(\"Min &amp; max value of image\", output_min_max);\n</code></pre> ARGUMENT DESCRIPTION image The name of the variable that contains the image data to process. scale The scale of analysis. If possible, use the scale (resolution) of the input image. If this runs really slow (or times out), then increase the scale of analysis by a factor of 2 or more. aoi The area of interest or the geographic footprint of the image."},{"location":"patterns/map-raster-layers/#chart-histogram-of-data-values","title":"chart histogram of data values","text":"<p>See how your data are distributed between the minimum and maximum data value by charting a histogram.</p> <pre><code>var output_histogram = geo.iCart.iHistogram(image, scale, aoi);\n\nprint(\"Image histogram\", output_histogram);\n</code></pre> ARGUMENT DESCRIPTION input_image The name of the variable that contains the image data to process. scale The scale of analysis. If possible, use the scale (resolution) of the input image. If this runs really slow (or times out), then increase the scale of analysis by a factor of 2 or more. aoi An area of interest or the geographic footprint of the image."},{"location":"patterns/map-raster-layers/#histogram-for-spectral-indices","title":"histogram for spectral indices","text":"<p>Many spectral indices, particularly normalized difference indices, will output results that range from -1 to 1. However, there are often some pixels that for various reasons lie outside this range in either direction. To chart a histogram for these images, you will need to adapt the pattern above by placing a <code>.clamp()</code> on the image. </p> <pre><code>var output_histogram = geo.iCart.iHistogram(image.clamp(-1, 1), scale, aoi);\n\nprint(\"Image histogram\", output_histogram);\n</code></pre> <p>The clamp method has two arguments (min, max) and redefines the range of values in the image so that they all fall within this range. (For this reason, you will generally see \u2018bookends\u2019 on either side of a histogram charted from a clamped image.)  </p>"},{"location":"patterns/map-raster-layers/#get-aoi-from-map-extent","title":"get AOI from Map extent","text":"<p>If you are working with a global dataset or an image that has been flattened from a collection, the chart histogram pattern will likely throw errors and tell you it cannot work on an unbounded image. You can work around this with the helper below from the geo module. It will retrieve an area of interest (AOI) from the current geographic extent of the Map window.  </p> <pre><code>var aoi = geo.uiMap.getAOIfromMapExtent();\n</code></pre>"},{"location":"patterns/map-raster-layers/#get-nominal-scale-helper","title":"get Nominal scale helper","text":"<p>Sometimes you may be working with an image and realize that you do not know the native image scale. The helper below from the geo module will retrieve the nominal scale of the image. This is the scale at the equator of the image dataset and should be interpreted with some caution, but it can be helpful as a starting point for defining the scale for the <code>geo.iCart.iHistogram()</code> and <code>geo.iCart.iMinMax()</code> methods described above.  </p> <pre><code>var scale = geo.iCart.getNominalScaleFromImage(image);\n\nprint(\"IMAGE SCALE\", scale);\n</code></pre>"},{"location":"patterns/map-raster-layers/#define-raster-viz-dictionary","title":"define raster viz dictionary","text":"<p>For raster data, store the viz dictionary as a variable and then call this variable when you add the map layer. </p> <p>Here is a common pattern to visualize single-band images with grayscale:</p> <pre><code>var single_viz = {\nmin: [],        max: [],        }\n;\n</code></pre> <p>Here is a common pattern to visualize single-band images with color (this includes both color gradient layers and nominal layers where a unique color displays each unique class):</p> <pre><code>var single_viz = {\nmin: [],        max: [],        palette: [],    }\n;\n</code></pre> <p>If your image data represents nominal data with integers, you can quickly visualize this data with random colors using the <code>.randomVisualizer()</code> method on the image and calling an empty dictionary for the viz parameters.    </p> <pre><code>Map.addLayer(image.randomVisualizer(), {}, \"Nominal Classes\");\n</code></pre> <p>This pattern is most useful for quick visualizations, when the color used to display the class does not matter too much. If you want to be able to control which color displays each class, then you should use the single band image with color pattern described earlier and make sure that the length (number of) integer values in your class set equals the length of colors in your palette.   </p>"},{"location":"patterns/map-raster-layers/#add-map-layer","title":"add map layer","text":"<p><code>Map.addLayer()</code> method will display data as a map layer.    </p> <pre><code>Map.addLayer(data,viz,\"Layer Name\",show,opacity);\n</code></pre> <p>The <code>Map.addLayer()</code> method takes the following arguments: </p> ARGUMENT DESCRIPTION data The name of the variable that contains the data that you wish to display. viz The viz dictionary that defines how to visualize (display) the data. layer name A string that provides a label for the data in the list of layers. show A boolean argument to control whether or not the layer is displayed when first loaded. opacity A decimal number between 0 and 1 to adjust the opacity of the layer."},{"location":"patterns/map-raster-layers/#complete-pattern","title":"complete pattern","text":"<p>Here is a complete pattern for the simple case of single-band grayscale images.</p> <pre><code>// Print min and max values of image. \n\nprint(\"Min &amp; max value of image\", geo.iCart.iMinMax(image, scale, aoi));\n\n// Chart histogram of actual data values.\n\nprint(\"Image histogram\", geo.iCart.iHistogram(image, scale, aoi));\n\n// Define viz dictionary. \n\nvar single_viz = {\nmin: [],        max: [],        }\n;\n\n// Add map layer. \n\nMap.addLayer(image,single_viz,\"Layer Name\");\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/map-vector-layers/","title":"map vector as layers","text":"<p>PATTERNS</p>"},{"location":"patterns/map-vector-layers/#map-vector-layers","title":"map vector layers","text":"<p>Earth Engine is primarily a tool for visualizing raster data. This means two things:  </p> <ul> <li>you can choose a color to display vector data, but not much else;</li> <li>if you want to control more than just the color, you will need to convert your vector data into an image. </li> </ul>"},{"location":"patterns/map-vector-layers/#simple-viz-with-color","title":"simple viz with color","text":"<p>Similar to raster data, you use the <code>Map.addLayer()</code> method to display a feature collection as a map layer. This method takes the same five data objects described previously, but the viz dictionary here is much simpler: it can only contain a <code>color</code> key. Because of this, I usually write the dictionary directly into the statement.    </p> <pre><code>Map.addLayer(fc, {color: 'white'}, \"Layer Name\");\n</code></pre>"},{"location":"patterns/map-vector-layers/#paint-strokes-without-fill","title":"paint strokes without fill","text":"<p>Sometimes it is helpful to draw just the outlines (strokes) of features on a map, leaving the fills (interiors) completely transparent. This is particularly helpful with cadastre (property) lines and other boundaries of human geography.  </p> <p>The method below allows you to paint the strokes of features in a collection with a color and weight (thickness) of your choice and store the output as an RGB image. (An RGB image has three bands that combine to make colors).  </p> <p>You can then add the rgb image to the map as a layer, using empty curly brackets <code>{}</code> as a placeholder for the viz dictionary. You do not need to define the viz parameters because the data type is a byte (0-255) and Earth Engine will display the three bands (red, green, blue) correctly by default.  </p> <pre><code>var strokes = geo.fcCart.paintStrokes(fc, \"white\", 0.5);\n\nMap.addLayer(strokes, {}, \"Feature outlines\");\n</code></pre> <p>If you then add the <code>strokes</code> layer on top of the other layers on the Map, you will be able to see the underlying layer through the transparent interiors of the features in the collection.  </p>"},{"location":"patterns/map-vector-layers/#paint-nominal-values-with-colors","title":"paint nominal values with colors","text":"<p>If you have a feature collection with nominal data (classes, categories) and you would like to display each class with a unique color, then this pattern should work:</p> <p> <pre><code>graph LR\n\n  step01(\"Convert fc to nominal image\") ;\n  step02(\"Display image as layer\") ;\n\n  step01 --&gt; step02\n\n\n  classDef task fill:#C9C3E6,stroke-width:0px,color:#000000 ;\n\n  class step01 task; \n  class step02 task;\n</code></pre> <p></p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/proximity-operations/","title":"proximity operations","text":"<p>PATTERNS</p>"},{"location":"patterns/proximity-operations/#proximity-operations","title":"proximity operations","text":"<p>Proximity operations concern questions of distance, how near (or far) places are from each other.  </p> <p>more soon </p>"},{"location":"patterns/proximity-operations/#a-short-illustration","title":"a short illustration","text":"<p>I find the proximity methods in earth engine to be a little confusing, so I made the app below to illustrate how some important concepts. The text below walks you through how to build the map layers in the app. </p> <p> </p> <p>open app in new tab</p>"},{"location":"patterns/proximity-operations/#00-start-a-script","title":"00 start a script","text":"<p>This workflow draws on methods in the geo module, so you will need to load that module after you write a script header. </p> <pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   Jeff Howarth   \n    DATE:     10/7/2024  \n    TITLE:    On distance with web mercator\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n</code></pre>"},{"location":"patterns/proximity-operations/#01-proximity-with-vector","title":"01 proximity with vector","text":"<p>The first part of the script demonstrates proximity methods with vector. We start by constructing and drawing a test point in the center of Youngman\u2019s Field. </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. Proximity with vector. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Gather Test point\n// -------------------------------------------------------------\n\nvar test_point = ee.FeatureCollection(\"projects/ee-patterns/assets/t05/youngman_center\");\n\n// -------------------------------------------------------------\n//  1.2 Set Map center, zoom, and base layer. \n// -------------------------------------------------------------\n\nMap.centerObject(test_point, 19);\nMap.setOptions('HYBRID');\n\n// -------------------------------------------------------------\n//  1.3 Add test point layer. \n// -------------------------------------------------------------\n\nMap.addLayer(test_point, {color: 'yellow'}, \"1.3 Test Point\", false);\n</code></pre> <p>We then use the vector tool <code>geo.fcProximity.bufferByDistance()</code> to buffer the point by 50 yards and add the result as a layer to the Map.  </p> <pre><code>// -------------------------------------------------------------\n//  1.4 Buffer the point by 50 yards (45.72 meters)\n// -------------------------------------------------------------\n\nvar d = 45.72;\n\nvar test_buffer = geo.fcProximity.bufferByDistance(test_point, d);\n\n// -------------------------------------------------------------\n//  1.5 Add layer to Map.\n// -------------------------------------------------------------\n\nMap.addLayer(test_buffer, {color: \"red\"}, \"1.3 Test vector buffer 50 yards\", false);\n</code></pre> <p>Notice how the buffer lines up pretty well with the goal lines that are 50 yards from center field.   </p>"},{"location":"patterns/proximity-operations/#02-proximity-with-raster","title":"02 proximity with raster","text":"<p>Now we can try to reproduce this simple buffer using raster methods. The first step involves converting the test point feature collection to a boolean image and displaying the result as a Map layer.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. Proximity with raster.\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n// 2.1 Convert test point to a Boolean image.\n// -------------------------------------------------------------\n\nvar image_boolean_test = geo.fcConvert.toBooleanImage(test_point);\n\n// -------------------------------------------------------------\n// 2.2 Display test point image. \n// -------------------------------------------------------------\n\nMap.addLayer(image_boolean_test, {min:0, max:1}, \"2.2 Test point Image\", false);\n</code></pre> <p>The next step is to use <code>geo.iFocal.iDistance()</code> to calculate the euclidean distance from all non-zero pixels in the test point image. At this point, we will use the coordinate reference system for web mercator. </p> <pre><code>// -------------------------------------------------------------\n//  2.3. Calculate euclidean distance from test point.\n// -------------------------------------------------------------\n\nvar crs = \"EPSG: 3857\";  // web mercator\n\nvar distance_image_test = geo.iFocal.iDistance(image_boolean_test, d, crs, \"euclidean\", \"pixels\");\n\n// -------------------------------------------------------------\n//  2.4. Define viz parameters\n// -------------------------------------------------------------\n\nvar viz_euc = {min:0, max: d, palette: geo.iPalettes.iDistance.inferno.reverse()};\n\n// -------------------------------------------------------------\n//  2.5. Display euclidean distance as layer on Map.\n// -------------------------------------------------------------\n\nMap.addLayer(distance_image_test,  viz_euc, \"2.5 Euc distance\", false);\n</code></pre> <p>In a last step, we can create a raster version of a buffer by applying a threshold of 50 yards to the distance image that results in a Boolean image. And then add this result to the Map as a layer.   </p> <pre><code>// -------------------------------------------------------------\n// 2.6 Threshold euclidean distance image at 50 yards. \n// -------------------------------------------------------------\n\nvar distance_image_test_threshold = distance_image_test.lte(d).selfMask();\n\n// -------------------------------------------------------------\n// 2.7 Add threshold image as layer to Map. \n// -------------------------------------------------------------\n\nMap.addLayer(distance_image_test_threshold, {min:0, max:1}, '2.7 Threshold Distance at 50 Yards', false);\n</code></pre>"},{"location":"patterns/proximity-operations/#reflection","title":"reflection","text":"<p>You just made a 50 yard buffer around a point in the center of Youngman Field with vector and raster methods. How do they differ? What do you think causes their difference?  </p>"},{"location":"patterns/proximity-operations/#03-crs-matters","title":"03 crs matters","text":"<p>Go back to section 2.3 and replace the crs variable with this:</p> <pre><code>var crs = \"EPSG: 32145\";    // VT State Plane (NAD83)\n</code></pre> <p>Then run your script and compare the results to the vector method. Why do you think crs matters for raster proximity methods? Do they also matter for vector methods?  </p>"},{"location":"patterns/proximity-operations/#vector-methods","title":"vector methods","text":""},{"location":"patterns/proximity-operations/#buffer-by-distance","title":"buffer by distance","text":"<p>This method takes a feature collection and distance (in meters) as arguments. The result is a buffer around each feature in the collection; the buffer defines the zone that is within the specified distance to each feature in the collection.  </p> <pre><code>var fc_buffer = geo.fcProximity.bufferByDistance(fc, distance);\n</code></pre>"},{"location":"patterns/proximity-operations/#raster-methods","title":"raster methods","text":""},{"location":"patterns/proximity-operations/#make-distance-raster","title":"make distance raster","text":"<p>This method makes an image that represents the distance of each pixel from all non-zero (and unmasked) pixels in the input image. </p> <pre><code>var crs = \"EPSG: 32145\";    // VT State Plane (NAD83)\n\nvar image_distance = geo.iFocal.iDistance(image_input, radius, crs, \"model\", \"units\");\n</code></pre> <p>The method takes four arguments:  </p> ARGUMENT DESCRIPTION image_input Input image to calculate distance to all non-zero but unmasked cells. Often a boolean or an object image. radius The radius of the distance kernel. This defines the size of the moving window used to calculate distance. It can not be greater than 255. crs A coordinate reference system as a string that provides the EPSG definition. \u201cmodel\u201d Defines the model of distance employed. Must be a string and one of the following: \u201ceuclidean\u201d, \u201cmanhattan\u201d, \u201cchebyshev\u201d. \u201cunits\u201d Defines the system of measurement for the distance kernel, either \u201cpixels\u201d or \u201cmeters\u201d. Must be a string. <p></p> <p>This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivs 4.0 International License.</p>"},{"location":"patterns/reclassify/","title":"reclassify raster","text":"<p>PATTERNS</p>"},{"location":"patterns/reclassify/#reclassify-raster","title":"reclassify raster","text":"<p>These methods purposefully reclassify the values in a raster. </p>"},{"location":"patterns/reclassify/#boolean-raster","title":"Boolean raster","text":"<p>This pattern asks a true or false question about each value in the input raster and returns a 1 if true and 0 if false in the corresponding pixel of the output raster.   </p> <p></p> <p> <pre><code>graph LR\n  input[image]\n  method(\".gt()\") ;\n  output[/\"image_boolean\"/]  ;\n  arg1[\"number\"]  ;\n\n  input --&gt; method\n  method --&gt; output\n  arg1 --o method\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg1 arg;</code></pre> <p></p> <pre><code>var image_boolean = image.gt(number);  </code></pre> <p>The table below lists some of the common methods to ask true or false questions about a raster. Each takes a number as an argument. Some technical folks will use the verb threshold to describe methods that use greater than or less than methods to produce boolean rasters.  </p> <p> METHOD DESCRIPTION <code>.eq()</code>, <code>.neq()</code> Equal to, not equal to <code>.gt()</code> <code>.gte()</code> Greater than, greater than or equal to <code>.lt()</code> <code>.lte()</code> Less than, less than or equal to <p></p>"},{"location":"patterns/reclassify/#reclassify-by-defined-breaks","title":"Reclassify by defined breaks","text":"<p>This method reclassifies values in the input raster based on user-defined breaks. This is useful when the input values represent a field model and when the intervals between breaks are not equal.  </p> <p>The workflow can be a little confusing, but the basic idea is that you are using two or more threshold values to define a correspond set of boolean rasters that you then add together. The workflow below assumes that you are storing your thresholds as a list with two items.  </p> <p> <pre><code>graph LR\n  input[input]\n  method(\".gte()\") ;\n  output[/\"image_boolean\"/]  ;\n  arg1[\"threshold[0]\"]  ;\n\n  arg1 --o method\n  input --&gt; method\n  method --&gt; output\n\n  method2(\".gte()\") ;\n  output2[/\"image_boolean\"/]  ;\n  arg2[\"threshold[1]\"]  ;\n\n  input --&gt; method2\n  method2 --&gt; output2\n  arg2 --o method2\n\n  method3(\".add()\") ;\n  output3[\"output_reclass\"]\n\n  output --&gt; method3 \n  output2 --&gt; method3\n  method3 --&gt; output3\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class input in-out; \n  class method op;\n  class output in-out;\n  class arg1 arg;\n\n  class method2 op;\n  class output2 in-out;\n  class arg2 arg;\n\n  class method3 op;\n  class output3 in-out;\n\n</code></pre> <p></p> <p>The figure below illustrates this workflow for a simple example that reclassifies an input raster (left) with two defined breaks: 0 and 2.  </p> <p></p> <p>The code snippet below shows the pattern for EE with javascript. The first step isolates the band in the image to reclassify. The second step defines the breaks as a list of thresholds. The third step chains together the workflow illustrated in the flowchart and diagram above. Notice that the <code>.gte()</code> argument calls an item from the threshold list, where <code>threshold[0]</code> is the first item in the list and <code>threshold[1]</code> is the second item.   </p> <pre><code>// ------------------------------------------------------------------------\n//  Reclassify by defined breaks. \n// ------------------------------------------------------------------------\n\n// Isolate band if necessary\n\nvar output = input.select(\"band_name\");\n\n// Define thresholds to reclassify a raster.\n\nvar thresholds = [0, 2];\n\n// Make binaries for each threshold and add together. \n\nvar output_reclassed = output.gte(thresholds[0])\n.add(output.gte(thresholds[1]))\n;\n</code></pre> <p>The output raster will contain three values as follows:</p> NEW VALUE FROM OLD VALUE TO OLD VALUE 0 min value in raster just less than 0 1 0 just less than 2 2 2 max value in raster <p>To add additional breaks, you will need to:  </p> <ol> <li>add one or more values to the list of thresholds,  </li> <li>add a corresponding number of <code>.add(output.gte(thresholds[#]))</code> lines to the routine.    </li> </ol> <p>For example, the pattern below uses four preliminary thresholds that are often applied to NDVI images. The result will be an image with five classes that range from 0 to 4.  </p> <pre><code>// ------------------------------------------------------------------------\n//  Reclassify by defined breaks. \n// ------------------------------------------------------------------------\n\n// Isolate band if necessary\n\nvar output = input.select(\"band_name\");\n\n// Define thresholds to reclassify a raster.\n\nvar thresholds = [0, 0.15, 0.33, 0.66];\n\n// Make binaries for each threshold and add together. \n\nvar output_reclassed = output.gte(thresholds[0])\n.add(output.gte(thresholds[1]))\n.add(output.gte(thresholds[2]))\n.add(output.gte(thresholds[3]))\n;\n</code></pre>"},{"location":"patterns/reclassify/#reclassify-by-equal-intervals","title":"Reclassify by equal intervals","text":"<p>This method assigns raster values into equal interval classes. The method divides each value in a raster by the interval number and then rounds down to the nearest integer (finds the floor). The integers in the output are ordinal but arbitrary class numbers. </p> <p></p> <p> <pre><code>graph LR\n  method(\"geo.iReclass.equalInterval()\") ;\n  output[/\"image_reclassified\"/]  ;\n  arg1[\"image\"]  ;\n  arg2[\"interval\"]  ;\n\n  method --&gt; output\n  arg1 --o method\n  arg2 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class method op;\n  class output in-out;\n  class arg1 arg;\n  class arg2 arg;</code></pre> <p></p> <pre><code>var image_reclassified = geo.iReclass.equalInterval(image, interval);\n</code></pre>"},{"location":"patterns/reclassify/#remap-old-values-to-new-values","title":"Remap old values to new values","text":"<p>This method assigns integer values in the input raster to new integer values in the output raster based on transition rules defined by two lists. The first list defines the set of original values in the input raster. The second list defines the set of new values to be stored in the output raster. The order of the two lists determines the transition. The two lists must be the same length (have the same number of values).</p> <p></p> <p> <pre><code>graph LR\n  input[\"image\"] ;\n  method(\".remap()\") ;\n  output[/\"image_remapped\"/]  ;\n  arg1[\"[original values]\"]  ;\n  arg2[\"[new values]\"]  ;\n\n  input --&gt; method  \n  method --&gt; output\n  arg1 --o method\n  arg2 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out;\n  class method op;\n  class output in-out;\n  class arg1 arg;\n  class arg2 arg;</code></pre> <p></p> <pre><code>var image_remapped = image.remap(\n[0,1,2,3,4],            // Original values\n[1,0,0,0,1]             // New values \n)                       // Lengths of two lists must be equal.\n;\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/scalar-operations/","title":"scalar operations","text":"<p>PATTERNS</p>"},{"location":"patterns/scalar-operations/#scalar-operations","title":"scalar operations","text":"<p>Uniformly change the values of all data in a raster object by adding, subtracting, multiplying, or dividing the raster by a constant.   </p>"},{"location":"patterns/scalar-operations/#add","title":"add","text":"<p>Add each pixel value by constant. For example, pattern below adds by one.  </p> <pre><code>var image_add_constant = image.add(1)\n</code></pre>"},{"location":"patterns/scalar-operations/#subtract","title":"subtract","text":"<p>Subtract each pixel value by constant. For example, pattern below subtracts by 1.</p> <pre><code>var image_subtract_constant = image.subtract(1)\n</code></pre>"},{"location":"patterns/scalar-operations/#multiply","title":"multiply","text":"<p>Multiply each pixel value by constant. For example, pattern below multiplies by 2.</p> <pre><code>var image_multiply_constant = image.multiply(2)\n</code></pre>"},{"location":"patterns/scalar-operations/#divide","title":"divide","text":"<p>Divide each pixel value by constant. For example, pattern below divides by 2.</p> <pre><code>var image_divide_constant = image.divide(2)\n</code></pre>"},{"location":"patterns/scalar-operations/#problem-types","title":"problem types","text":"<p>Here are a few types of problems that can be solved with scalar operations.  </p>"},{"location":"patterns/scalar-operations/#change-value-units","title":"change value units","text":"<p>A common example is when you need to change the units of your data. For example, to change elevation data from centimeters to meters you divide all elevation values by the number 100 (scalar).   </p> <p> <pre><code>graph LR\n  input[\"image_cm\"] ;\n  method(\".divide()\") ;\n  output[/\"image_m\"/]  ;\n  arg1[\"100\"]  ;\n\n\n  input --&gt; method  \n  method --&gt; output\n  arg1 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out;\n  class method op;\n  class output in-out;\n  class arg1 arg;</code></pre> <p></p> <pre><code>var image_m = image_cm.divide(100);\n</code></pre> <p>The table below lists some common types of unit conversions and their pattern context.</p> CONTEXT INPUT UNITS OUTPUT UNITS METHOD TERRAIN cm m <code>.divide(100)</code> TERRAIN ft m <code>.multiply(3.28084)</code> SLOPE degrees percent <code>.divide(180).multiply(Math.PI).tan().multiply(100)</code>"},{"location":"patterns/scalar-operations/#vertical-exaggeration","title":"vertical exaggeration","text":"<p>Another common example is when you want to apply vertical exaggeration to a terrain operation by multiplying the elevation values by a constant, usually called the z-factor. For example, by multiplying elevation by 2, you will exaggerate the terrain, making every location appear twice as high as it \u2018really\u2019 is. It is often helpful to exaggerate terrain when visualizing micro-topography at large scales or macro-topography at small scales. </p> <p> <pre><code>graph LR\n  input[\"image_m\"] ;\n  method(\".multiply()\") ;\n  output[/\"image_m_ve_2\"/]  ;\n  arg1[\"2\"]  ;\n\n\n  input --&gt; method  \n  method --&gt; output\n  arg1 --o method\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n  class input in-out;\n  class method op;\n  class output in-out;\n  class arg1 arg;</code></pre> <p></p> <pre><code>var image_m_ve_2 = image_m.multiply(2);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/terrain/","title":"terrain","text":"<p>PATTERNS</p>"},{"location":"patterns/terrain/#terrain","title":"terrain","text":"<p>These methods derive topographic attributes of terrain from raster elevation data. Most terrain operations characterize attributes of a surface with focal (neighborhood) operations.</p> <p>Before we get too deep into these methods, it is helpful to understand some general concepts about terrain analysis with raster data models.  </p>"},{"location":"patterns/terrain/#change-in-elevation","title":"change in elevation","text":""},{"location":"patterns/terrain/#concepts","title":"concepts","text":"<p>Slope describes how the vertical dimension of space changes with respect to the  horizontal dimension. Many of us first learn about slope as \u201crise over run\u201d which can be expressed as a percentage. Most GIS will compute slope as a percentage or in degrees. Earth Engine calculates slope in degrees and then, if you would like to find the percent slope for your application, it leaves it to you to convert from degrees to percentage with scalar operations.  </p> <p></p> <p>A raster model will define \u201crun\u201d based on distance between the centers of cells. As a result, the distance between two adjacent cells that share a side will be the same as the length of a pixel side, or the scale of the raster.   </p> <p></p> <p>In raster analysis, a common slope computation employs a neighborhood operation with a kernel that resembles a \u201cplus\u201d sign. The crosspiece of the plus computes the difference in z-values (elevation) for the x dimension, while the post of the plus computes the difference in z-values for the y dimension. The change in elevation with respect to change in distance can be found by dividing by the distance across the crosspiece or post (which will both be double the cell size). The degree of slope is then found through some trigonometry.</p> <p></p> <p>Because the slope calculation directly compares changes in elevation with changes in distance, the units of the z-values must be the same as the units of the xy values. In Earth Engine, the xy units will generally be meters. Therefore, accurate slope computations require elevation data in meters.   </p>"},{"location":"patterns/terrain/#decision-flow","title":"decision flow","text":"<p>The workflow for slope analysis will often depend on the data you are using and your purpose. I tend to think through some version of the flowchart depicted below. The </p> <p> <pre><code>graph TD\n\n  q1&gt;\"Do z-units = xy units?\"] ;\n  q2&gt;\"Is your purpose to visualize slope shading?\"] ;\n  q3&gt;\"Does your application require slope in percent?\"] ;  \n  step01(\"Change units \\n\\n APPLY SCALAR\") ;\n  step02(\"Consider changing z-factor \\n\\n APPLY SCALAR\") ;\n  step03(\"Derive slope\") ;\n  step04(\"Convert slope units\") ;\n  step05(&amp;#128526);\n\n  q1-- NO --&gt;step01 --&gt; q2\n  q1-- YES --&gt;q2\n  q2-- YES --&gt;step02\n  q2-- NO --&gt;step03\n  step02 --&gt; step03\n  step03 --&gt; q3\n  q3-- YES --&gt; step04  \n  q3 -- NO --&gt; step05\n  step04 --&gt; step05\n\n\n\n  classDef task fill:#DDE6C3,stroke-width:0px,color:#000000;\n  classDef check fill:#C3D1E6, stroke-width:0px,color:#000000;  \n  classDef done fill:#FFFFFF, stroke-width:0px,color:#000000;  \n\n\n  class q1 check; \n  class q2 check; \n  class q3 check; \n  class step01 task;\n  class step02 task;\n  class step03 task;\n  class step04 task;\n  class step05 done; \n</code></pre> <p></p>"},{"location":"patterns/terrain/#slope-method","title":"slope method","text":"<p>Derive slope of a surface in degrees from elevation in meters. </p> <p>Call the <code>ee.Terrain.slope</code> method with the elevation data (with z-units meters) as the argument.  </p> <p> <pre><code>graph LR\n  step02(\"ee.Terrain.slope()\") ;\n  step03[/\"image_slope\"/]  ;\n  arg01[\"image_elevation_meters\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; </code></pre> <p></p> <pre><code>var image_slope = ee.Terrain.slope(image_elevation_meters);\n</code></pre>"},{"location":"patterns/terrain/#direction-of-change","title":"direction of change","text":""},{"location":"patterns/terrain/#concepts_1","title":"concepts","text":"<p>Closely related to slope, aspect reports the direction of change, or the steepest downhill direction of a pixel. </p> <p>Like slope, aspect is derived with a kernel that computes change in elevation in both x- and y- dimensions, but rather than reporting the steepness of the slope, aspect reports the direction, generally expressed as an azimuthal angle from North 0.  </p> <p> </p>"},{"location":"patterns/terrain/#aspect-method","title":"aspect method","text":"<p>In Earth Engine, the aspect method closely resembles the pattern for slope. </p> <p> <pre><code>graph LR\n  step02(\"ee.Terrain.aspect()\") ;\n  step03[/\"image_aspect\"/]  ;\n  arg01[\"image_elevation_meters\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg; </code></pre> <p></p> <pre><code>var image_aspect = ee.Terrain.aspect(image_elevation_meters);\n</code></pre> <p>Because the method directly compares changes in z-values to changes in x- and y- values, the units for elevation must match the units for x- and y- dimensions. Practically, this means the elevation units must be meters.  </p> <p>The output aspect image reports the direction of slope in degrees. Completely flat pixels (with no slope direction) receive the value 0. It is often good practice to mask these pixels so as not to confuse them with north-facing locations.  </p>"},{"location":"patterns/terrain/#analytic-hillshading","title":"analytic hillshading","text":""},{"location":"patterns/terrain/#concepts_2","title":"concepts","text":"<p>Shaded relief is a method to visualize a three-dimensional surface by creating the illusion of highlights and shadows thrown by sunlight on a terrain. Before computers, cartographers created shaded relief by hand (manual shaded relief) in a workflow that blended science and art. Most GIS software now provide a method to automate shaded relief, called analytic hillshading, that simplifies the shading illusion. </p> <p>The method assumes that the illumination source (sun) is an infinite distance from Earth. As a result, the illumination rays travel and reach the Earth\u2019s surface in parallel.  </p> <p></p> <p>The angle of the illumination rays depends on the sun\u2019s position, which is determined by two coordinates. The solar azimuth angle defines the sun\u2019s position on the horizon in degrees from North. It is often most effective to put the illumination source above the northwest horizon, even though in the northern hemisphere it would be unusual to find the sun in this part of the sky. An interesting fact about the illusion of shaded relief is that placing the illumination source in the southern sky will make the landscape appear inverted: mountain ridges look like valleys and creeks look like ridge lines. Because of this, many analytic hillshade tools in GIS will use 315 as the starting solar azimuth angle. You can then adjust this \u00b1 30 degrees depending on the orientation of ridges and valleys in the area of interest, while taking care not to invert the landscape by pushing the sun too far.  </p> <p>The second solar coordinate the defines the sun\u2019s position above the horizon, or how high the sun hangs in the sky. Many GIS call this the zenith angle, but in Earth Engine it is called elevation. If the sun is directly overhead, the zenith angle is 90 and the sun approaches 0 as it nears the horizon. By default, many GIS go with the Goldilocks solution and set the zenith angle at 45. It is often good to start here and then adjust based on your terrain. Lowering the zenith angle can be helpful on flat terrain, while raising the angle can be helpful in more rugged landscapes.       </p> <p></p> <p>The brightness of the reflected ray is determined by the local incidence angle from the surface normal (perpendicular to the surface). When the incidence angle is near 0, the rays directly strike the surface and reflect at their brightest power. Because most GIS will store the output of the analytic hillshade method as a byte data type (0-255), the brightest pixels will have the data value 255. In a grayscale palette, this value will be displayed white. As the incidence angle increases, the rays strike the surface obliquely, the brightness values decrease, and the display values change from white to gray. As the angle exceeds 90, the brightness values change from gray to black.</p> <p> </p>"},{"location":"patterns/terrain/#hillshade-operation","title":"hillshade operation","text":"<p>In Earth Engine, the <code>ee.Terrain.hillshade()</code> method takes three arguments to output a hillshade image.  </p> <p> <pre><code>graph LR\n  step02(\"ee.Terrain.hillshade()\") ; \n  step03[/\"image_hs\"/]  ;\n  arg01[\"image_elevation_meters\"] ;\n  arg02[\"azimuth angle\"] ;\n  arg03[\"zenith angle\"] ;\n\n  step02 --&gt; step03\n  arg01 --o step02\n  arg02 --o step02\n  arg03 --o step02\n\n  classDef in-out fill:#FFFFFF,stroke-width:1px,stroke: #000000, color:#000000; \n  classDef op fill:#000000,stroke-width:0px,color:#FFFFFF;\n  classDef arg fill:#CCCCCC,stroke-width:0px,color:#000000;\n\n\n  class step01 in-out; \n  class step02 op;\n  class step03 in-out;\n  class arg01 arg;\n  class arg02 arg; \n  class arg03 arg; </code></pre> <p></p> <pre><code>var image_hs = ee.Terrain.hillshade(image_elevation_meters, azimuth, zenith);\n</code></pre>"},{"location":"patterns/terrain/#deviation-from-mean-elevation","title":"deviation from mean elevation","text":"<p>Description forthcoming </p> <pre><code>var image_dme = geo.iTerrain.devFromMeanElev(image, 10);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/time-series/","title":"time series","text":"<p>PATTERNS </p>"},{"location":"patterns/time-series/#time-series","title":"time series","text":"<p>under construction </p>"},{"location":"patterns/ui-design/","title":"ui design","text":"<p>PATTERNS </p>"},{"location":"patterns/ui-design/#user-interface-design","title":"user interface design","text":""},{"location":"patterns/ui-design/#swipe-map-with-side-bar-layout","title":"swipe map with side bar layout","text":"<p>The patterns below provide a template for a swipe map with a side bar for title, subtitle, documentation, and credits. </p>"},{"location":"patterns/ui-design/#make-layout","title":"make layout","text":"<pre><code>// -------------------------------------------------------------\n//  Make Swipe Map with Side Bar Layout\n// -------------------------------------------------------------\n\n// Initialize side bar.\n\nvar side_bar = ui.Panel({\nlayout: ui.Panel.Layout.flow('vertical'),\nstyle: {width: \"20%\"}\n});\n\n// Initialize two new maps.\n\nvar left_Map = ui.Map();\nvar right_Map = ui.Map();\n\n// Initialize swipe map with left and right maps.\n\nvar swipe_map = ui.SplitPanel(          // Initialize split panel.\nleft_Map,                             // Put on left side of panel.\nright_Map,                            // Put on right side of panel.\n'horizontal',                         // Arrange split in horizontal direction.\ntrue                                  // Make a WIPE transition.\n)\n;\n\n// Link maps together.\n\nui.Map.Linker([\nleft_Map, right_Map\n])\n;\n\n// Initialize a panel to hold swipe map.\n\nvar swipe_map_panel = ui.Panel(\n{\nwidgets: [swipe_map]\n});\n\n// Initialize layout with side bar and swipe map\n\nvar layout = ui.SplitPanel(\n{\nfirstPanel: side_bar,\nsecondPanel: swipe_map_panel, orientation: 'horizontal',\nwipe: false\n}\n);\n\n// Add layout to root. \n\nui.root.clear();\nui.root.setLayout(ui.Panel.Layout.flow('horizontal'));\nui.root.add(layout);\n</code></pre>"},{"location":"patterns/ui-design/#add-labels-for-maps","title":"add labels for maps","text":"<pre><code>// -------------------------------------------------------------\n//  Make left and right map labels.\n// -------------------------------------------------------------\n\nvar style_label_map = {\nfontSize: '18px',\nfontWeight: 'bold',\nfontFamily: 'Helvetica, sans-serif',\n}\n;\n\nvar label_map_left = ui.Label({\nvalue: 'label for left map',\nstyle: style_label_map,\n}\n);\n\nlabel_map_left.style().set({\nposition: 'bottom-left',\n});\n\nvar label_map_right = ui.Label({\nvalue: 'label for right map',\nstyle: style_label_map,\n}\n);\n\nlabel_map_right.style().set({\nposition: 'bottom-right',\n});\n\nleft_Map.add(label_map_left);\nright_Map.add(label_map_right);\n</code></pre>"},{"location":"patterns/ui-design/#add-title","title":"add title","text":"<pre><code>// -------------------------------------------------------------\n//  Add Title\n// -------------------------------------------------------------\n\nvar style_title = {\nfontSize: '24px',\nfontWeight: 'bold',\nfontFamily: 'Helvetica, sans-serif',\nwhiteSpace: 'wrap'\n}\n;\n\nvar title = ui.Label({\nvalue: \"Layout title\",\nstyle: style_title,\n}\n);\n\nside_bar.add(title);\n</code></pre>"},{"location":"patterns/ui-design/#add-subtitle","title":"add subtitle","text":"<pre><code>// -------------------------------------------------------------\n//  Add Subtitle\n// -------------------------------------------------------------\n\nvar style_subtitle = {\nfontSize: '18px',\nfontWeight: 'bold',\nfontFamily: 'Helvetica, sans-serif',\ncolor: 'OliveDrab',\nwhiteSpace: 'pre'\n}\n;\n\nvar subtitle = ui.Label({\nvalue: \"Place\\n(start-end)\",\nstyle: style_subtitle,\n}\n);\n\nside_bar.add(subtitle);\n</code></pre>"},{"location":"patterns/ui-design/#add-documentation","title":"add documentation","text":"<pre><code>// -------------------------------------------------------------\n//  Add documentation.\n// -------------------------------------------------------------\n\nvar style_docs = {\nfontSize: '12px',\nfontFamily: 'Helvetica, sans-serif',\nposition: 'bottom-right'\n}\n;\n\nvar docs = ui.Label({\nvalue: 'more information',\nstyle: style_docs,\ntargetUrl: 'link to google doc'       // Change sharing to \"Anyone with the link\"\n}\n);\n\nside_bar.add(docs);\n</code></pre>"},{"location":"patterns/ui-design/#add-credits","title":"add credits","text":"<pre><code>// -------------------------------------------------------------\n//  Add credits \n// -------------------------------------------------------------\n\nvar style_credits = {\nfontSize: '10px',\nfontFamily: 'Helvetica, sans-serif',\nposition: 'bottom-right'\n}\n;\n\nvar credits = ui.Label({\nvalue: 'Your Name',\nstyle: style_credits,\ntargetUrl: 'link to portfolio or online presence'\n}\n);\n\nside_bar.add(credits);\n</code></pre>"},{"location":"patterns/ui-design/#add-interactivity","title":"add interactivity","text":"<p>These patterns provide tools that allow the user to interact with the layout.  </p>"},{"location":"patterns/ui-design/#select-places-of-interest","title":"select places of interest","text":"<pre><code>// -------------------------------------------------------------\n//  Select places of interest\n// -------------------------------------------------------------\n\n//  Make dictionary of places of interest. \n\nvar places = {\n\n// \"Place name\": [longitude, latitude, zoom]\n\"Atwater Lot\": [-73.17655, 44.01282, 18],\n\"Full Extent\": [-73.17661, 44.01243, 14],\n\n};\n\nvar select = ui.Select({\nitems: Object.keys(places),\nplaceholder: \"Choose a location\",\nonChange: function(key) {\n\n// This will recenter the map to the place of interest. \n\nleft_Map.setCenter(places[key][0], places[key][1], places[key][2]);\n\n}\n});\n\n// Add the widget to the side bar.\n\nside_bar.add(select);\n</code></pre>"},{"location":"patterns/ui-design/#layer-visibility-checkbox","title":"layer visibility checkbox","text":"<pre><code>// -------------------------------------------------------------\n//  Checkbox for layer visibility.\n// -------------------------------------------------------------\n\n// Initialize a checkbox with a label and check the box by default. \n\nvar checkbox = ui.Checkbox('Label', true);\n\n// Define what happens when you check the box. \n\ncheckbox.onChange(function(checked) {\n\n// Show or hide the first map layer (controlled by index) based on the checkbox's value.\n\nleft_Map.layers().get(0).setShown(checked);\nright_Map.layers().get(0).setShown(checked);\n});\n\n// Add the checkbox to the side panel.  \n\nside_bar.add(checkbox);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/vector-operations/","title":"vector operations","text":"<p>PATTERNS </p>"},{"location":"patterns/vector-operations/#vector-operations","title":"vector operations","text":"<p>Vector operations work with tables of geometries and often attributes. </p>"},{"location":"patterns/vector-operations/#transform-geometries","title":"transform geometries","text":"<p>These methods create new geometries based on the input geometries of feature collections.    </p> <p>More to come.</p>"},{"location":"patterns/vector-operations/#bounding-box","title":"bounding box","text":"<pre><code>var fc_bounds = geo.fcGeometry.boundingBox(fc);\n\nMap.addLayer(fc_bounds, {color: 'cyan'}, \"Bounding box\", false);\n</code></pre>"},{"location":"patterns/vector-operations/#centroid","title":"centroid","text":"<pre><code>var fc_centroid = geo.fcGeometry.centroidPoint(fc);\n\nMap.addLayer(fc_centroid, {color: 'yellow'}, \"Centroid point\", false);\n</code></pre>"},{"location":"patterns/vector-operations/#convex-hull","title":"convex hull","text":"<pre><code>var fc_convex_hull = geo.fcGeometry.convexHullPolygon(fc);\n\nMap.addLayer(fc_convex_hull, {color: 'magenta'}, \"Convex hull\", false);\n</code></pre>"},{"location":"patterns/vector-operations/#multipart-vs-single-part-geometries","title":"multipart vs. single part geometries","text":"<p>These methods change the form of the geometries liked to rows in a table. The picture below illustrates several concepts. The leftmost frame (A) shows a table with a singlepart geometry; a single polygon linked to each row in the table. The center frame (B) shows a table linked to multipart geometry (multipart geometry can link two or more polygons to a single row of attributes). The rightmost frame (C) shows another table with multipart geometries; four polygons associated with one row.   </p> <p></p> <p>Operations are shown laterally. Moving from A to B is a dissolve operation (singlepart \u2192 multipart), while moving from B to A is an explode operation (multipart \u2192 singlepart). Note the asymmetry between moves on the right side. From B to C is another dissolve, but from C to B is not possible.  </p>"},{"location":"patterns/vector-operations/#dissolve-by-attribute","title":"dissolve by attribute","text":"<p>This will dissolve a feature collection into multipart features that share a common attribute. </p> <pre><code>// -------------------------------------------------------------\n//  Dissolve by attribute\n// -------------------------------------------------------------\n\nvar output_dissolve = geo.fcGeometry.dissolveByAttribute(fc, \"property\");\n\nprint(\"DISSOLVE\", fc.first(), output_dissolve.first());\n</code></pre> <p>Using the illustration at the top of this section, the snippet below will transform A into B. </p> <pre><code>var B = geo.fcGeometry.dissolveByAttribute(A, \"GRADE\");\n</code></pre> <p>Please note that the property name is literal (and case sensitive), so when working with HOLC data you would need to specify \u201cholc_grade\u201d to transform A to B and \u201ccity\u201d to transform B to C. </p>"},{"location":"patterns/vector-operations/#vector-overlay","title":"vector overlay","text":"<p>Vector overlay operations compare locations between two vector layers. In Earth Engine, the vector layers are generally features in a feature collection.  </p> <p>more soon </p>"},{"location":"patterns/vector-operations/#clip-by-region","title":"clip by region","text":"<p><code>geo.fcOverlay.clipByRegion()</code> is a knife method that takes two arguments. </p> ARGUMENT DESCRIPTION fc_dough A vector dataset (feature collection) with features that you want to cut. fc_cutter A vector dataset (feature collection) with features that you want to use as the knife to cut the dough. <p>The output is a feature collection that retains that attributes but alters the geometry of the dough.  </p> <pre><code>var fc_clip = geo.fcOverlay.clipByRegion(fc_dough, fc_cutter);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"patterns/zonal-operations/","title":"zonal operations","text":"<p>PATTERNS</p>"},{"location":"patterns/zonal-operations/#zonal-operations","title":"zonal operations","text":"<p>Zonal operations analyze pixel values in one layer based zones (regions) defined by another layer. In Earth Engine, the zones are generally defined by features in a feature collection.  </p> <p>more soon </p>"},{"location":"patterns/zonal-operations/#zonal-area","title":"zonal area","text":"<p>These methods use the zones defined by the geometry of a feature collection to compute the area of each class in a nominal or boolean layer.  </p>"},{"location":"patterns/zonal-operations/#area-of-classes","title":"area of classes","text":"<p>This method returns a dictionary that reports the total area (in square meters) of each class (integer value) in the input raster.  </p> <pre><code>var area_of_classes = geo.iZonal.areaClasses(image, scale, region, \"band_name\");\n\nprint(\n\"Area (square meters)\",\narea_of_classes\n);\n</code></pre> <p>The table below describes the arguments.  </p> ARGUMENT DESCRIPTION image The boolean or nominal (class) image to compute the area for each unique pixel value. scale The pixel scale for analysis to troubleshoot TIME OUT errors. It can be helpful to first run at a coarse resolution and then increase resolution (make number smaller) as appropriate. region Feature collection with one or more features that define the area of analysis or study region. \u201cband_name\u201d The band name in the image with the integer values that identify the classes to compute the area of."},{"location":"patterns/zonal-operations/#area-of-classes-as-percent-of-region","title":"area of classes as percent of region","text":"<p>This method returns a dictionary that reports the total area of each class (integer value) in the input raster as a percent of the region. It takes the output from <code>.areaClasses()</code> (above) as the input and returns a dictionary. </p> <pre><code>var class_percent_of_region = geo.iZonal.classPercentRegion(area_of_classes);\n\nprint(\n\"Area (percent of region)\",\nclass_percent_of_region\n)\n;\n</code></pre>"},{"location":"patterns/zonal-operations/#complete-pattern","title":"complete pattern","text":"<p>Here is the complete pattern for calculating the area of raster classes and their percent area of a region.  </p> <pre><code>var area_of_classes = geo.iZonal.areaClasses(image, scale, region, \"band_name\");\n\nprint(\n\"Area (square meters)\",\narea_of_classes\n);\n\nvar class_percent_of_region = geo.iZonal.classPercentRegion(area_of_classes);\n\nprint(\n\"Area (percent of region)\",\nclass_percent_of_region\n)\n;\n</code></pre>"},{"location":"patterns/zonal-operations/#zonal-statistics","title":"zonal statistics","text":"<p>This method calculates a statistic of image values within a zone of analysis defined by one or more features in a feature collection. The output of the method is a feature collection with a new column that contains the statistic.  </p> <p></p> <pre><code>var fc_zonal_stat = geo.iZonal.zonalStats(dough, cutter, \"statistic\", scale);\n</code></pre> <p>The method takes four arguments that are defined in the table below.  </p> ARGUMENTS DESCRIPTION dough The image with pixel values to be analyzed. cutter The feature collection with one or more features that define the zones of analysis. \u201cstatistic\u201d The statistic to calculate within each zone of analysis. Must be a string from these options: \u201csum\u201d, \u201cmax\u201d, \u201cmin\u201d, \u201cmean\u201d, \u201ccount\u201d, \u201cvariety\u201d (\u201ccount\u201d reports the number of pixels, while \u201cvariety\u201d reports the number of unique pixel values). scale The scale of analysis. When you encounter time out errors, you can try to resolve by changing the scale of analysis. If you do not encounter time out errors, you can leave this argument blank. <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-01/","title":"P1. Memory under cover","text":"<p>PRACTICE 1</p>"},{"location":"problems/practice-01/#memory-under-cover","title":"Memory under cover","text":""},{"location":"problems/practice-01/#goal","title":"goal","text":"<p>Your goal is to import a digital elevation model (DEM), make a Map with the five layers shown in the app below, and then use these layers to interpret the four POI.</p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-01/#starter-script","title":"starter script","text":"<pre><code>// -------------------------------------------------------------\n//  Access image from this cloud address:\n//  \"projects/ee-patterns/assets/p01/chipmanHill_2023_35cm_DEMHF\"\n// -------------------------------------------------------------\n\nvar image ;\n\n\n// -------------------------------------------------------------\n//  Customize Map. \n// -------------------------------------------------------------\n\n// Set map center and zoom level.\n\n\n//  Set basemap style to hybrid.\n\n\n// -------------------------------------------------------------\n//  Display image as a map layer;\n//  Stretch layer display values over image data range.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Multiply the elevation values by 2 (apply a scalar operation)\n//  and then derive slope of this surface.\n// -------------------------------------------------------------\n\nvar image_slope ;\n\n// -------------------------------------------------------------\n//  Display slope image as a map layer;\n//  Stretch layer display values over image data range.\n//  Display so that \"steeper is darker\".\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Multiply the elevation values by 2 (apply a scalar operation)\n//  and then calculate the hillshade of this surface. \n// -------------------------------------------------------------\n\nvar image_hs ;\n\n// -------------------------------------------------------------\n//  Using the original elevation surface (without a scalar applied),\n//  calculate the deviation from mean elevation;\n//  Use 10 as the distance argument.\n//  Try to display the layer with this palette: ['blue', 'white', 'red']\n// -------------------------------------------------------------\n\nvar image_dme ;\n\n\n// -------------------------------------------------------------\n//  PRACTICE CHECKS\n// -------------------------------------------------------------\n\n//  I. QUANTITATIVE \n\nprint(\"QUANTITATIVE CHECKS:\");\n\n//  Import check module for tutorial 1.\n//  Uncomment the line below.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p01.js\");\n\n//  Uncomment the three lines below, run script, and look at the results in Console. \n\n// check.checkPoint(\"CP1:\", image_slope);\n// check.checkPoint(\"CP2:\", image_hs);\n// check.checkPoint(\"CP3:\", image_dme);\n\n//  II. QUALITATIVE  \n\n//  Use zoom to inspect locations marked A, B, C, D.\n//  For each letter, please write down:\n\n//    1. What do you think the linear feature marked by the letter \"is\"?\n//    2. Why?\n\n//  When you have completed this practice problem, please take the short quiz on Canvas where you will report your results. \n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-02/","title":"P2. Ice age bathtub","text":"<p>PRACTICE 2</p>"},{"location":"problems/practice-02/#ice-age-bathtub","title":"Ice age bathtub","text":""},{"location":"problems/practice-02/#goal","title":"goal","text":"<p>Your goal is to import a digital elevation model (DEM) and make a Map with the four layers shown in the app below. When you have finished solving the problem (or when the clock is approaching 5pm on Friday), please work through the check-up on Canvas as best you can. </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-02/#starter-script","title":"starter script","text":"<pre><code>var geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.\nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module.  \n\n// -------------------------------------------------------------------------------\n//  Gather image from \"projects/ee-patterns/assets/p02/NOAA-CoNED-SOCAL\".\n//  Print a histogram - do you see land vs ocean floor in the histogram?\n// -------------------------------------------------------------------------------\n\nvar image = ee.Image(\"projects/ee-patterns/assets/p02/NOAA-CoNED-SOCAL\");\n\nprint(\"Image\", image);\n\n\n// -------------------------------------------------------------------------------\n//  Area of interest for practice problem.\n// -------------------------------------------------------------------------------\n\nvar aoi = image.geometry();\n\n\n// Center map on aoi at zoom level 9 and set base layer to hybrid.\n\n\n\n\n// -------------------------------------------------------------------------------\n//  Apply a vertical exageration (z-factor) of 2 to elevation data for hillshade. \n//  Make a hillshade from this image and display the hillshade image as layer on Map.\n// -------------------------------------------------------------------------------\n\nvar image_ve ;\n\nvar image_hs ;\n\n\n// -------------------------------------------------------------------------------\n//  Separate the original elevation image (without vertical exageration) into two different images:\n\n//  (1) land elevations\n//  (2) ocean floor elevations (bathymetry)\n\n//  Each image should only store land or bathymetry elevation values, respectively.\n//  All other values should be masked.\n// -------------------------------------------------------------------------------\n\nvar image_land ;\n\nvar image_bathy ;\n\n// -------------------------------------------------------------------------------\n//  Reclassify the bathymetry image at 100 meter intervals. \n//  Display the reclassified image as layer on Map with 0.5 opacity.\n//  To improve contrast, set max of viz dictionary such that all locations less than -2000 m (or class 20) are the darkest blue in palette.\n//  Use this palette: geo.iPalettes.iBathy.eleven\n// -------------------------------------------------------------------------------\n\n\n\nvar image_bathy_reclass ;\n\n\n\n// -------------------------------------------------------------------------------\n//  Define the Pleistocene shoreline as 130 meters lower than today's shoreline.\n//  Make a boolean image that shows all land above ocean in Pleistocene.\n//  Display boolean image as layer on Map with all non-land masked.\n//  Set opacity of layer at 0.5.\n// -------------------------------------------------------------------------------\n\nvar image_pleistocene ;\n\n\n// -------------------------------------------------------------------------------\n//  Reclassify the land image at equal 100 meter intervals. \n//  Display the reclassified image as layer on Map with 0.5 opacity.\n//  Use this palette: geo.iPalettes.iHypso.bartholomew\n//  Set opacity of layer at 0.5.\n// -------------------------------------------------------------------------------\n\nvar image_land_reclass ;\n\n\n\n\n// -------------------------------------------------------------\n//  PRACTICE CHECKS\n// -------------------------------------------------------------\n\n//  I. QUANTITATIVE \n\nprint(\"QUANTITATIVE CHECKS:\");\n\n//  Import check module for tutorial 1.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p02.js\");\n\n//  Uncomment the five lines below, run script, and look at the results in Console. \n\n// check.checkPoint(\"CP1:\", image_hs);\n// check.checkPoint(\"CP2:\", image_land);\n// check.checkPoint(\"CP3:\", image_bathy);\n// check.checkPoint(\"CP4:\", image_pleistocene);\n// check.checkPoint(\"CP5:\", image_bathy_reclass);\n</code></pre>"},{"location":"problems/practice-02/#advice-on-printing-histograms","title":"advice on printing histograms","text":"<p>This is a BIG dataset. Whenever you print histogram or min-max values, set the scale to 30 and the extent to aoi.  </p> <pre><code>print(\"Image histogram\", geo.iCart.iHistogram(image, 30, aoi));\n</code></pre> <pre><code>print(\"Min &amp; max value of image\", geo.iCart.iMinMax(image, 30, aoi));\n</code></pre>"},{"location":"problems/practice-02/#check-definitions","title":"check definitions","text":"VARIABLE DESCRIPTION image_hs Hillshade image from elevation data with vertical exaggeration of 2, azimuth 315, and zenith 35. image_land Land elevations only. All sea floor elevations should be masked. image_bathy Sea floor elevations only. All land elevations should be masked. Include 0 elevation as sea floor. image_pleistocene Flexible depending on how you solve this. It could represent sea floor elevations when the sea-level was 130 meters lower than today, or you could skip this step and just define the boolean image. Many different answers are potentially fine for this one and we will discuss in class on Monday. image_bathy_reclass Modern sea floor (bathy) elevations reclassified into equal interval classes."},{"location":"problems/practice-02/#data-sources","title":"data sources","text":"<p>CoNED </p> <p>GEE Awesome Community Datasets </p> <p>CoNED Data Archive </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-03/","title":"P3. Parent materials of soils","text":"<p>PRACTICE 3</p>"},{"location":"problems/practice-03/#parent-materials-of-soils","title":"Parent materials of soils","text":""},{"location":"problems/practice-03/#purpose","title":"purpose","text":"<p>Your goal is to make a map that could help town planners in Addison County compare information from the Addison County Soil Survey (1971) to property parcels in their town.  </p> <p>Practically, your workflow will include the following patterns:  </p> <ul> <li>gather and inspect vector data  </li> <li>filter feature collections  </li> <li>convert vector to raster  </li> <li>mask raster data </li> <li>display layer of nominal classes with unique colors </li> <li>explain nominal class symbology    </li> <li>filter and flatten an image collection  </li> <li>make terrain layers </li> <li>paint strokes    </li> </ul> <p>When you solve the problem, you should have a workflow that uses the town of Middlebury as the test subject to produce a map with the layers shown in the app below. Ideally, you will write the script so that you can very easily shift the map to any other town in Addison County, Vermont.   </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-03/#data-sources","title":"data sources","text":"<p>We will use a number of datasets that are available through the cloud, either through the Earth Engine Data Catalog or assets that I maintain for Vermont geography.  </p> <p> DATA DESCRIPTIONS US Counties sourcebackground VT Towns source VT Parcels sourcebackground VT Soils sourcebackgroundreport DEM 1m sourcebackground <p></p>"},{"location":"problems/practice-03/#starter-script","title":"starter script","text":"<pre><code>var geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n\n// -------------------------------------------------------------\n//  DATA SOURCES \n// ------------------------------------------------------------- \n\nvar fc_address_county = \"TIGER/2018/Counties\";\nvar fc_address_town = \"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\";\nvar fc_address_parcel = \"projects/vt-conservation/assets/state/FS_VCGI_OPENDATA_Cadastral_VTPARCELS_poly_standardized_parcels_SP_v1\";\nvar fc_address_soils = \"projects/conservation-atlas/assets/soils/VT_Data_NRCS_Soil_Survey_Units\";\nvar ic_address_dem = \"USGS/3DEP/1m\"; var palette_soils = geo.iPalettes.iSoils.parent_materials_addison_county;\nvar class_labels_soils = geo.iPalettes.iSoils.parent_materials_addison_county_labels;\n\nprint(\"SOILS Palette and Class labels\", palette_soils, class_labels_soils);\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. GATHER HUMAN GEOGRAPHY\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Make Addison County layer\n// -------------------------------------------------------------\n\nvar fc_county ;\n\n// -------------------------------------------------------------\n//  1.2 Make study town (Middlebury) layer\n// -------------------------------------------------------------\n\nvar fc_town ;\n\n// -------------------------------------------------------------\n//  1.3 Center map on study town\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  1.4 Make parcels in study town layer\n// -------------------------------------------------------------\n\nvar fc_parcels ;\n\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. GATHER SOILS DATA AND FILTER FOR ADDISON COUNTY \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  2.1 Gather soils data\n// -------------------------------------------------------------\n\n\nvar fc_soils ;\n\n\n\n// -------------------------------------------------------------\n//  2.2 Filter for soils that overlap Addison County\n// ------------------------------------------------------------- \n\nvar fc_filter_bounds_soils ;\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  3. MAKE PARENT MATERIAL IMAGE FOR STUDY TOWN. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  3.1 Make nominal image of soil parent material. \n// -------------------------------------------------------------\n\nvar image_nominal_soils ;\n\n// -------------------------------------------------------------\n//  3.2 Mask by Addison County.\n// -------------------------------------------------------------\n\nvar image_with_mask_soils ;\n\n// -------------------------------------------------------------\n//  3.3 Display masked soils image as layer. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.4 Add legend to bottom-left of Map. \n// -------------------------------------------------------------\n\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  4. GATHER DEM \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  4.1 Construct image collection. \n// -------------------------------------------------------------\n\nvar ic_dem ;\n\n// -------------------------------------------------------------\n//  4.2 Filter for images that overlap Addison County.\n// -------------------------------------------------------------\n\nvar ic_filtered_dem_county ;\n\n// -------------------------------------------------------------\n//  4.3 Mosaic filtered image collection to image. \n// -------------------------------------------------------------\n\nvar ic_dem_mosaic ;\n\n\n// -------------------------------------------------------------\n//  4.2 Mask mosaic image by Addison County. \n// -------------------------------------------------------------\n\nvar image_with_mask_dem ;\n\n// -------------------------------------------------------------\n//  4.3 Make hillshade from masked image and display as layer with 0.5 opacity.\n//  No vertical exaggeration; azimuth 315; zenith 35.\n// -------------------------------------------------------------\n\nvar hs  ;\n\n// -------------------------------------------------------------\n//  4.6 Make slope from masked image and display as layer with 0.5 opacity.\n// -------------------------------------------------------------\n\nvar slope ;\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  5. PAINT STROKES\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  5.1 Make strokes for parcels (\"white\" and 0.5 weight) and add as layer.\n// -------------------------------------------------------------\n\nvar strokes_parcels ;\n\n// -------------------------------------------------------------\n//  5.2 Make strokes for town (\"white\" and 4 weight) and add as layer.\n// -------------------------------------------------------------\n\nvar strokes_town ;\n\n// -------------------------------------------------------------\n//  PRACTICE CHECKS\n// -------------------------------------------------------------\n\nprint(\"CHECKS:\");\n\n//  Import check module for tutorial 1.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p03.js\");\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n//  PLEASE DO THE FOLLOWING: \n\n// 1. Uncomment all of the check statements below.\n// 2. Replace 'result_#p#' with the name of the data object that you used to map as a layer in each section.\n// 3. Run the script.\n// 4. Use the results printed to Console in the Check Up that is due Friday 5pm. \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n// check.checkCollection(\"Check 1.1\", result_1p1);\n// check.checkCollection(\"Check 1.2\", result_1p2);\n// check.checkCollection(\"Check 1.4\", result_1p4);\n// check.checkCollection(\"Check 2.1\", result_2p1);\n// check.checkCollection(\"Check 2.2\", result_2p2);\n\n// check.checkPoint(\"Check 3.3\", result_3p3);\n// check.checkPoint(\"Check 4.5\", result_4p5);\n// check.checkPoint(\"Check 4.6\", result_4p6);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-04/","title":"P4. Forest blocks and habitat connectors","text":"<p>PRACTICE 4 </p>"},{"location":"problems/practice-04/#forest-blocks-and-habitat-connectors","title":"Forest blocks and habitat connectors","text":""},{"location":"problems/practice-04/#goal","title":"goal","text":"<p>This problem continues working on our map of forest habitat blocks for the town of Middlebury, Vt.  </p> <p>Your practical goal is to:</p> <ol> <li>include rare natural communities in your forest habitat block layer; </li> <li>incorporate lidar-informed flood inundation data to map habitat connectors;</li> <li>distinguish habitat blocks and connectors as separate classes in a single raster layer.</li> </ol> <p>Your workflow should reproduce all the layers shown in the app below.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-04/#data-sources","title":"data sources","text":"<p>This problem uses several datasets from the tutorial problem. In addition, we will use two new datasets described in the table below.  </p> <p> ASSET NAME DESCRIPTION FORMAT RESOLUTION LakeChamplainBasin Lake Champlain Basin Lidar-Informed Flood Inundation Layer Image 70 cm SignificantNaturalCommunities VT Significant Natural Communities FC <p></p>"},{"location":"problems/practice-04/#starter-script","title":"starter script","text":""},{"location":"problems/practice-04/#00-getting-started","title":"00 Getting started","text":"<p>Begin with a header and importing the module. The address variables will give you access to all the data that you need for this problem.  </p> <pre><code>/*     \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     \n    TITLE:  \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// Feature collections\n\nvar vt_town_address = \"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\";\nvar rare_address = \"projects/conservation-atlas/assets/rarity/Significant_Natural_Communities\";\nvar large_blocks_middlebury = \"projects/ee-patterns/assets/vt-conservation/t04_habitat_blocks\";\n\n// Images\n\nvar valley_bottom_address = \"projects/vt-conservation/assets/champlain_basin/LakeChamplainBasin\";\nvar imp_address = \"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Impervious\";\n</code></pre>"},{"location":"problems/practice-04/#01-define-study-region","title":"01 Define study region","text":"<p>This section is pretty similar to the tutorial, so you should be able to recycle that code here.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. Define study region.\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Define study town (Middlebury)\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.2 Convert study town into boolean (to use as mask later)\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.3 Define aoi as study town and towns that overlap (share boundary) with study town.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.4 Convert aoi into a boolean (to use as mask later).\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.5 Center map on study town and set basemap to hybrid. \n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-04/#02-include-rarity-in-blocks","title":"02 Include rarity in blocks","text":"<p>Often, rare elements on the landscape are small in size. So by selecting habitat blocks that are greater than 100 acres, we may show bias and under-represent rare elements of the landscape in our conservation plan, essentially making poverty traps for rare but significant natural communities. </p> <p>To try to right this wrong, this chunk of the problem gathers data on Significant Natural Communities collected through Vermont\u2019s Natural Heritage program and includes these locations in our habitat blocks layer, even if they are relatively small.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. Make blocks inclusive of rare communities.  \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  2.1 Gather habitat blocks cloud asset that overlap aoi. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.2 Convert 2.1 to a boolean image.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.3 Gather rare natural communities that overlap aoi.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  2.4 Make boolean image of rare natural communities that overlap aoi.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.5 Make a boolean image of locations that are either blocks or rare natural communities.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-04/#03-classify-habitat-blocks-versus-habitat-connectors","title":"03 Classify habitat blocks versus habitat connectors","text":"<p>If you look at the habitat block layers we have mapped thus far, you will notice that many blocks have both low connectivity and low circuitry. In this step, we aim to improve both conditions by modeling habitat connectors.  </p> <p>Your goal in this set of tasks is to use the Lidar-Informed Flood Inundation layer to represent valley bottoms. Your final layer should bring in valley bottom locations so that any valley bottom that does not overlap a habitat block is classed with the value 2. This will make a layer with three classes as shown in the table below.  </p> VALUE CLASS NAME 0 Neither a block or valley bottom. 1 Habitat blocks. 2 Habitat connectors (valley bottoms that are not habitat blocks or not impervious surfaces). <p>When you have made this layer, it is a good time to export the image as a cloud asset to use in the final steps of the problem.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  3. Classify habitat blocks versus habitat connectors.  \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  3.1 Gather valley bottom, make it boolean (anything not 0 is true), and mask for aoi.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  3.2 Erase all impervious land from valley bottoms.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.3 Distinguish valley bottoms without impervious that do not intersect habitat blocks as a new habitat class.\n// Your goal here is to make a single layer where the value 1 represents habitat blocks and 2 represents connectors that are not also blocks nor are they an impervious surface. \n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  3.4 Export 3.3 image to asset and display asset as Map layer.   \n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-04/#04-cartography","title":"04 Cartography","text":"<p>Finish your workflow with a little cartography to provide support to a map reader.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  4. A little cartography \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  4.1 Add a legend for the habitat block/connector layer.  \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  4.2 Add layer of outlines for study town.  \n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-04/#05-checks","title":"05 Checks","text":"<pre><code>// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n//  PRACTICE CHECKS\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\nprint(\"CHECKS:\");\n\n//  Import check module for practice problem 4.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p04.js\");\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\n//  PLEASE DO THE FOLLOWING: \n\n// 1. Uncomment all of the check statements below.\n// 2. Replace 'result_#p#' with the name of the data object that you used to map as a layer in each section.\n// 3. Run the script.\n// 4. Use the results printed to Console in the Check Up that is due Friday 5pm. \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\n// check.checkCollection(\"Check 1.1\", result_1p1);\n// check.checkCollection(\"Check 1.3\", result_1p3);\n// check.checkCollection(\"Check 2.1\", result_2p1);\n// check.checkCollection(\"Check 2.3\", result_2p3);\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  Check 3.4. What percent of Middlebury are habitat blocks and connectors?  \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// Please calculate percent area based on your result from 3.4.\n// When calculating area, please use 5 for scale and study_town (Middlebury) for extent.\n// The last two checks in Canvas will ask you to report area for habitat blocks and habitat connectors separately. \n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-05/","title":"P5. Land use in watershed riparian zones","text":"<p>PRACTICE 05 </p>"},{"location":"problems/practice-05/#land-use-in-watershed-riparian-zones","title":"land use in watershed riparian zones","text":""},{"location":"problems/practice-05/#goal","title":"goal","text":"<p>This problem aims to help you practice working with proximity and zonal statistics in Earth Engine. </p> <p>Your practical goal is to make a map that reports the percent of riparian zones that are either developed or used for agriculture in each watershed that overlaps a study town.  </p> <p>We will define key terms as follows: </p> <ul> <li>study town: Middlebury, Vermont  </li> <li>aoi: all level 12 watersheds that overlap the study town  </li> <li>surface waters: all streams, rivers, ponds, and lakes    </li> <li>riparian: all land within 50 feet of surface waters  </li> <li>developed: all impervious surfaces (buildings, roads, pavement, and railroads)  </li> <li>agriculture: all agricultural land uses (hayfields, crop fields, and pasture)  </li> <li>scale: for Part 9, use scale of 30 to help the model run a little faster</li> </ul> <p>Your solution should produce a map with the layers shown in the app below.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-05/#data-sources","title":"data sources","text":"<p>In this problem, we will use the National Hydrology Dataset (NHD) that is available as a cloud asset through the Awesome Earth Engine Community Catalog.</p> <p>In addition, we will use town and land cover data that we have worked with in previous problems.  </p>"},{"location":"problems/practice-05/#workflow","title":"workflow","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR: \n    DATE:   \n    TITLE:  Land use in watershed riparian zones\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// -------------------------------------------------------------\n//  datasets\n// -------------------------------------------------------------\n\n// Towns\n\nvar vt_towns = ee.FeatureCollection(\"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\"); // Land cover\n\nvar vt_ag = ee.Image(\"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Agriculture\");\nvar vt_imp = ee.Image(\"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Impervious\");\n\n// National Hydrology Dataset\n\nvar nhd_wbdhu12 = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/WBDHU12\");\nvar nhd_flowline = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/NHDFlowline\");\nvar nhd_area = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/NHDArea\");\nvar nhd_waterbody = ee.FeatureCollection(\"projects/sat-io/open-datasets/NHD/NHD_VT/NHDWaterbody\");\n\n// Viz helpers\n\nvar viz_bool = {min:0, max:1};\nvar red_palette = geo.iPalettes.yellowOrangeRed[6];\n\n// General parameters.\n\nvar scale = 30;  // To help model run a little faster, please set scale at 30 in Part 9. \n\n// -------------------------------------------------------------\n//  1. Define study town and set up map.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2. Select Level 12 watersheds that overlap study town. \n// -------------------------------------------------------------  \n\n\n\n// -------------------------------------------------------------\n//  3. Select NHD features that overlap selected watersheds. \n// -------------------------------------------------------------  \n\n\n// -------------------------------------------------------------\n//  4. Clip selected area features to selected watersheds. \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  5. Define riparian as buffer of selected hydrology features by 50 feet.  \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  6. Make union of buffered hydrology features.    \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  7. Define developed land as union of impervious and ag lands.    \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  8. Define developed land in riparian.     \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  9. Compute percent of developed land in riparian. (Set scale = 30 to help model run faster.)       \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  10. Classify percent into equal 10% intervals.  \n// ------------------------------------------------------------- \n\n\n\n// -------------------------------------------------------------\n//  11. Add watershed reference lines and legend.     \n// ------------------------------------------------------------- \n</code></pre>"},{"location":"problems/practice-05/#checks","title":"checks","text":"<p>Please add this code to the end of your script and edit the names to match those of your layers. You will need this answers to complete the checkup on Canvas that is due Monday by 5pm.</p> <pre><code>// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n//  PRACTICE CHECKS\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\nprint(\"CHECKS:\");\n\n//  Import check module for practice problem 4.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/p05.js\");\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\n//  PLEASE DO THE FOLLOWING: \n\n// 1. Uncomment all of the check statements below.\n// 2. Replace 'result_part_#' with the name of the data object that you used to map as a layer in each section.\n// 3. Run the script.\n// 4. Use the results printed to Console in the Check Up that is due Monday 5pm. \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\n\ncheck.checkFeature(\"Check Part 1:\", result_part_1);\ncheck.checkFeature(\"Check Part 2:\", result_part_2);\ncheck.checkArea(\"Check Part 6:\", result_part_6);\ncheck.checkArea(\"Check Part 7:\", result_part_7);\ncheck.checkArea(\"Check Part 8:\", result_part_8);\ncheck.checkPoint(\"Check Part 9:\", result_part_9);\ncheck.checkPoint(\"Check Part 10:\", result_part_10);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-06/","title":"P6. Changes in the night","text":"<p>PRACTICE 6 </p>"},{"location":"problems/practice-06/#changes-in-the-night","title":"Changes in the night","text":""},{"location":"problems/practice-06/#goal","title":"goal","text":"<p>This problem aims to introduce you to making and interpreting RGB composites with additive color.  </p> <p>Your practiceal goal is to make a map that shows changes in the brightness of nighttime lights between 1993, 2003, and 2013. You will then interpret the additive colors in the image to describe different patterns of change.  </p> <p>Your solution should make a map like that shown in the app below. </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-06/#conceptual-workflow","title":"conceptual workflow","text":"<p>The diagram below sketches how we will use additive color to show changes in a nighttime lights dataset with Earth Engine.  </p> <p></p>"},{"location":"problems/practice-06/#starter-workflow","title":"starter workflow","text":""},{"location":"problems/practice-06/#00-start-a-new-script","title":"00 start a new script","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     \n    TITLE:    P6: Changes in the night\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module.\n</code></pre>"},{"location":"problems/practice-06/#01-set-up-map-and-aoi","title":"01 set up map and AOI","text":"<pre><code>// -------------------------------------------------------------\n//  Set up Map.\n// -------------------------------------------------------------\n\nMap.setCenter(126.8, 33.485, 5);\nMap.setOptions('HYBRID');\n\n// Get AOI from Map extent\n</code></pre>"},{"location":"problems/practice-06/#02-gather-image-collection","title":"02 gather image collection","text":"<p>Please use this dataset and band: </p> <pre><code>var ic_address = 'NOAA/DMSP-OLS/NIGHTTIME_LIGHTS';\nvar band = \"stable_lights\";\n</code></pre> <pre><code>// -------------------------------------------------------------\n//  Gather image collection \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Select \"stable lights\" band from image.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-06/#03-filter-by-time","title":"03 filter by time","text":"<p>Please filter the collection for images captured in the years 2013.</p> <pre><code>// -------------------------------------------------------------\n//  Filter image collection by calendar unit.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-06/#04-select-image-rename-band","title":"04 select image, rename band","text":"<pre><code>// -------------------------------------------------------------\n//  Select first image of collection. \n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  Rename band \"2013\".\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-06/#05-display-image-as-map-layer","title":"05 display image as Map layer","text":"<pre><code>// -------------------------------------------------------------\n//  Display image as Map layer.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-06/#06-make-mean-image-for-2003","title":"06 make mean image for 2003","text":"<p>Please recycle the steps above to make an image that represents the mean brightness of nighttime lights in the year 2003.  </p> <p>Why do you think we need to make a composite image here, rather than just selecting the first image in the filtered collection? </p> <pre><code>// -------------------------------------------------------------\n//  Filter collection for year 2003\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  Composite collection by mean \n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  Rename image band.\n// -------------------------------------------------------------\n\n\n\n// -----------------------------------------------------------------------\n//  Display image as layer on the map.\n// -----------------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-06/#07-make-mean-image-for-2013","title":"07 make mean image for 2013","text":"<p>Now try to chain the workflow, rather than saving each step as a separate variable.  </p> <pre><code>// -----------------------------------------------------------------------\n//  Chain the workflow to make the third band.\n// -----------------------------------------------------------------------\n\nvar select_by_time_3 = select_by_band.filter(\nee.Filter.calendarRange(1993, 1993, \"year\")\n)\n.mean()\n.rename([\"1993\"])\n;\n\n// print(\"Year 3\", select_by_time_3);\n\nMap.addLayer(select_by_time_3, viz, \"1993\", false);\n\n\n// -----------------------------------------------------------------------\n//  Construct a three band image from the three images.  \n// -----------------------------------------------------------------------\n\n\n\n// -----------------------------------------------------------------------\n//  Add RGB composite as a layer to the map.\n// -----------------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-06/#08-explore-the-rgb-image","title":"08 explore the RGB image","text":"<p>Please copy and paste this code to the end of your script. You will need to replace \u201cchange_image\u201d with the name of your three band image that represents nighttime lights in 2013, 2003, and 1993.  </p> <p>Then run your script, explore the five patterns, and click locations to make charts of data values.  What do the different visual patterns (Flame, Aurora, Holiday Lights, Red Giant, Political lines) show you about the temporal characteristics of spatial change?</p> <p>When you have finished exploring the image, please complete the [practice-06 checkup] link coming soon on Canvas  by Friday 10/25 @ 5pm .  </p> <pre><code>// -----------------------------------------------------------------------\n//  Widgets\n// -----------------------------------------------------------------------\n\n//  Please uncomment the line below and run the script. \n\ngeo.uiWidgets.p6(change_image);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-07/","title":"P7. Swipe map app","text":"<p>PRACTICE 7 </p>"},{"location":"problems/practice-07/#swipe-map-app","title":"swipe map app","text":""},{"location":"problems/practice-07/#goal","title":"goal","text":"<p>Please publish an app that guides a user to investigate land cover change in a study region based on the plan that you developed in the tutorial this week.  </p> <p>Your script should resemble the app below, but should be focused on your chosen study region. Ideally, you will be able to include the app in your portfolio of college work. </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-07/#requirements","title":"requirements","text":"<p>To receive full credit, your app should include: </p> <ol> <li>A swipe map with natural and false color images of your study region at two different times (each labeled with a date).    </li> <li>A side bar that contains:  <ol> <li>A catchy title that sparks interest.</li> <li>A subtitle that describes where and when. </li> <li>A link to a short narrative. </li> <li>A byline credit. </li> <li>A select widget that takes the user to at least five predefined places of interest (and allows the user to zoom out to full extent).   </li> <li>Two checkbox widgets that allow the user to change the visibility of the layers in each map.  </li> </ol> </li> <li>The short narrative linked to the map should describe:  <ol> <li>Where is your study region?</li> <li>Why did you choose this region?</li> <li>What are the dates of the two images?</li> <li>What places in your select widget show changes that reflect differences in the time of year that your two images were collected? </li> <li>What places in your select widget show longer-term changes in the place?  <ol> <li>Describe the change in land cover. </li> <li>Try to interpret what this change means.</li> </ol> </li> <li>What are your data sources?    </li> </ol> </li> </ol>"},{"location":"problems/practice-07/#delivery","title":"delivery","text":"<p>Please complete the script, publish the app, and deliver this work by 5pm on Friday 11/1. To deliver, please complete the check up on Canvas where you will find a form that allows you to submit links to both your script and your app. </p> <p>Please note: this assignment will be manually checked, therefore you will not have the opportunity to make corrections after you submit your links.  </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-08/","title":"P8. Swipe map app (2)","text":"<p>PRACTICE 8 </p>"},{"location":"problems/practice-08/#swipe-map-app-2","title":"swipe map app (2)","text":""},{"location":"problems/practice-08/#goal","title":"goal","text":"<p>Please publish an app that supports your EO article. From the snapshots that you made in lab this week, please select two images and make an app that allows the reader to investigate changes between these two snapshots. </p> <p>The layout for your app should resemble the one from Practice 07. It should also differ in the following ways:  </p> <ul> <li>use images from the Landsat collection (rather than NAIP),  </li> <li>make a false color image that uses a SWIR (sometime called mid-IR) band,</li> <li>in your narrative, include a spectral signature chart and explain why your choice of false color helps distinguish different types of landcover in your two images when compared to natural color. </li> </ul>"},{"location":"problems/practice-08/#resources","title":"resources","text":"<p>Here are some pages to help you with this problem:  </p> <ul> <li>natural and false color images </li> <li>chart spectral signatures from Landsat</li> <li>swipe map with side bar layout </li> </ul>"},{"location":"problems/practice-08/#requirements","title":"requirements","text":"<p>To receive full credit, your app should include: </p> <ol> <li>A swipe map with natural and false color images of your study region at two different times (each labeled with a date).    </li> <li>A side bar that contains:  <ol> <li>A catchy title that sparks interest. OK if this is same as EO article.</li> <li>A subtitle that describes where and when. </li> <li>A link to a short narrative. </li> <li>A byline credit. </li> <li>A select widget that zooms the reader to at least three predefined places of interest that show different land cover types (and allows the user to zoom out to full extent).   </li> <li>Two checkbox widgets that allow the user to change the visibility of the layers in each map.  </li> </ol> </li> <li>The short (200-500 words) narrative linked to the map should include:  <ol> <li>A link to the EO story your app supports.</li> <li>The dates of the two images that your app shows.</li> <li>A spectral signature chart that shows at least three land cover types. (The chart can be drawn from one image. Your goal is to explain how the false color works based on the bands in your false color image.)</li> <li>A clear description of the spectral bands that you used to create your false color composite:  <ul> <li>What band (part of spectrum) is displayed with Red color channel?</li> <li>What band (part of spectrum) is displayed with Green color channel?</li> <li>What band (part of spectrum) is displayed with Blue color channel?</li> </ul> </li> <li>A short explanation of the spectral signature chart:  <ul> <li>When compared to natural color, why does your choice of false color help distinguish the landcover types shown in your chart?  </li> </ul> </li> <li>Your data sources and references if applicable.      </li> </ol> </li> </ol>"},{"location":"problems/practice-08/#delivery","title":"delivery","text":"<p>Please complete the script, publish the app, and deliver this work by 5pm on Friday 11/8. To deliver, please complete the check up on Canvas (available by Thurs morning) where you will find a form that allows you to submit links to both your script and your app. </p> <p>Please note: this assignment will be manually checked, therefore you will not have the opportunity to make corrections to your script after you submit your links.  </p> <p>But please also note: you can continue to change the narrative that is linked to your app after Friday and I will not be able to tell. </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-09/","title":"P9. CZU burn severity","text":"<p>PRACTICE 09 </p>"},{"location":"problems/practice-09/#czu-lightning-complex-burn-severity","title":"CZU Lightning Complex Burn Severity","text":""},{"location":"problems/practice-09/#goal","title":"goal","text":"<p>This tutorial introduces a general workflow to map the burn severity of wildfire with Sentinel-2 MSI data.</p> <p>We will use the CZU Lightning Complex fires on California\u2019s Slow Coast as a case study. This practice problem complements a research article on CZU impacts to the old growth forests in Big Basin Redwoods State Park (Potter 2023).  </p> <p>Your script should reproduce the map layers shown in the app below.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-09/#deliverables","title":"deliverables","text":"<p>Please take the checkup on Canvas by 5pm Friday 11/15. This checkup will ask you to report checkpoint answers and will be automatically graded, so you will be able to retake the checkup as many times as you would like until 5pm on Monday 11/18. Your final score for the checkup will be your maximum score.   </p>"},{"location":"problems/practice-09/#workflow","title":"workflow","text":"<p>Please work through the steps outlined below.  </p>"},{"location":"problems/practice-09/#00-start-a-script","title":"00 Start a script","text":"<p>Start a new script with the code block below. I define an area of interest for you by buffering a point near Bonny Doon, California. For the checks to work, please use this aoi. </p> <pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:      \n    TITLE:    09 Practice - CZU burn severity\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \n\nvar geometry = ee.Geometry.Point([-122.2241722048408, 37.148316599201095]);\n\nvar aoi = geometry.buffer(20 * 1000);\n</code></pre>"},{"location":"problems/practice-09/#01-set-up-map","title":"01 Set up map","text":"<pre><code>// -------------------------------------------------------------\n//  1. SET UP MAP.\n// -------------------------------------------------------------\n\n// Center map on AOI at zoom 10.\n\n\n\n// Set base map to terrain.\n</code></pre>"},{"location":"problems/practice-09/#02-make-post-burn-image","title":"02 Make post-burn image","text":"<pre><code>// -------------------------------------------------------------\n//  2. MAKE POST-BURN IMAGE.\n// -------------------------------------------------------------\n</code></pre> <p>Please adapt the S2 starter script for this step. Your post-burn image should: </p> <ol> <li>Filter by aoi location.</li> <li>Filter for September 2020.  </li> <li>Filter for images with less that 20% cloud cover. </li> <li>Apply the scale and cloud mask methods for S2. </li> <li>Flatten to median image. </li> <li>Clip image by aoi (see pattern below). </li> <li>Display RGB as SWIR2, NIR, Red</li> <li>Stretch enhance the RGB composite.  </li> </ol> <p>To clip the image, please use this method : </p> <pre><code> var clipped_image = image.clip(aoi)\n</code></pre>"},{"location":"problems/practice-09/#03-make-pre-burn-image","title":"03 Make pre-burn image","text":"<pre><code>// -------------------------------------------------------------\n//  3. MAKE PRE-BURN IMAGE.\n// -------------------------------------------------------------\n</code></pre> <p>Your pre-burn image should replicate the criteria of Step 2 with one exception: you now want to filter for 2019. This image should show conditions in the same place and season for the year before the burn.  </p>"},{"location":"problems/practice-09/#04-map-post-burn-nbr","title":"04 Map post-burn NBR","text":"<pre><code>// -------------------------------------------------------------\n//  4. MAP NORMALIZED BURN RATIO FOR POST-BURN SNAPSHOT\n// -------------------------------------------------------------\n</code></pre> <p>For this step, you will need to: </p> <ol> <li>Load spectral indices module. </li> <li>Define parameters for Sentinel 2 Surface Reflectance. </li> <li>Compute NBR index. </li> <li>Isolate NBR band as a new single-band image. </li> <li>Display result as map layer using the viz parameters defined below.</li> </ol> <pre><code>var nbr_viz = {bands: [\"NBR\"], min:-1, max:1, palette: ['purple', 'white', 'green']};\n</code></pre>"},{"location":"problems/practice-09/#05-map-pre-burn-nbr","title":"05 Map pre-burn NBR","text":"<pre><code>// -------------------------------------------------------------\n//  5. MAP NORMALIZED BURN RATIO FOR PRE-BURN SNAPSHOT\n// -------------------------------------------------------------\n</code></pre> <p>You do not need to reload the spectral indices module, since you already did that above. You will need to do the other steps described above (2-5) using the pre-burn image as the input. </p>"},{"location":"problems/practice-09/#06-map-burn-severity","title":"06 Map burn severity","text":"<p>From the readings this week, you saw that burn severity is the change in NBR caused by a fire.    </p> <p> </p> <p>Please calculate and map the burn severity based on your two NBR images.</p> <pre><code>// ------------------------------------------------------------------------\n//  6. MAP BURN SEVERITY INDEX.\n// ------------------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-09/#07-reclassify-burn-severity","title":"07 Reclassify burn severity","text":"<p>Please use the thresholds shown below to reclassify the burn severity image.  </p> <p> </p> <pre><code>// ------------------------------------------------------------------------\n//  7. RECLASSIFY BURN SEVERITY BASED ON USGS THRESHOLDS. \n// ------------------------------------------------------------------------\n\n// Viz parameters for classified layer.\n\nvar burn_severity_viz = {\nmin: 0,\nmax: 6,\npalette: [\n'#778735', '#a7c04f', '#07e444', '#f6fc0d', '#f7b140', '#f86819', '#a601d4'\n]\n};\n</code></pre>"},{"location":"problems/practice-09/#08-add-legend","title":"08 Add legend","text":"<pre><code>// ------------------------------------------------------------------------\n//  8. ADD BURN SEVERITY CLASS LEGEND TO MAP. \n// ------------------------------------------------------------------------\n\nvar burn_severity_labels = [\n'High post-fire regrowth',\n'Low post-fire regrowth',\n'Unburned',\n'Low Severity',\n'Moderate-low Severity',\n'Moderate-high Severity',\n'High Severity'\n]\n;\n\n// Make legend from image with nominal data.\n\nvar legend_nominal = geo.iCart.legendNominal(\n\"Burn Severity Classes\", burn_severity_viz, burn_severity_labels, \"bottom-left\"\n)\n;\n\n// Add legend to Map.  \n\nMap.add(legend_nominal);\n</code></pre>"},{"location":"problems/practice-09/#09-make-ocean-mask","title":"09 Make ocean mask","text":"<pre><code>// ------------------------------------------------------------------------\n//  9. MAKE OCEAN MASK. \n// ------------------------------------------------------------------------\n</code></pre> <ol> <li>Gather an image from this cloud address: \u201cNASA/NASADEM_HGT/001\u201d.</li> <li>Select \u201celevation\u201d band.</li> <li>Make a boolean image where land is 1 and ocean is 0. </li> <li>Display mask as a Map layer.  </li> </ol>"},{"location":"problems/practice-09/#10-display-burn-severity-with-mask","title":"10 Display burn severity with mask","text":"<pre><code>// ------------------------------------------------------------------------\n//  10. DISPLAY BURN SEVERITY WITH OCEAN MASK. \n// ------------------------------------------------------------------------\n\n// Display the burn severity class image with the ocean mask with opacity of 0.6.\n// All other layers should not be displayed by default. \n</code></pre>"},{"location":"problems/practice-09/#checks","title":"CHECKS","text":"<pre><code>// ----------------------------------------------------------------------\n//  CHECKS\n//\n//  Please update the \"result_step#\" variable as needed for each step.  \n// ----------------------------------------------------------------------\n\nvar check = require('users/jhowarth/eePatterns:checks/p09.js');\n\ncheck.checkPoint(\"CHECK STEP 2:\", result_step2.select(\"B8\"));\ncheck.checkPoint(\"CHECK STEP 3:\", result_step3.select(\"B8\"));\ncheck.checkPoint(\"CHECK STEP 4:\", result_step4);\ncheck.checkPoint(\"CHECK STEP 5:\", result_step5);\ncheck.checkPoint(\"CHECK STEP 6:\", result_step6);\ncheck.checkPoint(\"CHECK STEP 7:\", result_step7);\ncheck.checkPoint(\"CHECK STEP 9:\", result_step9);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/practice-10/","title":"P10. Memories of urban environments","text":"<p>PRACTICE 10 </p>"},{"location":"problems/practice-10/#memories-of-urban-environments","title":"Memories of urban environments","text":""},{"location":"problems/practice-10/#goal","title":"goal","text":"<p>This problem aims to introduce methods for mapping differences between conditions of sub-regions from whole regions. The general framework will help you explore distributive environmental (in)justice in built environments and the central question: are the costs and benefits of the built environment distributed unevenly among groups or classes of society?  </p> <p>This problem also introduces:</p> <ul> <li> <p>a workflow to compute land surface temperature (LST) from Landsat collections using a module by Sofia Ermida;  </p> </li> <li> <p>a community module of color palettes to help display raster images, but generates a noticeable delay in the execution of any script that calls it; </p> </li> <li> <p>methods for changing aggregation levels of regions with attributes of feature collections.   </p> </li> </ul> <p>By the end of the tutorial, you should have a script that reproduces the layers shown in the app below. You should also be able to rerun your analysis for any city in the USA with HOLC maps simply by changing one variable of your script.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/practice-10/#context","title":"context","text":"<p>This case study concerns the environmental legacies of redlining that are embedded in many (most) American cities. Your practical goal is to run the analysis by Hoffman et al (2020) with more recent LST data and create visuals inspired by the work of Nadja Popovich and Brian Palmer in the second reading for this week.  </p> <p>For more background on redlining and the history of the Home Owners\u2019 Loan Corporation (HOLC), please review the resources at Mapping Inequality from the University of Richmond.</p>"},{"location":"problems/practice-10/#deliverables","title":"deliverables","text":"<p>Please complete the checkup on Canvas by 5pm on Friday 11/22. Because of the holiday next week, this will be a hard deadline. If your travel plans make this deadline impossible, please contact me for an extension before the deadline.  </p>"},{"location":"problems/practice-10/#workflow","title":"workflow","text":"<p>Please work through the steps of the workflow outlined below. Many steps draw on patterns introduced earlier in the course and I keep the scaffolding for these steps quite light. This aims to help you practice for the upcoming IP.  </p>"},{"location":"problems/practice-10/#00-start-a-script","title":"00 Start a script","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:       11/20/2024\n    TITLE:      practice-10.js\n\n    Investigate environmental legacies of HOLC with LST.\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// Module for EE community palettes. \n\nvar palettes = require('users/gena/packages:palettes');\n\nprint(\"Community palettes\", palettes);\n</code></pre>"},{"location":"problems/practice-10/#01-make-and-display-layer-1","title":"01 Make and display Layer 1","text":"<pre><code>// ------------------------------------------------------------------------\n//  1. Make and display Layer 1.\n// ------------------------------------------------------------------------\n\nvar holc_address = \"projects/ee-primer/assets/holc_numeric_grades\"\n</code></pre>"},{"location":"problems/practice-10/#02-make-and-display-layer-2","title":"02 Make and display Layer 2","text":"<pre><code>// ------------------------------------------------------------------------\n//  2. Make and display Layer 2.\n// ------------------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-10/#03-define-display-levels-of-aggregation","title":"03 Define &amp; display levels of aggregation","text":"<pre><code>// ---------------------------------------------------------------------\n//  3. Define levels of aggregation for HOLC data.\n// ---------------------------------------------------------------------\n\n// Define and display all holc zones of a city as a single, multipart feature. \n\n\n// Define each holc grade as a single, multipart features. \n\n\n// Print aggregation levels. \n</code></pre>"},{"location":"problems/practice-10/#04-create-lst-datasets-from-landsat","title":"04 Create LST datasets from Landsat","text":"<p>Here is a starter script to help get started with Sofia\u2019s module.  </p> <pre><code>// ------------------------------------------------------------------------\n//  4. Create LST datasets from Landsat.\n// ------------------------------------------------------------------------\n\n// Module to compute LST from Landsat.\n\nvar LandsatLST = require('users/sofiaermida/landsat_smw_lst:modules/Landsat_LST.js');\n\n// Define arguments for LST module. \n\nvar date_start = '2020-07-01';            // Filter by time start.\nvar date_end = '2024-09-01';              // Filter by time end.\nvar region = holc;                        // Filter by location.\nvar use_ndvi = true;                      // Use NDVI in computation (true or false).\n\n// Compute LST from L9 collection.  \n\n\n// Compute LST from L8 collection.  \n\n\n// Print to inspect your work!\n</code></pre>"},{"location":"problems/practice-10/#05-merge-image-collections","title":"05 Merge image collections","text":"<pre><code>// ------------------------------------------------------------------------\n//  5. Merge image collections.\n// ------------------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-10/#06-filter-merged-collection","title":"06 Filter merged collection","text":"<p>Filter the dataset for images collected in summer months (June and August) with cloud cover less that 10 percent. Also select only the \u2018LST\u2019 band from the images.</p> <pre><code>// ------------------------------------------------------------------------\n//  6. Filter merged collection.\n// ------------------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-10/#07-flatten-convert-rename-clip","title":"07 Flatten, convert, rename, clip","text":"<p>Please do the following:  </p> <ol> <li>calculate the average (mean) temperature of summer months collection (result of step 6) for each pixel; </li> <li>convert units of reduced image from Kelvin (units that result from LST module) to Fahrenheit;</li> <li>rename the band \u201cAVG_LST_F\u201d in the output image;</li> <li>clip to the holc_extent.</li> </ol> <p>To convert from K to F: </p> <ol> <li>Subtract 273.15 from Kelvin temperature</li> <li>Multiply by 1.8 </li> <li>Add 32</li> </ol> <pre><code>// ------------------------------------------------------------------------\n//  7. Flatten, convert, rename, clip.\n// ------------------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-10/#08-display-layer-5","title":"08 Display Layer 5","text":"<p>I include a viz dictionary below to help you use the community palettes module. For more help on this, please refer to the module\u2019s docs.   </p> <pre><code>// ------------------------------------------------------------------------\n//  8. Display as Layer 5.\n// ------------------------------------------------------------------------\n\nvar output_viz = {\nbands: [\"AVG_LST_F\"],\nmin: 85,\nmax: 115,\npalette: palettes.colorbrewer.YlOrRd[9]\n};\n</code></pre>"},{"location":"problems/practice-10/#09-make-and-display-layer-6","title":"09 Make and display Layer 6","text":"<pre><code>// ------------------------------------------------------------------------\n//  9. Make and display Layer 6.\n// ------------------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-10/#10-compute-difference","title":"10 Compute difference","text":"<pre><code>// ------------------------------------------------------------------------\n//  10. Compute difference: mean of parts - mean of whole.\n// ------------------------------------------------------------------------\n\n//  Use zonal statistics to calculate mean lst in each aggregation level. \n\n\n//  Convert each of above to image.\n\n\n\n//  Compute difference: mean_parts - mean_whole \n</code></pre>"},{"location":"problems/practice-10/#11-display-layer-7","title":"11 Display Layer 7","text":"<pre><code>// ------------------------------------------------------------------------\n//  11. Display Layer 7.\n// ------------------------------------------------------------------------\n</code></pre>"},{"location":"problems/practice-10/#12-chart-difference","title":"12 Chart difference","text":"<pre><code>// ---------------------------------------------------------------------\n//  12. Chart difference for each part. \n// ---------------------------------------------------------------------\n\n// Define chart arguments. \n\nvar chart_arguments = {\ndata_image: difference,                           // Image used for Layer 7.\nclass_image: image_nominal,                       // Image used for Layer 2.\naoi: aoi_dissolve_whole,                          // Feature collection for Layer 3. \nreducer: ee.Reducer.mean(),\nscale: 30,\nclass_labels: geo.iPalettes.iHOLC.labels,\ntitle: 'Difference of grade from average LST',\npalette: geo.iPalettes.iHOLC.palette,\nha_label: \"degrees (F)\"\n\n\n};\n\nvar myChart = geo.uiChart.makeBarChartByClass(chart_arguments);\n\nMap.add(myChart);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/troubleshooting/","title":"TS. Troubleshooting errors","text":"<p>PROBLEMS </p>"},{"location":"problems/troubleshooting/#troubleshooting-errors","title":"Troubleshooting errors","text":"<p>This activity aims to help you practice troubleshooting your scripts in Earth Engine. Each script below contains several errors. Your task is to fix the errors and articulate a rule of thumb for handing each type of error in your workflows.</p> <p>Please do the following: </p> <ol> <li>Make a \u201ctroubleshooting\u201d folder in your Earth Engine repository. </li> <li>Start a new script for each of the workflows below. </li> <li>Fix the errors and document how you fixed the errors in this worksheet. </li> </ol> <p>Please note, you will receive a copy of this worksheet in lab. </p> <p>At the end of lab, please fill out this form where you will submit links to your scripts. Please ask an instructor if you need help getting links to your scripts.</p> <p>Thank you.</p>"},{"location":"problems/troubleshooting/#practice-01","title":"practice 01","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     Oct 14, 2024\n    TITLE:    Troubleshooting Practice 1\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\n\n\n// -------------------------------------------------------------\n//  Access image from this cloud address:\n//  \"projects/ee-patterns/assets/p01/chipmanHill_2023_35cm_DEMHF\"\n// -------------------------------------------------------------\n\nvar image = ee.ImageCollection(\"projects/ee-patterns/assets/p01/chipmanHill_2023_35cm_DEMHF\");\n\nprint(\"FIRST IMAGE\", image);\n\n// -------------------------------------------------------------\n//  Customize Map. \n// -------------------------------------------------------------\n\n// Set map center and zoom level.\n\nMap.centerObject(image, 15);\n\n//  Set basemap style to hybrid.\n\nMap.setOptions('HYBRID');\n\n// -------------------------------------------------------------\n//  Display image as a map layer;\n//  Stretch layer display values over image data range.\n// -------------------------------------------------------------\n\n// Print min and max values of image. \n\nprint(\"Min &amp; max value of image\", geo.iCart.iMinMax(image));\n\n// Chart histogram of actual data values.\n\nprint(\"Image histogram\", geo.iCart.iHistogram(image));\n\n// Define viz dictionary. \n\nvar single_viz = {\nmin: [86],        max: [246],        }\n;\n\n// Add map layer. \n\nMap.addLayer(image,single_viz,\"Digital Elevation Model (meters)\");\n\n\nvar i_min_max = geo.iCart.iMinMax(image);\n\nprint(\"Min &amp; max value of image\", i_min_max);\n\nMap.addLayer(image, {min: 96, max: 247}, \"Image displayed by min and max\", false);\n\n// -------------------------------------------------------------\n//  Calculate the PERCENT slope of each location in image. \n// -------------------------------------------------------------\n\nvar image_slope = ee.Terrain.slope(image);\n\nvar image_slope_percent = image_slope.divide(180).multiply(Math.PI).tan().multiply(100);\n\n// -------------------------------------------------------------\n//  Display slope image as a map layer;\n//  Stretch layer display values over image data range.\n// -------------------------------------------------------------\n\nprint(\"slope min max\", geo.iCart.iMinMax(image_slope_percent));\n\nvar output_histogram = geo.iCart.iHistogram(image_slope_percent);\n\nprint(\"slope histogram\", output_histogram);\n\nMap.addLayer(image_slope_percent, {min:0, max: 87}, \"Image slope - steeper is darker\");\n\n// -------------------------------------------------------------\n//  Calculate the hillshade of each location in image. \n// -------------------------------------------------------------\n\nvar image_hs = ee.Terrain.hillshade(image.multiply(2), 45, 315);\n\nprint(\"hs min max\", geo.iCart.iMinMax(image_hs));\n\nvar output_histogram = geo.iCart.iHistogram(image_hs);\n\nprint(\"hs histogram\", output_histogram);\n\nMap.addLayer(image_hs, {}, \"Image hillshade\");\n\n// -------------------------------------------------------------\n//  Calculate the deviation from mean elevation;\n//  Use 10 as the distance argument.\n//  Try to display the layer with this palette: ['blue', 'white', 'red']\n// -------------------------------------------------------------\n\nvar image_dme = geo.iTerrain.devFromMeanElev(image, 10);\n\nprint(\"dme min max\", geo.iCart.iMinMax(image_dme, 3));  var output_histogram = geo.iCart.iHistogram(image_dme);\n\nprint(\"dme histogram\", output_histogram);\n\nMap.addLayer(image_dme, {min: -1, max:1, palette: ['blue', 'white', 'red']}, \"Image DME\");\n</code></pre>"},{"location":"problems/troubleshooting/#practice-02","title":"practice 02","text":"<pre><code> /*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     Oct 14, 2024\n    TITLE:    Troubleshooting Practice 02\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.\nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// -------------------------------------------------------------------------------\n//  Gather image from \"projects/ee-patterns/assets/p02/NOAA-CoNED-SOCAL\".\n//  Print a histogram - do you see land vs ocean floor in the histogram?\n// -------------------------------------------------------------------------------\n\n// var bathy = ee.Image(\"projects/sat-io/open-datasets/gebco/gebco_grid/gebco_2023_n900_s00_w-1800_e-900\");\n\nvar image = ee.Image(\"projects/ee-patterns/assets/p02/NOAA-CoNED-SOCAL\");\n\nprint(\"Image\", image);\n\n// Chart histogram of data values.\n\nprint(\"Image histogram\", geo.iCart.iHistogram(image, 30));\n\n// -------------------------------------------------------------------------------\n//  Area of interest for practice problem.\n// -------------------------------------------------------------------------------\n\nvar aoi = image;\n\n\n// Center map on aoi at zoom level 9 and set base layer to hybrid.\n\nMap.centerObject(aoi, 9);\nMap.setOptions('hybrid');\n\n\n// -------------------------------------------------------------------------------\n//  Apply a vertical exageration (z-factor) of 2 to elevation data for hillshade. \n//  Make a hillshade from this image and display the hillshade image as layer on Map.\n// -------------------------------------------------------------------------------\n\nvar image_ve = image.multiply(2);\n\nvar image_hs = ee.Terrain.hillshade(imagee_ve, 315, 35);\n\nMap.addLayer(image_hs, {min:255, max:0}, \"Hillshade\");\n\n// -------------------------------------------------------------------------------\n//  Separate the original elevation image (without vertical exageration) into two different images:\n\n//  (1) land elevations\n//  (2) ocean floor elevations (bathymetry)\n\n//  Each image should only store land or bathymetry elevation values, respectively.\n//  All other values should be masked.\n// -------------------------------------------------------------------------------\n\nvar image_land = image.selfMask(image.gt(0));\n\nprint(\"image land\", image_land);\n\nvar image_bathy = image.updateMask(image.lte(0)) ;\n\n// -------------------------------------------------------------------------------\n//  Reclassify the bathymetry image at equal 100 meter intervals. \n//  Display the reclassified image as layer on Map with 0.5 opacity.\n//  To improve contrast, set max of viz dictionary such that all locations less than -2000 m (or class 20) are the darkest blue in palette.\n//  Use this palette: geo.iPalettes.iBathy.eleven\n// -------------------------------------------------------------------------------\n\n// Equal intervals\n\nvar image_bathy_reclass = geo.iReclass.equalInterval(aoi, -100);\n\n// Print min and max values of image. \n\nprint(\"Min &amp; max value of bathy reclass\", geo.iCart.iMinMax(image_bathy_reclass, 30, aoi));\n\n// Chart histogram of actual data values.\n\nprint(\"Bathy histogram\", geo.iCart.iHistogram(image_bathy_reclass, 30, aoi));\n\n// // Define viz dictionary. \n\nvar viz_bathy = {\nmax: [20],        min: [0], palette: geo.iPalettes.iBathy.eleven\n}\n;\n\n// Add map layer. \n\nMap.addLayer(image_bathy_reclass,viz_bathy,\"Bathymetry\", 1, 0.5);\n\n// -------------------------------------------------------------------------------\n//  Define the Pleistocene shoreline as 130 meters lower than today's shoreline.\n//  Make a boolean image that shows all land above ocean in Pleistocene.\n//  Display boolean image as layer on Map with all non-land masked.\n// -------------------------------------------------------------------------------\n\nvar image_pleistocene = image_bathy.add(130);\n\nvar image_pleistocene_boolean = image_pleistocene.gt(0);\n\nvar image_pleistocene_boolean_simple = image_bathy.gte(-130).updateMask();\n\nMap.addLayer(image_pleistocene_boolean.selfMask(), {min:0, max:1, palette: \"#ffffff\"}, \"Pleistocene Land\", 1, 0.5);\n\n// -------------------------------------------------------------------------------\n//  Reclassify the land image at equal 100 meter intervals. \n//  Display the reclassified image as layer on Map with 0.5 opacity.\n//  Use this palette: geo.iPalettes.iHypso.bartholomew\n// -------------------------------------------------------------------------------\n\nvar image_land_reclass = geo.iReclass.equalInterval(image_land, 100);\n\nprint(\"image land reclass\", image_land_reclass);\n\n// Print min and max values of image. \n\nprint(\"Min &amp; max value of land_image_reclass\", geo.iCart.iMinMax(image_land_reclass, 30, aoi));\n\nvar viz_land = {\nmin: [0],        max: [30], palette: geo.iPalettes.iHypso.bartholome\n}\n;\n\nMap.addLayer(image_land_reclass,viz_land,\"Image land\", 1, 0.5);\n</code></pre>"},{"location":"problems/troubleshooting/#practice-03","title":"practice 03","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     October 14, 2024\n    TITLE:    Troubleshooting Practice 03\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n\n// -------------------------------------------------------------\n//  DATA SOURCES \n// ------------------------------------------------------------- \n\nvar fc_address_county = \"TIGER/2018/Counties\";\nvar fc_address_town = \"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\";\nvar fc_address_parcel = \"projects/vt-conservation/assets/state/FS_VCGI_OPENDATA_Cadastral_VTPARCELS_poly_standardized_parcels_SP_v1\";\nvar fc_address_soils = \"projects/conservation-atlas/assets/soils/VT_Data_NRCS_Soil_Survey_Units\";\nvar ic_address_dem = \"USGS/3DEP/1m\"; var palette_soils = geo.iPalettes.iSoils.parent_materials_addison_county;\nvar class_labels_soils = geo.iPalettes.iSoils.parent_materials_addison_county_labels;\n\nprint(\"SOILS Palette and Class labels\", palette_soils, class_labels_soils);\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. GATHER HUMAN GEOGRAPHY\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Make Addison County layer\n// -------------------------------------------------------------\n\nvar fc_county = ee.FeatureCollection(fc_address_county)\n.filter(ee.Filter.eq(\"NAME\", \"ADDISON\"))\n;\n\nprint(\n\"COUNTY first row\",\nfc_county.first()\n);\n\n\nMap.addLayer(fc_county, {color: 'yellow'}, \"1.1: Addison County\", false);\n\nvar result_1p1 = fc_county; // -------------------------------------------------------------\n//  1.2 Make study town (Middlebury) layer\n// -------------------------------------------------------------\n\nvar town_name = \"Middlebury\";\n\nvar fc_town = ee.FeatureCollection(fc_address_town)\n.filter(ee.Filter.eq(\"TOWNNAME\",  town_name.toUpperCase()))\n;\n\nMap.addLayer(fc_town, {color: 'green'}, \"1.2: Study town: \".concat(town_name), false);\n\nvar result_1p2 = fc_town; // -------------------------------------------------------------\n//  1.3 Center map on study town\n// -------------------------------------------------------------\n\nMap.centerObject(fc_town, 13);\nMap.setOptions('hybrid');\n\n// -------------------------------------------------------------\n//  1.4 Make parcels in study town layer\n// -------------------------------------------------------------\n\nvar fc_parcels = ee.FeatureCollection(fc_address_parcel);\n\nprint(\n\"PARCEL first row\",\nfc_parcels.first()\n);\n\n\n// Filter by attribute  \n\nvar fc_filtered_parcels = fc_parcels.filter(\nee.Filter.eq('TOWN', town_name.toUpperCase()))\n;\n\n// Check filtered result.  \n\nprint(\n\"Parcels Townname\",\nfc_parcels.size(),\nfc_filtered_parcels.size()\n);\n\n// Add filtered data to map.  \n\nMap.addLayer(fc_filtered_parcels, {color: 'cyan'}, \"1.4: Parcels in Study Town\", false);\n\nvar result_1p4 = fc_filtered_parcels;\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. GATHER SOILS DATA AND FILTER FOR ADDISON COUNTY \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  2.1 Gather soils data\n// -------------------------------------------------------------\n\n// Gather fc data from address.\n\nvar fc_soils = ee.FeatureCollection(fc_address_soils);\n\n// Inspect the table.  \n\n// print(\n//   \"SOILS\",\n//   \"number of rows\",\n//   fc_soils.size(),\n//   \"names of columns\",\n//   fc_soils.first().propertyNames(),\n//   \"first row of table\",\n//   fc_soils.first(),\n//   \"unique values for target column\",\n//   fc_soils.aggregate_array('PARENT').distinct().sort()\n// );\n\n// Display as map layer. \n\nMap.addLayer(fc_soils, {color: 'white'}, \"2.1: Vermont Soils\", false);\n\nvar result_2p1 = fc_soils;\n\n// -------------------------------------------------------------\n//  2.2 Filter for soils that overlap Addison County\n// -------------------------------------------------------------\n\n// Filter feature collection by bounds of another vector dataset. \n\nvar fc_filter_bounds_soils = fc_soils.filter(\nee.Filter.bounds(fc_county)\n);\n\n// Check filtered result.  \n\n// print(\n//   \"FC SIZE BEFORE VS AFTER FILTER\",\n//   fc_soils.size(),\n//   fc_filter_bounds_soils.size()\n// );\n\n// Add filtered data to map.\n\nMap.addLayer(fc_filter_bounds_soils, {color: 'magenta'}, \"2.2 Soils that overlap Addison County\", false);  var result_2p2 = fc_filter_bounds_soils; // -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  3. MAKE PARENT MATERIAL IMAGE FOR STUDY TOWN. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  3.1 Make nominal image of soil parent material. \n// -------------------------------------------------------------\n\nvar image_nominal_soils = geo.fcConvert.toNumericImage(fc_filter_bounds_soils, \"PARENT\")\n;\n\n// -------------------------------------------------------------\n//  3.2 Mask by Addison County.\n// -------------------------------------------------------------\n\nvar image_boolean_county = geo.fcConvert.toBooleanImage(fc_county);\n\nvar image_with_mask_soils = image_nominal_soils.updateMask(fc_county);\n\n// -------------------------------------------------------------\n//  3.3 Display masked soils image as layer. \n// -------------------------------------------------------------\n\nvar viz_soils = {\n\nmin: 0,\nmax: 10,\npalette: palette_soils\n\n};\n\nMap.addLayer(image_with_mask_soils, viz_soils, \"3.3 Parent Materials of Addison County\");\n\nvar result_3p3 = image_with_mask_soils;\n\n// -------------------------------------------------------------\n//  3.4 Add legend to botom-left of Map. \n// -------------------------------------------------------------\n\nvar legend_nominal_soils = geo.iCart.legendNominal(\n\"PARENT MATERIAL\", viz_soils, class_labels_soils, \"bottom-left\"\n)\n;\n\n// Add legend to Map.  \n\nMap.add(legend_nominal_soils);\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  4. GATHER DEM \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  4.1 Construct image collection. \n// -------------------------------------------------------------\n\nvar ic_dem = ee.ImageCollection(ic_address_dem);\n\n// print(\n//   \"IC DEM\", \n//   ic_dem.size(),\n//   ic_dem.first() \n// );\n\n// -------------------------------------------------------------\n//  4.2 Filter for images that overlap Addison County.\n// -------------------------------------------------------------\n\nvar ic_filtered_dem_county = ic_dem.filter(ee.Filter.bounds(image_boolean_county));\n\n// print(\"IC DEM Addison\", ic_filtered_dem_county.first(), ic_filtered_dem_county.size());\n\n// -------------------------------------------------------------\n//  4.3 Mosaic filtered image collection to image. \n// -------------------------------------------------------------\n\nvar ic_dem_mosaic = geo.icFlatten.mosaicToImage(ic_filtered_dem_county);\n\n// print(\"Mosaic\", ic_dem_mosaic);\n\n// -------------------------------------------------------------\n//  4.4 Mask mosaic image by Addison County. \n// -------------------------------------------------------------\n\nvar image_with_mask_dem = ic_dem_mosaic.updateMask(image_boolean_county);\n\n// -------------------------------------------------------------\n//  4.5 Make hillshade from masked image and display as layer with 0.5 opacity.\n// -------------------------------------------------------------\n\nvar hs = ee.Terrain.hillshade(image_with_mask_dem, 315, 35);\n\nMap.addLayer(hs, {min:0, max: 255}, \"4.5 Hillshade\", true, 0.5);\n\nvar result_4p5 = hs;\n\n// -------------------------------------------------------------\n//  4.6 Make hillshade from masked image and display as layer with 0.5 opacity.\n// -------------------------------------------------------------\n\nvar slope = ee.Terrain.slope(image_with_mask_dem);\n\nMap.addLayer(slope, {min:45, max:0}, \"4.6 Slope\", false, 0.5);\n\nvar result_4p6 = slope;\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  5. PAINT STROKES\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  5.1 Make strokes for parcels (\"white\" and 0.5 weight) and add as layer.\n// -------------------------------------------------------------\n\nvar strokes_parcels = geo.fcCart.paintStrokes(fc_filtered_parcels, \"white\", 0.5);\n\nMap.addLayer(strokes_parcels, {}, \"5.1 Parcel Outlines\");\n\n// -------------------------------------------------------------\n//  5.2 Make strokes for town (\"white\" and 4 weight) and add as layer.\n// -------------------------------------------------------------\n\nvar strokes_town = geo.fcCart.paintStrokes(fc_town, \"white\", 4);\n\nMap.addLayer(strokes_town, {}, \"5.2 Town Outlines\");\n</code></pre>"},{"location":"problems/troubleshooting/#practice-4","title":"practice 4","text":"<pre><code>/*     \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:   10/2/2024       \n    TITLE:  Troubleshooting Practice 4   \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// Feature collections\n\nvar vt_town_address = \"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\";\nvar rare_address = \"projects/conservation-atlas/assets/rarity/Significant_Natural_Communities\";\nvar large_blocks_middlebury = \"projects/ee-patterns/assets/vt-conservation/t04_habitat_blocks\";\n\n// Images\n\nvar valley_bottom_address = \"projects/vt-conservation/assets/champlain_basin/LakeChamplainBasin\";\nvar imp_address = \"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Impervious\";\n\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. Define study region.\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Define study town (Middlebury)\n// -------------------------------------------------------------\n\nvar town = ee.FeatureCollection(vt_town_address);\n\nvar study_town = town\n.filter(ee.Filter.eq(\"TOWNNAME\", \"MIDDLEBURY\"));\n\nMap.addLayer(study_town, {color: \"black\"}, \"1.1 Study Town\", false);\n\n// print(study_town, study_town.first().getNumber(\"SHAPE_area\").divide(4046.86));\n\nvar result_1p1 = study_town;\n\n// -------------------------------------------------------------\n//  1.2 Convert study town into boolean (to use as mask later)\n// -------------------------------------------------------------\n\nvar town_mask = geo.fcConvert.toBooleanImage(study_town);\n\nMap.addLayer(town_mask, {min:0, max:1}, \"1.2 town mask\", false);\n\n// -------------------------------------------------------------\n//  1.3 Define aoi as study town and towns that overlap (share boundary) with study town.\n// -------------------------------------------------------------\n\nvar aoi = town.filterBounds(study_town);\n\nMap.addLayer(aoi, {color: \"white\"}, \"1.3 Area of interest (aoi)\", false);\n\n\nvar result_1p3 = aoi;\n\n// -------------------------------------------------------------\n//  1.4 Convert aoi into a boolean (to use as mask later).\n// -------------------------------------------------------------\n\nvar aoi_mask = geo.fcConvert.toBooleanImage(aoi);\n\nMap.addLayer(aoi_mask, {min:0, max:1}, \"1.4 aoi mask\", false);\n\n// -------------------------------------------------------------\n//  1.5 Center map on study town and set basemap to hybrid. \n// -------------------------------------------------------------\n\nMap.centerObject(study_town, 12);\nMap.setOptions('hybrid');\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. Make blocks inclusive of rare communities.  \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  2.1 Gather habitat blocks cloud asset that overlap aoi. \n// -------------------------------------------------------------\n\nvar blocks_asset = ee.FeatureCollection(large_blocks_middlebury)\n.filterBounds(aoi)\n;\n\nMap.addLayer(blocks_asset, {color: 'GreenYellow'}, \"2.1 Blocks overlap aoi\", false);\n\nvar result_2p1 = blocks_asset;\n\n// -------------------------------------------------------------\n//  2.2 Convert 2.1 to a boolean image.\n// -------------------------------------------------------------\n\nvar image_boolean_blocks = geo.fcConvert.toBooleanImage(blocks_asset)\n.updateMask(aoi_mask)\n;\n\n// var classes_areas = geo.iZonal.areaClasses(image_boolean_blocks.unmask(), 5, study_town, \"max\");\n\n// print(\n//     \"Area (square meters) blocks\",\n//     classes_areas\n// );\n\n// var class_percent_of_region = geo.iZonal.classPercentRegion(classes_areas);\n\n// print(\n//   \"Area (percent of region)\",\n//   class_percent_of_region\n//   )\n// ;\n\nprint(\"image_boolean_blocks\", image_boolean_blocks);\n\nMap.addLayer(image_boolean_blocks, {min:0, max:1}, \"2.2 Blocks boolean\", false);\n\n// -------------------------------------------------------------\n//  2.3 Gather rare natural communities that overlap aoi.\n// -------------------------------------------------------------\n\nvar rare_nc = ee.FeatureCollection(rare_address)\n.filterBounds(aoi)\n;\n\nMap.addLayer(rare_nc, {color:'cyan'}, \"2.3 Rare Natural Communities overlap aoi\", false);\n\nvar result_2p3 = rare_nc;\n\n// -------------------------------------------------------------\n//  2.4 Make boolean image of rare natural communities that overlap aoi.\n// -------------------------------------------------------------\n\nvar image_boolean_rare = geo.fcConvert.toBooleanImage(rare_nc)\n.updateMask(aoi_mask)\n;\n\nMap.addLayer(image_boolean_rare, {min:0, max:1}, \"2.4 Image rare\", false);\n\n// -------------------------------------------------------------\n//  2.5 Find locations that are either blocks or rare natural communities.\n// -------------------------------------------------------------\n\nvar blocks_or_rare = image_boolean_blocks.or(image_boolean_rare);\n\nMap.addLayer(blocks_or_rare, {color: \"Yellow\"}, \"2.5 Blocks or Rare\", false);\n\nvar classes_areas = geo.iZonal.areaClasses(blocks_or_rare, 5, study_town, \"max\");\n\n// print(\n//     \"Area (square meters) + rarity\",\n//     classes_areas\n// );\n\n// var class_percent_of_region = geo.iZonal.classPercentRegion(classes_areas);\n\n// print(\n//   \"Area (percent of region)\",\n//   class_percent_of_region\n//   )\n// ;\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  3. Classify habitat blocks versus habitat connectors.  \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  3.1 Gather valley bottom, make it boolean (anything not 0 is true), and mask for aoi.\n// -------------------------------------------------------------\n\nvar valley_bottoms = ee.Image(valley_bottom_address)\n// .neq(0)\n.updateMask(aoi_mask)\n;\n\nvar output_min_max = geo.iCart.iMinMax(valley_bottoms, 10, study_town);\n\nprint(\"Min &amp; max value of valley bottom image\", output_min_max);\n\nMap.addLayer(valley_bottoms, {min:0, max:1}, \"3.1 Valley bottoms\", false, 1);\n\n// -------------------------------------------------------------\n//  3.2 Erase all impervious land from valley bottoms.\n// -------------------------------------------------------------\n\nvar imp = ee.Image(imp_address)\n.unmask()\n.updateMask(aoi_mask)\n;\n\nvar valley_bottoms_not_impervious = valley_bottoms.multiply(imp.eq(0));\n\n// print(valley_bottoms_not_impervious);\n\nvar output_min_max = geo.iCart.iMinMax(valley_bottoms_not_impervious, 10, study_town);\n\nprint(\"Min &amp; max value of image\", output_min_max);\n\n\nMap.addLayer(valley_bottoms_not_impervious, {min:0, max:1}, \"3.2 Valley bottoms without Impervious\", false);\n\n// -------------------------------------------------------------\n//  3.3 Distinguish valley bottoms without impervious that do not intersect habitat blocks as a new habitat class.\n//  Your goal here is to make a single layer where the value 1 represents habitat blocks and 2 represents corridors. \n// -------------------------------------------------------------\n\n//  Note to TAs: there are a lot of different ways to solve this step, so do not feel like you need to force\n//  students to use my solution. There are alternatives. \n\n// One way\n\nvar habitat_classes = blocks_or_rare\n.eq(0)\n.multiply(valley_bottoms_not_impervious)\n.multiply(2)\n.add(blocks_or_rare)\n;\n\n// Another way\n\n// var habitat_classes = blocks_or_rare\n//   .eq(0)\n//   .multiply(valley_bottoms_not_impervious)\n//   .remap(\n//     [0,1],\n//     [0,2])\n//   .add(blocks_or_rare)\n//   ;\n\n\nprint(\"habitat classes\", habitat_classes);\n\nMap.addLayer(habitat_classes.selfMask(), {min:0, max:2, palette: [\"black\", \"#9370DB\", \"#DBD570\"]}, \"3.3b Habitat blocks and connectors\", false);\n\n// -------------------------------------------------------------\n//  3.4 Export image to asset and display as map layer.  \n// -------------------------------------------------------------\n\n//  I started getting some \"tile\" errors here that tells me EE is getting sweating the task. \n//  So that is why I exported the result from 3.3 as an asset and continued working with it. \n\n// geo.iExport.toCloudAsset(\n//   habitat_classes, \n//   \"p04_habitat_blocks_and_connectors\",\n//   aoi, \n//   \"mode\"\n// );\n\nvar image_asset = ee.Image(\"projects/ee-patterns/assets/vt-conservation/p04_habitat_blocks_and_connectors\");\n\n\nvar viz_habitat = {\nmin:1,\nmax:2, palette: [\"#9370DB\", \"#DBD570\"]\n};\n\nMap.addLayer(image_asset.selfMask(), viz_habitat, \"3.3 Habitat blocks and connectors\", true);\n\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  4. A little cartography \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  4.1 Add a legend.  \n// -------------------------------------------------------------\n\n// Make legend from image with nominal data.\n\nvar legend_nominal = geo.iCart.legendNominal(\n\"Act 171 Habitat Elements\", viz_habitat, [\"Blocks\", \"Connectors\"], \"position-on-map\"\n)\n;\n\n// Add legend to Map.  \n\nMap.add(legend_nominal);\n\n// -------------------------------------------------------------\n//  4.2 Add outlines of study town.  \n// -------------------------------------------------------------\n\nvar strokes = geo.fcCart.paintStrokes(study_town, \"white\", 4);\n\nMap.addLayer(strokes, {}, \"Study town outlines\");\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n//  PRACTICE CHECKS\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n\n// Please calculate percent area based on your result from 3.4.\n// When calculating area, please use 5 for scale and study_town (Middlebury) for extent.\n// The last two checks in Canvas will ask you to report area for habitat blocks and habitat connectors separately. \n\nvar habitat_classes_areas = geo.iZonal.areaClasses(habitat_classes, 5, study_town, \"max\");\nvar class_percent_of_region = geo.iZonal.classPercentRegion(habitat_classes_areas);\n\nprint(\n\"Check 3.4: Area (percent of region) habitat\",\nclass_percent_of_region\n)\n;\n</code></pre>"},{"location":"problems/tutorial-01/","title":"T1. A sketch map from lidar","text":"<p>TUTORIAL 1</p>"},{"location":"problems/tutorial-01/#a-sketch-map-from-lidar","title":"A sketch map from lidar","text":""},{"location":"problems/tutorial-01/#goal","title":"goal","text":"<p>In this tutorial, our practical goal is to import a digital surface model (DSM) from this address:</p> <pre><code>\"projects/ee-patterns/assets/t01/Elevation_DSM0p7m2017_cm\"\n</code></pre> <p>and make a map with the layers shown below.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-01/#starter-script","title":"starter script","text":"<pre><code>// -------------------------------------------------------------\n//  Construct image data object from address.\n// -------------------------------------------------------------\n\nvar image ;\n\n// -------------------------------------------------------------\n//  Print properties of image to the Console. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Set map center and zoom level.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Set basemap style.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Display image as a map layer.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Import geoMethods module. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  Set viz range to data range.\n// -------------------------------------------------------------\n\nvar image_min_max ;\n\n\n\n// -------------------------------------------------------------\n//  Chart histogram of image data values.\n// -------------------------------------------------------------\n\nvar image_histogram ;\n\n\n// -------------------------------------------------------------\n//  Apply scalar operation; \n//  convert image data from centimeters to meters.\n// -------------------------------------------------------------\n\nvar image_meters ;\n\n// -------------------------------------------------------------\n//  Display new image as a layer\n//  with viz range set to data range.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  Derive slope of the surface image. \n// -------------------------------------------------------------\n\nvar image_slope ;\n\n// -------------------------------------------------------------\n//  Display slope image as map layer so that \"steeper is darker\".\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  TUTORIAL CHECKS\n// -------------------------------------------------------------\n\n//  I. QUANTITATIVE \n\n//  Import check module for tutorial 1.\n\nvar check = require(\"users/jhowarth/eePatterns:checks/t01.js\");\n\n//  Uncomment the four lines below, run script, and look at the results in Console. \n\n// print(\"QUANTITATIVE CHECKS:\");\n// check.checkPoint(\"CP1:\", image);\n// check.checkPoint(\"CP2:\", image_meters);\n// check.checkPoint(\"CP3:\", image_slope);\n\n//  II. QUALITATIVE  \n\n//  Use zoom to inspect locations marked A, B, C, D.\n//  For each letter, please write down:\n\n//    1. What do you think the location \"is\"?\n//    2. How does the location represent environmental change?\n\n//  We will discuss in next lecture. \n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-02/","title":"T2. A slippy topographic map","text":"<p>TUTORIAL 2</p>"},{"location":"problems/tutorial-02/#a-slippy-topographic-map","title":"A slippy topographic map","text":""},{"location":"problems/tutorial-02/#goal","title":"goal","text":"<p>In this tutorial, our practical goal is to import a digital elevation model (DEM) from this address:</p> <pre><code>'USGS/3DEP/10m'\n</code></pre> <p>and make a map with the layers shown below.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-02/#starter-script","title":"starter script","text":"<pre><code>// Require geo module. \n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\"); print(\"geo dictionary\", geo.help);      // Prints dictionary of all tools in module.\nprint(\"geo palettes\", geo.iPalettes);   // Prints dictionary of all palettes in module. \n\n// -------------------------------------------------------------------------------\n//  Area of interest for tutorial.\n// -------------------------------------------------------------------------------\n\nvar aoi = geo.aoi.t2;\n\nprint(\"Area of interest\", aoi);\n\n// -------------------------------------------------------------------------------\n//  MAP\n//\n//  Center map on aoi at zoom level 10. \n//  Set basemap to hybrid.\n// -------------------------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------------------------\n//  DEM\n//\n//  Gather raster from this address: 'USGS/3DEP/10m'\n//  Display the image with stretch enhancement. \n//  Do not show the image by default. \n// -------------------------------------------------------------------------------\n\nvar image ;\n\n// -------------------------------------------------------------------------------\n//  SLOPE\n//\n//  Derive slope of a surface in degrees from elevation in meters from DEM.\n//  Display the image with stretch enhancement. \n// -------------------------------------------------------------------------------\n\nvar image_slope ;\n\n\n// -------------------------------------------------------------------------------\n//  HILLSHADE\n//\n//  Derive hillshade from DEM.\n//  Display as layer. \n// -------------------------------------------------------------------------------\n\nvar image_hs ;\n\n// -------------------------------------------------------------------------------\n//  ASPECT\n//\n//  Derive aspect from DEM.\n//  Display image as pseudo-color layer with palette: geo.iPalettes.iAspect.cyclical\n//  Add legend aspect image (continuous data) to 'bottom-left' of Map.\n//  Do not show the image by default. \n// -------------------------------------------------------------------------------\n\nvar image_aspect ;\n\n\n// -------------------------------------------------------------------------------\n//  ASPECT, part 2\n//\n//  Make a boolean image where all pixels not equal to 0 are true.\n//  Display boolean image as a map layer.\n//  Do not show the image by default. \n\n//  Mask all pixels in aspect image that are equal to 0.\n//  Display masked image as a map layer. \n//  Do not show the image by default. \n// -------------------------------------------------------------------------------\n\n//  Make a boolean (true/false) image based on a criterion.\n\nvar aspect_neq_0 ;\n\n// -------------------------------------------------------------------------------\n//  ASPECT, part 3\n//\n//  Reclassify the aspect image by equal intervals (22.5).\n//  Remap the image to represent N, NE, E, SE, S, SW, W, NW categories. \n//  Display remapped image as a pseudo-color layer with palette: geo.iPalettes.iAspect.nominal\n//  Add legend to the bottom-left corner of Map.\n// -------------------------------------------------------------------------------\n\n//  Reclassify by equal intervals.\n\nvar image_aspect_reclassified ;\n\n//  Remap values. \n\nvar image_aspect_remapped ;\n\n// -------------------------------------------------------------------------------\n//  ADD AOI ON TOP OF MAP\n// -------------------------------------------------------------------------------\n\nMap.add(geo.aoi.t2_layer);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-03/","title":"T3. Intro to feature collections","text":"<p>TUTORIAL 3</p>"},{"location":"problems/tutorial-03/#introduction-to-feature-collections","title":"Introduction to feature collections","text":""},{"location":"problems/tutorial-03/#goal","title":"goal","text":"<p>This tutorial aims to introduce you to gathering, filtering, and displaying large vector datasets in Earth Engine. Your goal is to work through the starter script and try to reproduce the layers that are shown in the app below.</p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-03/#starter-script","title":"starter script","text":"<pre><code>var geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ---------------------------------------------------------------------------\n//  I. A SIMPLE FEATURE COLLECTION PATTERN\n//\n//  (1) Gather feature collection from \"TIGER/2018/Counties\".\n//  (2) Note the number of rows in the table, the column names, and the first row of data.\n//  (3) Also find all the unique county names in the county. How many are there?\n//  (4) Display all the rows in the collection as a Map layer. Use {color: 'white'} \n// ---------------------------------------------------------------------------\n\n\n\n\n// ---------------------------------------------------------------------------\n//  II. FILTER BY ATTRIBUTE\n//\n//  (1) How may counties in the USA are named \"Addison\"?\n//  (2) Display all counties named Addison in the USA on the Map with {color: 'gray'}.\n// ---------------------------------------------------------------------------\n\n\n\n// ---------------------------------------------------------------------------\n//  III. FILTER BY LOCATION\n//\n//  (1) Use the geometry tool (upper left of Map) to create a point somewhere inside Addison County, Vermont.\n//  (2) Filter the original feature collection by location using this poi. \n//  (3) Display the result (Addison county filtered by poi) on the Map with {color: 'black'}.\n// ---------------------------------------------------------------------------\n\n\n\n\n// ---------------------------------------------------------------------------\n//  IV. FILTER BY MULTIPLE ATTRIBUTES.\n//  \n//  (1) Filter the original collection for \"Orange\" county.\n//  (2) How many Orange counties are in the USA?\n//  (3) Display the result (All counties named 'Orange') on map as layer with {color: 'orange'}.\n\n//  (4) Use AND filter to filter the original collection of counties for \"Orange\" county IN VERMONT.\n//  HINT: the STATEFP column stores strings (even through they look like numbers).\n//  (5) Display the result as a layer on the Map with {color: 'OrangeRed'}.\n// ---------------------------------------------------------------------------\n\n\n\n\n// ---------------------------------------------------------------------------\n//  V. FILTER BY ATTRIBUTE AND LOCATION\n//\n//  (1) Construct a new feature collection from \"TIGER/2018/States\".\n//  (2) Filter collection for Vermont.\n//  (3) Center Map on Vermont. \n//  (4) Add Vermont layer to Map with {color: 'green'}\n//  (5) Filter original county collection by name \"Orange\" and use a FILTER BY LOCATION to filter in bounds of Vermont state.\n//  (6) Display result on map with {color: \"LightGreen\"}\n// ---------------------------------------------------------------------------\n\n\n\n\n// ---------------------------------------------------------------------------\n//  VI. FILTER BY ATTRIBUTE AND LOCATION: TRICKY CASE\n//  \n//  (1) Try to reproduce last workflow (FILTER BY ATTRIBUTE AND FILTER BY LOCATION) to map \"Essex\" county in Vermont.\n//  (2) How did it work? What do you think happened?\n//  (3) Can you fix it with a workflow that does not use AND but still links together\n//    (A) a FILTER BY ATTRIBUTE with \n//    (B) a SPATIAL FILTER  \n//  (4) Display the fixed result as a layer to the map with {color: 'magenta'}.\n// ---------------------------------------------------------------------------\n\n\n\n// ---------------------------------------------------------------------------\n//  VII. FIRST CHALLENGE \n//\n//  (1) How could you select all the counties in Vermont using a FILTER BY ATTRIBUTE workflow?\n//  (2) After you filter the data, add the result  {color: \"PowderBlue\"}\n// ---------------------------------------------------------------------------\n\n\n\n// ---------------------------------------------------------------------------\n//  VIII. SECOND CHALLENGE\n//\n//  (1) How could you select all the counties in Vermont using a FILTER BY LOCATION workflow?\n//  (2) After you filter the data, add the result  {color: \"DeepSkyBlue\"}\n// ---------------------------------------------------------------------------\n\n\n\n// ---------------------------------------------------------------------------\n//  IX. FINAL TASK\n//  \n//  (1) Convert one of the counties in Vermont dataset (VII or VIII) to nominal image \n//  (2) Display each county in a unique color.\n// ---------------------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-03/#checks-in-starter","title":"checks in starter","text":"<p>Here are some checks that you can print to Console for sections I - V.  </p> SECTION DESCRIPTION CHECKS I-2 Number of rows in table. 3233 I-2 Column names 18 of them, beginning with GEOID and ending with METDIVFP I-2 First row of table id: 00000000000000000011; geometry: Polygon, 656 vertices; properties: 17 I-3 Unique county names 1922 of them II-1 Number of rows in table 1 III-2 Number of rows in table 1 IV-2 Number of rows in table 8 V Number of rows in table (states) 56 <p>For sections VI - IX, you should be able to check your work by visually comparing your map layers to the ones shown in the app above.  </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-04/","title":"T4. Forest blocks","text":"<p>TUTORIAL 4</p>"},{"location":"problems/tutorial-04/#forest-blocks","title":"Forest blocks","text":""},{"location":"problems/tutorial-04/#goal","title":"goal","text":"<p>This tutorial aims to introduce concepts and techniques for working with local overlay operations and geographic objects in Earth Engine.  </p> <p>Our practical goal is to identify all habitat blocks (contiguous regions of tree canopy and shrublands without impervious surfaces) that are greater than 100 acres in area. You will experiment with two different approaches to model these geographic objects and then export one layer as a cloud asset. In the end, your workflow should produce the set of layers shown in the app below. </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-04/#starter-scripts","title":"Starter scripts","text":"<p>Please complete the workflow outlined below. For most tasks, you will produce a layer that you can compare to the layers in the app.</p>"},{"location":"problems/tutorial-04/#00-start-your-workflow","title":"00 Start your workflow.","text":"<p>Start a new script and then add your header, import the geo module, and your cloud data addresses. </p> <pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     \n    TITLE:  \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// -------------------------------------------------------------  \n\n// Feature collections  \n\nvar town_address = \"projects/conservation-atlas/assets/cadastre/Boundary_TWNBNDS_poly\"; // Images\n\nvar canopy_address = \"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_TreeCanopy\" ;\nvar shrub_address = \"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Shrublands\";\nvar imp_address = \"projects/vt-conservation/assets/landcover/STATEWIDE_2022_50cm_LANDCOVER_Impervious\";\n</code></pre>"},{"location":"problems/tutorial-04/#01-define-study-region","title":"01 Define study region.","text":"<p>Your goals here are to first define a study town. We will use Middlebury in this tutorial, but ideally you will write your script so that you will be able to easily switch your study to any other town in Vermont.</p> <p>After you select the study town, please define your study region as the study town plus all adjacent towns (or any town that overlaps a boundary of the study town). </p> <p>Next make boolean images for both the study town and the study region. We will need these to mask layers later in the workflow.  </p> <p>Finally, center the Map on your study town. I used a zoom level of 12, but just pick one that works for your monitor. Then change the base map to \u2018hybrid\u2019 so that you can compare the land cover layers in the next step to an image of ground conditions.    </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  1. Define study region.\n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  1.1 Make a layer that shows the study town (Middlebury).\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.2 Convert study town into boolean (to use as mask later).\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.3 Define aoi as study town and surrounding towns. \n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  1.4 Convert aoi into a boolean (to use as mask later).\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  1.5 Center map on study town.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-04/#02-gather-land-cover-data","title":"02 Gather land cover data.","text":"<p>The next set of tasks involve gathering the land cover data that we will use to model habitat blocks. These datasets are all available through VCGI. I have imported them as assets in the cloud so that we can all share them. The table below provides more details about each dataset used in this tutorial. </p> <p> ASSET NAME DESCRIPTION FORMAT RESOLUTION STATEWIDE_2022_50cm_LANDCOVER_TreeCanopy Vermont Tree Canopy Land Cover 2022 Image 50 cm STATEWIDE_2022_50cm_LANDCOVER_Shrublands Vermont Shrublands Land Cover 2022 Image 50 cm STATEWIDE_2022_50cm_LANDCOVER_Impervious Vermont Impervious Surfaces Land Cover 2022 Image 50 cm <p></p> <p>After you construct images from these address, you will likely need to inspect the data properties of these objects in order to display them effectively. The table below lists the palettes that I used in the tutorial. </p> <pre><code>var canopy_palette = [\"#238b45\", \"#74c476\"];\nvar shrubs_palette = [\"#c0e673\"];\nvar imp_palette = [\"#4e4e4e\", \"#ffffff\", \"#a2a2a2\", \"#C47774\"];\n</code></pre> <p>The layers that you draw on your Map should:  </p> <ul> <li>use the colors from these palettes  </li> <li>only show data for our aoi  </li> </ul> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  2. Gather land cover data. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  2.1 Gather and display tree canopy masked by aoi.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.2 Gather and display shrub masked by aoi.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  2.3 Gather and display impervious masked by aoi.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-04/#03-model-habitat-as-a-boolean-image","title":"03 Model habitat as a boolean image.","text":"<p>In this set of tasks, your goal is to use local operations with the land cover data to make a layer that shows locations that are either tree canopy or shrubland but not impervious and then report both the total area and the area as a percent of the study town.  </p> <p>Part of the puzzle here involves working with masks. Remember, that any location that is masked will not be included in the analysis. In this case, you want to exclude all locations outside of your AOI, but include all locations within your AOI.   </p> <p>You might find it helpful to use the inspector tool to click on locations and see their data values. For each layer, you want to make sure that values are masked outside the AOI and not masked inside the aoi.  </p> <p>Also pay close attention that you should report the area and percent area of tree or shrub without impervious in the study town, not the entire AOI. </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  3. Model habitat as boolean image. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  3.1 Make boolean image that shows locations that are either tree canopy or shrub.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.2 Make image of tree or shrub locations that are not impervious.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.3. Calculate area of tree or shrub without impervious in study town.\n// -------------------------------------------------------------\n\n\n\n// -------------------------------------------------------------\n//  3.3. Calculate area of tree or shrub without impervious as percent of study town. \n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-04/#04-model-habitat-blocks-as-object-image-with-focal-methods","title":"04 Model habitat blocks as object image with focal methods.","text":"<p>In this set of tasks, your goal is to experiment with focal methods to identify objects and calculate their areas.  </p> <p>I would like you to pay attention to two things here:  </p> <ol> <li>How would you describe the habitat that is omitted from the resulting layer? Why do you think this habitat was excluded from the results? </li> <li>How does your result change when you zoom in or out of the layer? What does this tell you about how focal methods work in Earth Engine?  </li> </ol> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  4. Model habitat blocks as object image with focal methods. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  4.1 Make object layer from clusters with 3.2 boolean image.\n// -------------------------------------------------------------\n\n\n// -------------------------------------------------------------\n//  4.2 Make object area layer from clusters with 3.2 boolean image.\n// -------------------------------------------------------------\n</code></pre>"},{"location":"problems/tutorial-04/#05-model-habitat-blocks-as-object-image-with-vector-methods","title":"05 Model habitat blocks as object image with vector methods.","text":"<p>Your goal here is to experiment with vector methods to identify objects. You will find that this approach is computationally expensive and Earth Engine may throw errors at you that complain about how much work you are asking it to do. To help resolve this, you will filter the collection by attribute and select only the habitat blocks that are at least 100 acres in area. You should be able to display this result as a map layer.  </p> <p>Finally, because the vector method is computationally expensive, your last task in this set is to export the feature collection as an asset. We will use this layer in the practice problem later this week.  </p> <pre><code>// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n//  5. Model habitat blocks as object image with vector methods. \n// -+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-\n\n// -------------------------------------------------------------\n//  5.1 Make objects from 3.2 boolean image using convert to vector method.\n// -------------------------------------------------------------\n\n\n// DO NOT ADD AS LAYER - EE WILL LIKELY PROTEST! \n// Just inspect with print to console methods. \n\n\n// -------------------------------------------------------------\n//  5.2 Filter for blocks greater than 100 acres and display as map layer. \n// -------------------------------------------------------------\n\n\n// Again, this is a big computational ask for Earth Engine, so do not show layer by default.\n\n\n// -------------------------------------------------------------\n//  5.3 Export 5.2 feature collection to asset and display as layer.\n// -------------------------------------------------------------\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-05/","title":"T5. Scale in web mercator","text":"<p>TUTORIAL 5</p>"},{"location":"problems/tutorial-05/#scale-in-web-mercator","title":"scale in web mercator","text":""},{"location":"problems/tutorial-05/#_1","title":"T5. Scale in web mercator","text":"<p>This tutorial aims to introduce concepts and methods for working with proximity and zonal statistics in Earth Engine.  </p> <p>Our practical goal is to make a map of Tissot\u2019s Indicatrix and then compute the area and number of pixels contained by each circle through a zonal overlay method. By the end, your script should reproduce the layers shown in the app below. </p> <p>In addition, you should be able to interpret your results by using the Inspector tool to compare how pixel scale changes with respect to the area and pixel count of Tissot\u2019s indicatrix.   </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-05/#workflow","title":"workflow","text":""},{"location":"problems/tutorial-05/#00-start-script","title":"00 start script","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:   \n    DATE:     10/7/2024\n    TITLE:    Scale in web mercator\n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n</code></pre>"},{"location":"problems/tutorial-05/#01-set-up-map","title":"01 set up map","text":"<pre><code>// -------------------------------------------------------------\n//  1. Set up map\n// -------------------------------------------------------------\n\n// 1.1. Center map on prime meridian and equator at zoom level 2.  \n\nMap.setCenter(0,0,2);\n\n// 1.2. Set base map to hybrid.\n\n\n\n// 1.3. Compute Map scale at Map zoom \n\nvar scale = Map.getScale();\n\nprint(\"Map scale\", scale);\n</code></pre>"},{"location":"problems/tutorial-05/#02-visualize-pixel-area","title":"02 visualize pixel area","text":"<pre><code>// -------------------------------------------------------------\n//  2. Visualize change in pixel area across Map.\n// -------------------------------------------------------------\n\n// 2.1. Make a layer that stores area of each pixel in square kilometers.\n\nvar pixel_area = ee.Image.pixelArea().divide(1e6);\n\n// 2.2. Draw a rectangle from equator to pole.\n\nvar test_extent = ee.Geometry.Polygon(\n[[[-139.54012012783244, 16.927790310290327],\n[-139.54012012783244, -85.91090722591649],\n[52.41300487216755, -85.91090722591649],\n[52.41300487216755, 16.927790310290327]]]);\n\n// 2.3. Calculate min and max of area image with test_extent rectangle at scale of zoom level. \n\n\n\n// 2.4. Define viz parameters with palette: geo.iPalettes.iDistance.inferno\n\n\n\n// 2.5. Display pixel_area as layer on Map.\n\n\n\n// 2.6. Make legend of pixel area layer. \n\n\n\n// 2.7. Add legend to Map.  \n</code></pre>"},{"location":"problems/tutorial-05/#03-create-tissots-indicatrix","title":"03 create Tissot\u2019s indicatrix","text":"<pre><code>// -------------------------------------------------------------\n//  3. Create Tissot's Indicatrix. \n// -------------------------------------------------------------\n\n// 3.1. Gather tissot grid.\n\nvar grid = geo.projections.tissot_grid;\n\nprint(\"3.1. grid\", grid);\n\n// 3.2. Display grid as Map layer.\n\n\n\n// 3.3 Buffer each point in grid by 600,000 meters. \n\n\n\n// 3.4 Add buffered points (Tissot's Indicatrix) as Map Layer. \n\nMap.addLayer(indicatrix, {color: 'gold'}, \"3.4. Tissot's Indicatrix\");\n</code></pre>"},{"location":"problems/tutorial-05/#04-visualize-area-of-indicatrix","title":"04 visualize area of indicatrix","text":"<pre><code>// -------------------------------------------------------------\n//  4. Visualize area of Tissot's indicatrix\n// -------------------------------------------------------------\n\n// 4.1 Zonal statistic for sum of pixel area at scale 5000.\n\n\n\n\n// 4.2 Convert 4.1 output to image\n\n\n\n// 4.3 Define viz parameters.\n\n\n\n// 4.4 Display as Map layer.\n\n\n\n// 4.5. Make legend of tissot area layer. \n\n\n\n// 4.6. Add legend to Map.  \n</code></pre>"},{"location":"problems/tutorial-05/#05-visualize-count-of-indicatrix","title":"05 visualize count of indicatrix","text":"<pre><code>// -------------------------------------------------------------\n//  5. Visualize count of indicatrix\n// -------------------------------------------------------------\n\n// 5.1 Zonal statistic for count of pixel area at scale 5000.\n\n\n\n// 5.2 Convert to image. \n\n\n\n// 5.3 Define viz parameters. \n\n\n\n\n// 5.4 Display as Map layer.  \n\n\n\n\n// 5.5. Make legend of tissot area layer. \n\n\n// 5.6. Add legend to Map.  \n</code></pre>"},{"location":"problems/tutorial-05/#06-inspect-your-results","title":"06 inspect your results","text":"<p>Click on the Inspector tab on the right panel of the Code Editor. Moving from the equator towards the poles, clock on the Tissot Indicatrix and note the Scale (approx. m/px) that GEE reports. This number should report the distance on the ground represented by the length of one pixel side.  </p> <p>HINT: You may need to click on the Point header in order to see the scale reports. </p> <p>Try to answer these questions:  </p> <ol> <li>How does scale change with latitude?  </li> <li>How does this jive with the area and count statistics that you calculated for each circle?  </li> <li>How do you explain these results?  </li> </ol> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-07/","title":"T7. NAIP Explorer","text":"<p>TUTORIAL 7 </p>"},{"location":"problems/tutorial-07/#project-planning-with-naip-explorer","title":"project planning with NAIP explorer","text":""},{"location":"problems/tutorial-07/#goal","title":"goal","text":"<p>This tutorial aims to introduce:  </p> <ul> <li>NAIP imagery</li> <li>image interpretation  </li> <li>natural and false color  </li> <li>spectral signature charts </li> </ul> <p>By the end of the tutorial, you should have a plan to investigate changes in a region of your choice in this week\u2019s practice problem.  </p>"},{"location":"problems/tutorial-07/#workflow","title":"workflow","text":"<ol> <li>Please open the NAIP Explorer app.</li> <li>Choose a study region:<ul> <li>please choose some place in the USA (lower 48 is likely best due to data availability) that is not Middlebury, Vermont (though other places in Vermont are fair game); </li> <li>please choose a place that you are either familiar with through past experience or that you are interested in visiting sometime in the future;</li> <li>please choose a region with sufficient geographical diversity to provide five different land cover types (with distinct spectral signatures).</li> </ul> </li> <li>Please complete this form.</li> </ol> <p>The completed form is  due by the end of your lab meeting period.   </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"problems/tutorial-08/","title":"T8. Landsat snapshots","text":"<p>TUTORIAL 8 </p>"},{"location":"problems/tutorial-08/#landsat-snapshots","title":"Landsat snapshots","text":""},{"location":"problems/tutorial-08/#goal","title":"goal","text":"<p>This tutorial aims to introduce you to workflows for processing and displaying earth observation data collected by Landsat missions over the last forty years.    </p> <p>Your practical goal is to gather and process a time series of snapshots that use data collected by Landsat missions to show change in a place over time. In the practice problem this week, you will use this data to make an app the shows and explains these changes.  </p>"},{"location":"problems/tutorial-08/#instructions","title":"instructions","text":"<p>Please complete the following tasks:</p> <ol> <li>Choose a study location. <ol> <li>Review the World of Change stories on Earth Observatory.  </li> <li>Pick a story location to investigate. The story should use RGB composites from Landsat to show changes to the Earth\u2019s surface over the last forty or so years.  </li> </ol> </li> <li>Collect snapshots from Landsat collections  <ol> <li>Make a new folder in your repository called \u201cTutorial-08\u201d.</li> <li>Use the Landsat starter scripts to create a series of scripts where each script captures one image at a different time. </li> <li>Please make at least one image with data from each Landsat mission (5,7,8,9).  Note: even if the story that you selected from EO only shows two snapshots, please collect at least one image from each Landsat mission. I would like you to understand differences between the missions and how this can affect their use.</li> </ol> </li> <li>By 5pm today (11/4), please complete the Canvas quiz for Tutorial 08.</li> </ol>"},{"location":"problems/tutorial-09/","title":"T9. Spectral indices","text":"<p>TUTORIAL 09 </p>"},{"location":"problems/tutorial-09/#spectral-indices","title":"spectral indices","text":""},{"location":"problems/tutorial-09/#goal","title":"goal","text":"<p>This tutorial introduces spectral indices, or calculations made with local operations that compare two or more spectral bands. Additionally, this tutorial introduces a method to reclassify spectral indices with user-defined breaks to make nominal images of landcover.    </p> <p>Your practical goal is to solve the two problems described below. The first we will walk through in lecture. The second you will do either alone or with a buddy or two during lab.  </p>"},{"location":"problems/tutorial-09/#deliverables","title":"deliverables","text":"<p>By 5pm on November 11, please complete the Tutorial 09 checkup on Canvas. To receive credit for this tutorial, you must submit links to your scripts (and accomplish all prompts listed below). You must also thoughtfully respond to the check-up prompts to briefly critique your results for both problems. Please note that this check-up will be manually graded, so you will only be able to submit it once.  </p>"},{"location":"problems/tutorial-09/#ndvi-problem","title":"NDVI problem","text":"<p>Please use Landsat 9 to make a map of New York City that accomplishes the following: </p> <ol> <li>Filters the image collection for:<ol> <li>a poi in New York City,</li> <li>the years 2022 - 2024,</li> <li>the months of July and August,</li> <li>with less than 20% cloud cover,</li> <li>with cloudy pixels masked.</li> </ol> </li> <li>Flattens the collection to the median image. </li> <li>Displays the median image with two different false color composites:<ol> <li>A NIR, Red, Green composite.</li> <li>A SWIR2, NIR, Green composite.  </li> </ol> </li> <li>Calculates the NDVI of the median image. </li> <li>Displays the NDVI band with the divergent color scheme <code>palette_ndvi</code> defined below.</li> <li>Reclassifies the NDVI band with user-defined thresholds to distinguish five classes:  <ol> <li>Water</li> <li>Impervious or bare</li> <li>Sparse and/or stressed vegetation</li> <li>Moderately healthy vegetation  </li> <li>Dense and/or healthy vegetation  </li> </ol> </li> <li>Adds the reclassified layer to the Map and displays with nominal palette scheme <code>palette_reclass</code> defined below.</li> <li>Adds legends to the map for both NDVI layer and reclassified NDVI layer.  </li> </ol> <pre><code>// Palette helpers. \n\nvar palette_ndvi = ['purple', 'white', 'green'])\nvar palette_reclass = [\"PaleTurquoise\", \"White\", \"Gold\", \"YellowGreen\", \"OliveDrab\"]\n</code></pre>"},{"location":"problems/tutorial-09/#nbr-problem","title":"NBR problem","text":"<p>Please use Landsat 9 to make a map of the Quebec wildfire scars from the summer of 2023. Your map should accomplish the following:</p> <ol> <li>Filters the image collection for:<ol> <li>a poi on \u201cNutimesanu, QC, Canada\u201d,</li> <li>the year 2023,</li> <li>the months of August and September,</li> <li>with less than 20% cloud cover,</li> <li>with cloudy pixels masked.</li> </ol> </li> <li>Flattens the collection to the median image. </li> <li>Displays the median image with two different false color composites:<ol> <li>A NIR, Red, Green composite.</li> <li>A SWIR2, NIR, Green composite.  </li> </ol> </li> <li>Calculates the NBR of the median image. </li> <li>Displays the NBR band with the divergent color scheme <code>palette_ndvi</code> defined below.</li> <li>Reclassifies the NBR band with user-defined thresholds to distinguish three classes:  <ol> <li>Water</li> <li>Burn scar</li> <li>Not burned </li> </ol> </li> <li>Adds the reclassified layer to the Map and displays with nominal palette scheme <code>palette_reclass</code> defined below.</li> <li>Adds legends to the map for both NBR layer and reclassified NBR layer.  </li> </ol> <pre><code>// Palette helpers. \n\nvar palette_nbr = ['purple', 'white', 'green'])\nvar palette_reclass = [\"LightSkyBlue\", \"DarkOrchid\", \"YellowGreen\"]\n</code></pre>"},{"location":"problems/tutorial-10/","title":"T10. Drought mapping","text":"<p>TUTORIAL 10 </p>"},{"location":"problems/tutorial-10/#drought-mapping","title":"Drought mapping","text":""},{"location":"problems/tutorial-10/#goal","title":"goal","text":"<p>This tutorial aims to introduce you to mapping temporal anomalies, where anomaly means the percent difference of a part to a whole and temporal means the parts and whole represent a short duration record versus a long duration record.  </p> <p>In this example, we will look at temporal anomalies in the NDVI index of MODIS 8 day composites. Since NDVI represents the \u201cgreenness\u201d or health of vegetation, it is often used as a proxy for drought.  </p> <p>We will develop the model using the case of drought in Santa Barbara, California. But the script should be written such that you can easily run the analysis for almost any region in the world.  </p> <p> </p> <p>open app in new tab</p>"},{"location":"problems/tutorial-10/#workflow","title":"workflow","text":"<p>Here are the main steps to the solution. Whenever possible, please print your results to console so that you can self-check your workflow.   </p>"},{"location":"problems/tutorial-10/#00-start-a-script","title":"00 start a script","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:       \n    DATE:         \n    TITLE:        tutorial-10.js\n\n    Mapping drought - temporal anomaly with MODIS 8 day composites.  \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\nMap.setOptions('hybrid');\n</code></pre>"},{"location":"problems/tutorial-10/#01-combine-modis-collections","title":"01 combine MODIS collections","text":"<pre><code>// ----------------------------------------------------------------------\n//  Step 1. Combine Terra and Aqua daily collections. \n// ----------------------------------------------------------------------\n\n// Print metadata for spectral bands. \n\n\n\n// Gather collections of terra and aqua 8 day averages. \n\n\n// Combine daily collections. \n</code></pre>"},{"location":"problems/tutorial-10/#02-filter-ldr-and-sdr","title":"02 filter ldr and sdr","text":"<pre><code>// ----------------------------------------------------------------------\n//  Step 2. Filter collection for long- and short- duration records.\n// ----------------------------------------------------------------------\n\n// Mask cloudy and water pixels and rename bands --&gt; long duration record.\n\nvar output_ldr = combineMODIS\n.map(geo.icMODIS.maskClouds_8day)                   // Mask cloudy pixels\n.map(geo.icMODIS.maskWater_8day)                    // Mask water pixels.\n.map(geo.icMODIS.renameSpectralBands)               // Rename bands because they have weird names.\n;\n\n// Define year of interest as 2015.\n\nvar yoi = 2015;\n\n// Filter long duration record by year of interest --&gt; short term record.\n</code></pre>"},{"location":"problems/tutorial-10/#03-map-sdr-median","title":"03 map sdr median","text":"<p>The script below assumes that you named your short duration record: output_sdr  </p> <pre><code>// ----------------------------------------------------------------------\n//  Step 3. Display median short duration image as Map layer.  \n// ----------------------------------------------------------------------\n\nvar viz = {\n\nbands: ['R', 'G', 'B'],\nmin: [0.01, 0.02, 0.0],\nmax: [0.25, 0.25, 0.175],\ngamma: 1.2,\n\n};\n\n// Define display image from short duration collection. \n\nvar display_image = output_sdr    // short duration collection\n.median()                       // flatten image (median)\n.multiply(0.0001)               // apply scalar for reflectance values (* 0.0001)  \n;          Map.addLayer(display_image, viz, 'STEP 3. MODIS imagery', false);\n</code></pre>"},{"location":"problems/tutorial-10/#04-chart-histogram","title":"04 chart histogram","text":"<p>In the script above, I already did some stretch enhancement for you. This step is here if you would like to further adjust, or to have this step in workflow for future applications.  </p> <pre><code>// // ------------------------------------------------------------------------\n// //  Step 4. Chart histogram for a selected Image band.  \n// // ------------------------------------------------------------------------\n\n// // Select a band in viz dictionary to chart. \n\n// var select_band = display_image.select(viz.bands[0]);\n\n// // Get AOI from map extent.\n\n// var aoi = geo.uiMap.getAOIfromMapExtent();\n\n// // Get scale from map extent.\n\n// var scale =  Map.getScale();\n\n// // Make and print histogram.\n\n// var histogram = geo.iCart.iHistogram(\n//     select_band, \n//     scale,\n//     aoi                 \n// );\n\n// print(\"Step 4. HISTOGRAM OF SELECTED BAND\", histogram);\n</code></pre>"},{"location":"problems/tutorial-10/#05-map-spectral-index-function","title":"05 Map spectral index function","text":"<pre><code>// ----------------------------------------------------------------------\n//  Step 5. Calculate spectral index for each image in each collection.  \n// ----------------------------------------------------------------------\n\n// Write computation as a function.  \n\n\n\n// Map function over long duration record.  \n\n\n\n// Map function over short duration record. \n</code></pre>"},{"location":"problems/tutorial-10/#06-display-median-ndvi-of-sdr","title":"06 Display median NDVI of sdr","text":"<pre><code>// ----------------------------------------------------------------------\n//  Step 6. Display median NDVI of sdr as a Map layer.  \n// ----------------------------------------------------------------------\n\n// Flatten sdr with spatial index as median image and select 'NDVI' band.\n\n\n// Define viz parameters.\n\nvar viz_ndvi =  {min:-0.8, max:0.8, palette: geo.iPalettes.iDrought};\n\n// Display image as map layer. \n</code></pre>"},{"location":"problems/tutorial-10/#07-define-roi","title":"07 Define roi","text":"<pre><code>// ------------------------------------------------------------------------\n//  Step 7. Define regions of interest.  \n// ------------------------------------------------------------------------\n\n// Gather regions as feature collection from \"FAO/GAUL/2015/level2\".  \n\n\n\n// Define a point of interest (update with geometry tools to change roi).\n\nvar geometry = ee.Geometry.Point([-119.72687261495858, 34.42223412451513]);\n\n// Select region of interest with poi.\n\n\n// Center Map on roi at zoom 9.\n</code></pre>"},{"location":"problems/tutorial-10/#08-make-monthly-summaries","title":"08 Make monthly summaries","text":"<p>The script below assumes that you named short duration record with spectral index from Step 5: output_sdr_with_si.</p> <pre><code>// ----------------------------------------------------------------------\n//  Step 8. Make monthly summaries of short and long duration records. \n// ----------------------------------------------------------------------\n\n// Make monthly summary of short duration record. \n\nvar monthly_summaries_sdr = geo.icIntervals.reduceToMonthlySeries(\noutput_sdr_with_si,             // Collection\n\"month\",                        // Time unit to reduce.\nee.Reducer.mean()               // Reducer\n);\n\n// Make monthly summary of long duration record (use same time unit and reducer as above).\n\n\nprint(\"STEP 8. MONTHLY SUMMARIES\", monthly_summaries_sdr);\n</code></pre>"},{"location":"problems/tutorial-10/#09-make-two-band-image","title":"09 Make two band image","text":"<p>The script below assumes that you named your results from Step 8: monthly_summaries_sdr and monthly_summaries_ldr.</p> <pre><code>// ----------------------------------------------------------------------\n//  Step 9. Make two band image of short- and long-duration records.  \n// ----------------------------------------------------------------------\n\nvar monthly_summaries_stack = geo.icIntervals.stackShortLongRecords(\n\"NDVI\",                         // Band in each image to chart.\nmonthly_summaries_sdr,          // Short duration monthly summaries.\nmonthly_summaries_ldr           // Long duration monthly summaries.\n)\n;\n\nprint(\"STEP 9. TWO BAND TIME SERIES\", monthly_summaries_stack);\n</code></pre>"},{"location":"problems/tutorial-10/#10-chart-monthly-summaries","title":"10 Chart monthly summaries","text":"<p>The script below assumes that you named your results from Step 8: monthly_summaries_sdr and monthly_summaries_ldr.</p> <pre><code>// -------------------------------------------------------------\n//  Step 10. Chart monthly summaries.  \n// -------------------------------------------------------------\n\nvar panel_chart = geo.icIntervals.initializePanelForChart('bottom-left');\n\nMap.add(panel_chart);\n\n// Define parameters for time series chart.\n\nvar parameters = {\ncollection: monthly_summaries_stack,  // Name of two band image (Step 9).\nreducer: ee.Reducer.mean(),\nimage_scale: 500,\ninterval_unit: \"month\",          panel: panel_chart,\nroi: regions_select                   // Name of your selected region of interest (Step 7).\n};\n\n// Chart time series with parameters. \n\ngeo.icIntervals.chartMonthlyStacks(parameters);\n</code></pre>"},{"location":"problems/tutorial-10/#11-percent-difference","title":"11 percent difference","text":"<p>The script below assumes that you named your results from Step 9: monthly_summaries_stack.</p> <pre><code>// --------------------------------------------------------------------------\n//  STEP 11. Compute percent difference of short- and long-duration monthly summaries.   \n// --------------------------------------------------------------------------  \n\nvar percent_difference = monthly_summaries_stack    // Two band image. \n.map(geo.icIntervals.percentDifference(\n'NDVI_SDR',                                 // Band name for spectral index of SDR\n'NDVI_LDR'                                  // Band name for spectral index of LDR\n)\n)\n;\n\nprint(\"STEP 11. PERCENT DIFFERENCE\", percent_difference);\n</code></pre>"},{"location":"problems/tutorial-10/#12-map-percent-difference-layer","title":"12 map percent difference layer","text":"<pre><code>// --------------------------------------------------------------------------\n//  STEP 12. Display percent difference for a target month as a Map layer.   \n// --------------------------------------------------------------------------  \n\n// Define month of interest to display.\n\nvar moi = 8;\n\nvar display_month = percent_difference.filter(ee.Filter.eq(\"month\", moi));\n\n// Define viz paramters. \n\nvar viz_percent_difference = {\nmin:-30, max:30, palette: geo.iPalettes.iDrought\n};\n\n// Add layer to map.\n\nMap.addLayer(display_month, viz_percent_difference, \"STEP 12. NDVI Anomaly\");\n</code></pre>"},{"location":"problems/tutorial-10/#13-display-regions","title":"13 Display regions","text":"<pre><code>// ------------------------------------------------------------------------\n//  STEP 13. Display regions of interest as map layers.\n// ------------------------------------------------------------------------\n\nvar strokes = geo.fcCart.paintStrokes(regions, \"white\", 0.5);\n\nMap.addLayer(strokes, {}, \"STEP 13A. Region outlines\");\n\nvar strokes_select = geo.fcCart.paintStrokes(regions_select, \"yellow\", 2);\n\nMap.addLayer(strokes_select, {}, \"STEP 13B. Selected region outlines\");\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"solutions/error-glossary/","title":"Error Glossary","text":"<p>SOLUTIONS</p>"},{"location":"solutions/error-glossary/#error-glossary","title":"Error Glossary","text":"<p>This page shows some error messages that you may receive while using Earth Engine and provides some tips on how you might be able to resolve them.  </p>"},{"location":"solutions/error-glossary/#geometry-errors","title":"geometry errors","text":"<p>The error message indicates a problem with the .geometry of an object.  </p>"},{"location":"solutions/error-glossary/#collectiongeometry","title":"collection.geometry","text":"<p>EE complains because you are asking it to do too much. The proximate cause is likely from a collection that you are using as an input to an operation. If the step that made this collection was a filter, then check to make sure the filter worked as you thought it would.  </p> <p>Make self checks a habit; at each step of a problem, check your results to see if they match what you think they should be. </p>"},{"location":"solutions/error-glossary/#invalid-type","title":"invalid type","text":"<p>The error message indicates a problem with the data type associated with a data object.  </p>"},{"location":"solutions/error-glossary/#feature-argument-geometry","title":"Feature, argument \u2018geometry\u2019","text":"<p>EE complains because you are asking it to do something with the wrong kind of thing. This happens when you try to use a method with arguments of the wrong data type. In the above example, the method expected a feature\u2019s geometry but found an image.  </p> <p>Fixing these problems often requires tracing back several steps. In the above example, EE threw the error when it was asked to display a Map layer, but the <code>Map.addLayer()</code> did not cause the error. Rather, the cause occurred a step of two earlier when EE was asked to use a method with an argument of the wrong type.    </p> <p>Check each output you get from an operation by printing the result to the Console. This will help you identify if the operation worked before you go too far downstream. </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"solutions/practice/","title":"Practice","text":"<p>SOLUTIONS </p>"},{"location":"solutions/practice/#practice-problems","title":"Practice problems","text":"<p>The links in the table below will open a worked out script for the problem in the Code Editor.  </p> LINK PROBLEM UPDATE P1 Memory under cover 9/11/24 P2 Ice age bathtub 9/18/24 P3 Parent materials of soils 9/25/24 P4 Forest blocks and habitat connectors 10/2/24 P5 Land use in riparian zone 10/14/24 P9 CZU Burn Severity 11/13/24"},{"location":"solutions/tutorials/","title":"Tutorials","text":"<p>SOLUTIONS </p>"},{"location":"solutions/tutorials/#tutorial-problems","title":"Tutorial problems","text":"<p>The links in the table below will open a worked out script for the problem in the Code Editor.  </p> LINK PROBLEM UPDATE T1 A sketch map from Lidar 9/9/24 T2 A slippy topographic map 9/16/24 T3 Intro to feature collections 9/23/24 T4 Forest blocks (part 1) 9/30/24 T5 Scale in web mercator 10/7/24 T9 Quebec fire scars 11/13"},{"location":"starters/MODIS/","title":"MODIS","text":"<p>STARTERS </p>"},{"location":"starters/MODIS/#modis","title":"MODIS","text":"<p>Earth Engine provides a somewhat staggering number of different MODIS products as cloud assets. The sheer number of products available can make it a little confusing to navigate. This page aims to help by introducing some key concepts for working with MODIS.   </p>"},{"location":"starters/MODIS/#key-terms","title":"key terms","text":""},{"location":"starters/MODIS/#sensor-and-satellites","title":"sensor and satellites","text":"<p>The Moderate Resolution Imaging Spectrometer, or MODIS, is a sensor onboard two satellites:  </p> <ul> <li>Terra: originally called as EOS AM-1  </li> <li>Aqua: originally called EOS PM-1 </li> </ul>"},{"location":"starters/MODIS/#orbits","title":"orbits","text":"<p>These two satellites image Earth\u2019s entire surface once every 1-2 days. The video below shows the orbit of the Aqua satellite.   </p>"},{"location":"starters/MODIS/#bands","title":"bands","text":"<p>Compared to Landsat and Sentinel, MODIS bucks convention for band names. It also differs from other sensors by having a second NIR band (between NIR and SWIR1).     </p> BAND NUMBER BAND NAME BAND WIDTH (nm) B1 Red 620 - 670 B2 NIR 841 - 876 B3 Blue 459 - 479 B4 Green 545 - 565 B5 NIR2 1230 - 1250 B6 SWIR1 1628 - 1652 B&amp; SWIR2 2105 - 2155"},{"location":"starters/MODIS/#sr-snapshots","title":"SR snapshots","text":"<p>These scripts will help you get started making snapshots with two different MODIS surface reflectance (SR) products. The eight day composites help speed up processing times.  </p>"},{"location":"starters/MODIS/#daily-images","title":"daily images","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_MODIS_daily.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/17/2024\n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// // Map.centerObject(geometry, 6);\n\nMap.setOptions('hybrid');\n\n// ----------------------------------------------------------------------\n//  Combine Terra and Aqua daily collections. \n// ----------------------------------------------------------------------\n\n// Print metadata for spectral bands. \n\nprint(\"MODIS spectra\", geo.icMODIS.spectral_bands);\n\n// Gather collections of terra and aqua daily images. \n\nvar terra_1day = ee.ImageCollection(\"MODIS/061/MOD09GA\");\nvar aqua_1day = ee.ImageCollection(\"MODIS/061/MYD09GA\");\n\nprint(\n\"MODIS\",\nterra_1day.first(),\nterra_1day.size(),\naqua_1day.first(),\naqua_1day.size()\n)\n;\n\n// Combine daily collections. \n\nvar combineMODIS = terra_1day\n.merge(aqua_1day)\n;\n\nprint(\n\"TERRA, AQUA COMBINED\",\ncombineMODIS.size()\n)\n;\n\n// ----------------------------------------------------------------------\n//  Filter \n// ----------------------------------------------------------------------\n\n// Define year and month of interest. \n\nvar yoi = 2021;\nvar moi = 8;\n\n// Filter collections by time and cloudy pixels.\n\nvar output = combineMODIS\n.filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n.filter(ee.Filter.calendarRange(moi, moi, \"month\"))\n.map(geo.icMODIS.maskClouds_1day)                   // Mask cloudy pixels\n.map(geo.icMODIS.renameSpectralBands)               // Rename bands because they have weird names.\n.median()\n.multiply(0.0001)                                   // Apply scalar after flattening collection.\n;\n\nprint(\"OUTPUTS\", output);\n\n\n// ----------------------------------------------------------------------\n// Display\n// ----------------------------------------------------------------------\n\nvar viz = {\n\nbands: ['R', 'G', 'B'],\nmin: [0.01, 0.02, 0.0],\nmax: [0.25, 0.25, 0.175],\ngamma: 1.2,\n\n};\n\nMap.addLayer(output, viz, 'MODIS imagery');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictionary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Get scale from map extent.\n\nvar scale =  Map.getScale();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(\nselect_band, scale,\naoi                 );\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/MODIS/#8-day-composites","title":"8 day composites","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_MODIS_8day_composites.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for MODIS collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\nMap.setOptions('hybrid');\n\n\n// ----------------------------------------------------------------------\n//  Combine Terra and Aqua daily collections. \n// ----------------------------------------------------------------------\n\n// Print metadata for spectral bands. \n\nprint(\"MODIS spectra\", geo.icMODIS.spectral_bands);\n\n// Gather collections of terra and aqua 8 day averages. \n\nvar terra_8day = ee.ImageCollection(\"MODIS/061/MOD09A1\");\nvar aqua_8day = ee.ImageCollection(\"MODIS/061/MYD09A1\");\n\nprint(\n\"MODIS\",\nterra_8day.first(),\nterra_8day.size(),\naqua_8day.first(),\naqua_8day.size()\n)\n;\n\n// Combine daily collections. \n\nvar combineMODIS = terra_8day\n.merge(aqua_8day)\n;\n\nprint(\n\"TERRA, AQUA COMBINED\",\ncombineMODIS.size()\n)\n;\n\n// ----------------------------------------------------------------------\n//  Filter collection\n// ----------------------------------------------------------------------\n\n// Define year and month of interest. \n\nvar yoi = 2021;\nvar moi = 8;\n\n// Filter collections by time and cloudy pixels.\n\nvar output = combineMODIS\n.filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n.filter(ee.Filter.calendarRange(moi, moi, \"month\"))\n.map(geo.icMODIS.maskClouds_8day)                   // Mask cloudy pixels\n.map(geo.icMODIS.renameSpectralBands)               // Rename bands because they have weird names.\n.median()\n.multiply(0.0001)                                   // Apply scalar after flattening collection.\n;\n\nprint(\"OUTPUTS\", output);\n\n\n// ----------------------------------------------------------------------\n// Display\n// ----------------------------------------------------------------------\n\nvar viz = {\n\nbands: ['R', 'G', 'B'],\nmin: [0.01, 0.02, 0.0],\nmax: [0.25, 0.25, 0.175],\ngamma: 1.2,\n\n};\n\nMap.addLayer(output, viz, 'MODIS imagery');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictionary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Get scale from map extent.\n\nvar scale =  Map.getScale();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(\nselect_band, scale,\naoi                 );\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/MODIS/#sr-time-series","title":"SR time series","text":"<p>These scripts will help you get started with time series analysis. We use the eight-day composites to help speed up processing times.   </p>"},{"location":"starters/MODIS/#basic-time-series","title":"basic time series","text":"<p>The script below compiles a collection (rather than a flat image) and then charts all spectral bands over the duration of the collection. </p> <pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_MODIS_8day_time_series.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for MODIS time series. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\nMap.setOptions('hybrid');\n\n// ----------------------------------------------------------------------\n//  Combine Terra and Aqua daily collections. \n// ----------------------------------------------------------------------\n\n// Print metadata for spectral bands. \n\nprint(\"MODIS spectra\", geo.icMODIS.spectral_bands);\n\n// Gather collections of terra and aqua 8 day averages. \n\nvar terra_8day = ee.ImageCollection(\"MODIS/061/MOD09A1\");\nvar aqua_8day = ee.ImageCollection(\"MODIS/061/MYD09A1\");\n\nprint(\n\"MODIS\",\nterra_8day.first(),\nterra_8day.size(),\naqua_8day.first(),\naqua_8day.size()\n)\n;\n\n// Combine daily collections. \n\nvar combineMODIS = terra_8day\n.merge(aqua_8day)\n;\n\nprint(\n\"TERRA, AQUA COMBINED\",\ncombineMODIS.size()\n)\n;\n\n// ----------------------------------------------------------------------\n//  Filter collection\n// ----------------------------------------------------------------------\n\n// Define year and month of interest. \n\nvar yoi = 2023;\n\n// Filter collections by time and cloudy pixels.\n\nvar output = combineMODIS\n.filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n.map(geo.icMODIS.maskClouds_8day)                   // Mask cloudy pixels\n.map(geo.icMODIS.renameSpectralBands)               // Rename bands because they have weird names.\n;\n\nprint(\"OUTPUT COLLECTION\", output);\n\n\n// ----------------------------------------------------------------------\n//  Display image from collection as Map layer.  \n// ----------------------------------------------------------------------\n\nvar viz = {\n\nbands: ['R', 'G', 'B'],\nmin: [0.01, 0.02, 0.0],\nmax: [0.25, 0.25, 0.175],\ngamma: 1.2,\n\n};\n\n// Define display image \n\nvar display_image = output    // time series collection\n.median()                   // flatten image\n.multiply(0.0001)           // apply scalar for reflectance values  \n;          Map.addLayer(display_image, viz, 'MODIS imagery');\n\n\n// // ------------------------------------------------------------------------\n// //  Chart histogram for a selected Image band.  \n// // ------------------------------------------------------------------------\n\n// // Select a band in viz dictionary to chart. \n\n// var select_band = display_image.select(viz.bands[0]);\n\n// // Get AOI from map extent.\n\n// var aoi = geo.uiMap.getAOIfromMapExtent();\n\n// // Get scale from map extent.\n\n// var scale =  Map.getScale();\n\n// // Make and print histogram.\n\n// var histogram = geo.iCart.iHistogram(\n//     select_band, \n//     scale,\n//     aoi                 \n// );\n\n// print(\"Histogram of selected band\", histogram);\n\n// ------------------------------------------------------------------------\n//  Define regions of interest.  \n// ------------------------------------------------------------------------\n\n// Gather regions from a feature collection.  \n\nvar regions = ee.FeatureCollection(\"FAO/GAUL/2015/level2\");\n\n// Define a point of interest with geometry tools.\n\nvar geometry = ee.Geometry.Point([-119.72687261495858, 34.42223412451513]);\n\n// Select region of interest with poi.\n\nvar regions_select = regions.filterBounds(geometry);\n\n// ------------------------------------------------------------------------\n//  Display regions of interest as map layers.\n// ------------------------------------------------------------------------\n\nvar strokes = geo.fcCart.paintStrokes(regions, \"white\", 0.5);\n\nMap.addLayer(strokes, {}, \"Region outlines\");\n\nvar strokes_select = geo.fcCart.paintStrokes(regions_select, \"yellow\", 2);\n\nMap.addLayer(strokes_select, {}, \"Selected region outlines\");\n\n// -------------------------------------------------------------\n//  Initialize panel for time series chart. \n// -------------------------------------------------------------\n\nvar panel_chart = geo.icIntervals.initializePanelForChart('bottom-left');\n\nMap.add(panel_chart);\n\n// Define parameters for time series chart.\n\nvar parameters = {\ncollection: output,\nreducer: ee.Reducer.mean(),\nimage_scale: 500,\n// interval_unit: \"month\",          // Comment out to chart by default \"system:time_start\"\npanel: panel_chart,\nroi: regions_select\n};\n\n// Chart time series with parameters. \n\ngeo.icIntervals.chartTimeSeries(parameters);\n</code></pre>"},{"location":"starters/MODIS/#time-series-of-spectral-index","title":"time series of spectral index","text":"<p>The script below will compute a spectral index (NDVI) for each image in the time series and then chart the index over duration of the collection.    </p> <pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_MODIS_8day_time_series_with_ndvi.js\n//  Author:       Jeff Howarth\n//  Last edited:  10/18/2023\n//\n//  Starter for MODIS time series. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\nMap.setOptions('hybrid');\n\n// ----------------------------------------------------------------------\n//  Combine Terra and Aqua daily collections. \n// ----------------------------------------------------------------------\n\n// Print metadata for spectral bands. \n\nprint(\"MODIS spectra\", geo.icMODIS.spectral_bands);\n\n// Gather collections of terra and aqua 8 day averages. \n\nvar terra_8day = ee.ImageCollection(\"MODIS/061/MOD09A1\");\nvar aqua_8day = ee.ImageCollection(\"MODIS/061/MYD09A1\");\n\nprint(\n\"MODIS\",\nterra_8day.first(),\nterra_8day.size(),\naqua_8day.first(),\naqua_8day.size()\n)\n;\n\n// Combine daily collections. \n\nvar combineMODIS = terra_8day\n.merge(aqua_8day)\n;\n\nprint(\n\"TERRA, AQUA COMBINED\",\ncombineMODIS.size()\n)\n;\n\n// ----------------------------------------------------------------------\n//  Filter collection\n// ----------------------------------------------------------------------\n\n\n// Filter collections by cloudy pixels.\n\nvar output = combineMODIS\n// .filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n.map(geo.icMODIS.maskClouds_8day)                   // Mask cloudy pixels\n//   .map(geo.icMODIS.maskWater_8day)                    // Mask water pixels. \n.map(geo.icMODIS.renameSpectralBands)               // Rename bands because they have weird names.\n;\n\nprint(\"OUTPUT COLLECTION\", output);\n\n\n// ----------------------------------------------------------------------\n//  Display image from collection as Map layer.  \n// ----------------------------------------------------------------------\n\nvar viz = {\n\nbands: ['R', 'G', 'B'],\nmin: [0.01, 0.02, 0.0],\nmax: [0.25, 0.25, 0.175],\ngamma: 1.2,\n\n};\n\n// Define display image \n\nvar display_image = output    // time series collection\n.median()                   // flatten image\n.multiply(0.0001)           // apply scalar for reflectance values  \n;          Map.addLayer(display_image, viz, 'MODIS imagery', false);\n\n\n// // ------------------------------------------------------------------------\n// //  Chart histogram for a selected Image band.  \n// // ------------------------------------------------------------------------\n\n// // Select a band in viz dictionary to chart. \n\n// var select_band = display_image.select(viz.bands[0]);\n\n// // Get AOI from map extent.\n\n// var aoi = geo.uiMap.getAOIfromMapExtent();\n\n// // Get scale from map extent.\n\n// var scale =  Map.getScale();\n\n// // Make and print histogram.\n\n// var histogram = geo.iCart.iHistogram(\n//     select_band, \n//     scale,\n//     aoi                 \n// );\n\n// print(\"Histogram of selected band\", histogram);\n\n\n// ----------------------------------------------------------------------\n//  Calculate spectral index for each image in the collection.  \n// ----------------------------------------------------------------------\n\n// Write computation as a function.  \n\nvar computeND = function(image) {\n\nvar si = image.normalizedDifference(['N', 'R']).rename('NDVI');\n\nreturn image.addBands(si);\n\n};\n\n// Map function over the collection.  \n\nvar output_with_si = output.map(computeND);\n\nprint(\"MAP NDVI\", output.first(), output_with_si.first());\n\n// Display spectral index image from collection as layer on Map.\n\nvar display_image_si = output_with_si     // time series collection\n.median()                               // flatten image\n.select(\"NDVI\")\n; Map.addLayer(display_image_si, {min:-0.8, max:0.8, palette: geo.iPalettes.iDrought}, \"Image with spectral index\");\n\n// ------------------------------------------------------------------------\n//  Define regions of interest.  \n// ------------------------------------------------------------------------\n\n// Gather regions from a feature collection.  \n\nvar regions = ee.FeatureCollection(\"FAO/GAUL/2015/level2\");\n\n// Define a point of interest with geometry tools.\n\nvar geometry = ee.Geometry.Point([-119.72687261495858, 34.42223412451513]);\n\n// Select region of interest with poi.\n\nvar regions_select = regions.filterBounds(geometry);\n\n// ------------------------------------------------------------------------\n//  Display regions of interest as map layers.\n// ------------------------------------------------------------------------\n\nvar strokes = geo.fcCart.paintStrokes(regions, \"white\", 0.5);\n\nMap.addLayer(strokes, {}, \"Region outlines\");\n\nvar strokes_select = geo.fcCart.paintStrokes(regions_select, \"yellow\", 2);\n\nMap.addLayer(strokes_select, {}, \"Selected region outlines\");\n\n// -------------------------------------------------------------\n//  Initialize panel for time series chart. \n// -------------------------------------------------------------\n\nvar panel_chart = geo.icIntervals.initializePanelForChart('bottom-left');\n\nMap.add(panel_chart);\n\n// Define parameters for time series chart.\n\nvar parameters = {\ncollection: output_with_si.select('NDVI'),\nreducer: ee.Reducer.mean(),\nimage_scale: 500,\n// interval_unit: \"month\",          // Comment out to chart by default \"system:time_start\"\npanel: panel_chart,\nroi: regions_select\n};\n\n// Chart time series with parameters. \n\ngeo.icIntervals.chartTimeSeries(parameters);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"starters/NAIP/","title":"NAIP","text":"<p>STARTERS </p>"},{"location":"starters/NAIP/#naip","title":"NAIP","text":"<p>Earth Engine provides images collected from the National Agricultural Imagery Program (NAIP) as cloud assets.</p> <p>The starter script below will help you quickly filter and mosaic this collection for an area of interest.  </p>"},{"location":"starters/NAIP/#naip_1","title":"NAIP","text":"<pre><code>/*    \n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n\n    AUTHOR:     \n    DATE:       \n    TITLE:  NAIP starter \n\n// &gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;\n*/\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n\n// -------------------------------------------------------------\n//  Define AOI from point with 10km buffer.\n// -------------------------------------------------------------\n\nvar geometry = ee.FeatureCollection(\n[ee.Feature(\nee.Geometry.Point([-73.16875, 44.01336]),\n{\n\"system:index\": \"0\"\n})]);\n\nvar aoi = geo.fcProximity.bufferByDistance(geometry, 10000);\n\nMap.centerObject(geometry, 15);\n\n// -------------------------------------------------------------\n//  Get year of interest.\n// -------------------------------------------------------------\n\nvar year_list = geo.icNAIP.yearList(\naoi,        4       // Change to 3 if you would like to include earliest images that lack NIR band.  \n);\n\nvar yoi = year_list.get(0);   // This gets the first year in the year list.\n\n// var yoi = year_list.get(year_list.length().subtract(1));  // This gets the last year.\n\n// print(\"Year of interest\", yoi);\n\n// -------------------------------------------------------------\n//  Filter NAIP image collection by aoi, year, and number of bands.\n// -------------------------------------------------------------\n\nvar ic = ee.ImageCollection(\"USDA/NAIP/DOQQ\")\n.filterBounds(aoi)\n.filter(ee.Filter.calendarRange(yoi, yoi, \"year\"))\n.map(geo.icNAIP.setNumberOfBands)\n.filter(ee.Filter.eq(\"number_of_bands\", 4))\n;\n\n// geo.icGather.inspectCollection(\"NAIP Collection\", ic);\n\n// -------------------------------------------------------------\n//  Mosaic image collection.\n// -------------------------------------------------------------\n\nvar ic_mosaic = geo.icFlatten.mosaicToImage(ic);\n\n// print(\"Mosaic\", ic_mosaic);\n\n// -------------------------------------------------------------\n//  Define viz dictionaries.\n// -------------------------------------------------------------\n\nvar rgb_viz_natural = {\nbands:  ['R', 'G', 'B'],      min:    [0, 0, 0],        max: [255, 255, 255],\ngamma: [1,1,1]    }\n;\n\nvar rgb_viz_false = {\nbands:  ['N', 'R', 'G'],      min:    [0, 0, 0],        max: [255, 255, 255],\ngamma: [1,1,1]    }\n;\n\n// -------------------------------------------------------------\n//  Refine viz dictionaries with histogram.\n// -------------------------------------------------------------\n\n// To refine natural image.\nvar histogram = geo.iCart.iHistogramRGB(ic_mosaic, rgb_viz_natural);\n\n// // To refine false image.\n// var histogram = geo.iCart.iHistogramRGB(ic_mosaic, rgb_viz_false);\n\nprint(histogram);\n\n// -------------------------------------------------------------\n//  Display as Map layers. \n// -------------------------------------------------------------\n\nMap.addLayer(ic_mosaic,rgb_viz_false,\"Earliest False Color\",true);\nMap.addLayer(ic_mosaic,rgb_viz_natural,\"Earliest Natural Color \",true);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"starters/landsat/","title":"Landsat","text":"<p>STARTERS </p>"},{"location":"starters/landsat/#landsat","title":"Landsat","text":"<p>Earth Engine provides a number of different Landsat products as cloud assets.</p> <p>The starter scripts on this page will help you quickly find and process collection 2, tier 1, level 2, surface reflectance data for a place and time of interest.  </p> <p>Since that was a mouthful, let\u2019s define some key terms first.</p>"},{"location":"starters/landsat/#key-terms","title":"key terms","text":""},{"location":"starters/landsat/#collections","title":"collections","text":"<p>There have been two major reprocessing efforts by USGS to improve data quality. Collection 2 is the most recent and has the best geolocation accuracy which improves time series analyses.    </p>"},{"location":"starters/landsat/#tiers","title":"tiers","text":"<p>Within a collection, Tier 1 data have the highest radiometric and positional quality. USGS recommends using Tier 1 data for all time-series analysis.  </p>"},{"location":"starters/landsat/#levels","title":"levels","text":"<p>The level of data processing applied to products.    </p> <ul> <li> <p>Level-1 includes processing to improve locational accuracy of data.  </p> </li> <li> <p>Level-2 products are built from Level 1, but also provide atmospheric correction to create surface reflectance and surface temperature products. Level-2 science products also include spectral indices derived from surface reflectance products.  </p> </li> <li> <p>Level-3 products are built from Level-2 products and include Analysis Ready Data (ARD), including Fractional Snow Covered Area and Burned Area, and Scene-based Inputs, including Provisional Actual Evapotranspiration.   </p> </li> </ul>"},{"location":"starters/landsat/#orbit","title":"orbit","text":"<p>This video visualizes the path of Landsat 8 around the globe. Please note that some details about satellite orbits differ between Landsat missions.</p>"},{"location":"starters/landsat/#spectral-bands","title":"spectral bands","text":"<p>The chart below compares the bands of each mission with respect to spectral and spatial resolution.</p> <p> </p>"},{"location":"starters/landsat/#mother-of-landsat","title":"mother of landsat","text":"<p>Please read Virginia Tower Norwood\u2019s biography.   </p>"},{"location":"starters/landsat/#prereqs","title":"prereqs","text":"<p>To thoughtfully use the starter scripts below, you should be able to answer these questions:  </p> <ul> <li>what is surface reflectance and how does this differ from other Landsat products available through Earth Engine catalog? </li> <li>what is the mission duration (start and end of image collection)?  </li> <li>what is the recurrence time of each scene (how may days between images)?  </li> <li>how does the satellite orbit affect the time difference between neighboring scenes?   </li> <li>what time of day is the scene captured as an image?  </li> <li>what portion of the EM spectrum does each band measure?  </li> <li>what is the spatial resolution of each band?  </li> </ul>"},{"location":"starters/landsat/#snapshots","title":"snapshots","text":"<p>These scripts will help you get started making snapshots from Landsat collections.  </p>"},{"location":"starters/landsat/#landsat-5","title":"Landsat 5","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L5.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/4/2024\n//\n//  Starter for Landsat 5 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ------------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ------------------------------------------------------------------------\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ------------------------------------------------------------------------\n//  Filter and flatten image collection.   \n// ------------------------------------------------------------------------\n\nvar output = ee.ImageCollection('LANDSAT/LT05/C02/T1_L2')\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(1995, 1995, 'year'))\n.filter(ee.Filter.calendarRange(1, 3, 'month'))\n// .filter(ee.Filter.calendarRange(1, 1, 'day_of_year'))\n.filter(ee.Filter.lt('CLOUD_COVER', 20))\n.map(geo.icLandsat.scale_L5)\n.map(geo.icLandsat.cloudMask_L5)\n.median()\n;\n\nprint(\"Landsat 5 image\", output);\n\n// ------------------------------------------------------------------------\n//  Display layer on Map.\n// ------------------------------------------------------------------------\n\nvar viz = {\nbands: ['SR_B3', 'SR_B2', 'SR_B1'],\nmin: [0.0, 0.0, 0.0],\nmax: [0.3, 0.3, 0.3],\n};\n\nMap.addLayer(output, viz, 'Landsat 5 image');\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictinary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(select_band, 30, aoi);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/landsat/#landsat-7","title":"Landsat 7","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L7.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/4/2024\n//\n//  Starter for Landsat 7 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ------------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ------------------------------------------------------------------------\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ------------------------------------------------------------------------\n//  Filter and flatten image collection.   \n// ------------------------------------------------------------------------\n\nvar output = ee.ImageCollection('LANDSAT/LE07/C02/T1_L2')\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(2000, 2000, 'year'))     // January 1999\u2013April 2022\n.filter(ee.Filter.calendarRange(1, 3, 'month'))\n// .filter(ee.Filter.calendarRange(1, 1, 'day_of_year'))\n// .filter(ee.Filter.lt('CLOUD_COVER', 20))\n.map(geo.icLandsat.scale_L7)\n.map(geo.icLandsat.cloudMask_L7)\n.median()\n;\n\nprint(\"Landsat 7 image\", output);\n\n// ------------------------------------------------------------------------\n//  Display as layer on Map.\n// ------------------------------------------------------------------------\n\nvar viz = {\nbands: ['SR_B3', 'SR_B2', 'SR_B1'],\nmin: [0.0, 0.0, 0.0],\nmax: [0.3, 0.3, 0.3]\n};\n\nMap.addLayer(output, viz, 'Landsat 7 image');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictinary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(select_band, 30, aoi);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/landsat/#landsat-8","title":"Landsat 8","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L8.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/4/2024\n//\n//  Starter for Landsat 8 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ------------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ------------------------------------------------------------------------\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n// ----------------------------------------------------------------------\n//  Filter and flatten image collection. \n// ----------------------------------------------------------------------\n\nvar output = ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(2015, 2015, 'year'))\n.filter(ee.Filter.calendarRange(1, 3, 'month')) // .filter(ee.Filter.calendarRange(1, 1, 'day_of_year')) \n// .filter(ee.Filter.lt('CLOUD_COVER',20))\n.map(geo.icLandsat.scale_L8)\n.map(geo.icLandsat.cloudMask_L8)\n.median()\n;\n\nprint(\"Landsat 8 image\", output);\n\n// ----------------------------------------------------------------------\n//  Display as layer on Map.\n// ----------------------------------------------------------------------\n\nvar viz = {\nbands: ['SR_B4', 'SR_B3', 'SR_B2'],\nmin: [0.0, 0.0, 0.0],\nmax: [0.25, 0.25, 0.25],\n};\n\nMap.addLayer(output, viz, 'Landsat 8 image');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictinary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(select_band, 30, aoi);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/landsat/#landsat-9","title":"Landsat 9","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_L9.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/4/2024\n//\n//  Starter for Landsat 9 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ------------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ------------------------------------------------------------------------\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 8);\n\n\n// ----------------------------------------------------------------------\n//  Filter and flatten image collection.\n// ----------------------------------------------------------------------\n\nvar output = ee.ImageCollection(\"LANDSAT/LC09/C02/T1_L2\")\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(2022, 2022, 'year'))\n.filter(ee.Filter.calendarRange(1, 3, 'month')) // .filter(ee.Filter.calendarRange(1, 1, 'day_of_year')) \n// .filter(ee.Filter.lt('CLOUD_COVER',20))\n.map(geo.icLandsat.scale_L9)\n.map(geo.icLandsat.cloudMask_L9)\n.median()\n;\n\nprint(\"Landsat 9 image\", output);\n\n// ----------------------------------------------------------------------\n//  Display image as layer on Map.\n// ----------------------------------------------------------------------\n\nvar viz = {\nbands: ['SR_B4', 'SR_B3', 'SR_B2'],\nmin: [0.0, 0.0, 0.0],\nmax: [0.25, 0.25, 0.25],\n};\n\nMap.addLayer(output, viz, 'Landsat 9 image');\n\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictinary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(select_band, 30, aoi);\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre>"},{"location":"starters/landsat/#land-surface-temperature","title":"Land Surface Temperature","text":"<p>Sofia Ermida wrote and shared a super helpful module that makes it relatively easy to compute land surface temperature (LST) from Landsat collections. The script below outlines a basic pattern for using her module.  </p> <pre><code>// Load module to compute LST from Landsat.\n\nvar LandsatLST = require('users/sofiaermida/landsat_smw_lst:modules/Landsat_LST.js');\n\n// Define arguments for LST module. \n\nvar date_start = '2020-07-01';            // Filter collection by time start.\nvar date_end = '2024-09-01';              // Filter collection by time end.\nvar region = aoi;                         // Filter collection by location.\nvar use_ndvi = true;                      // Use NDVI in computation (true or false)\n\n// Compute LST from Landsat 9.  \n\nvar L9 = LandsatLST\n.collection\n(\n'L9',                               // Landsat mission  - note this is a string 'L9'.\ndate_start,                         date_end,                        region,                               use_ndvi                                )\n;\n</code></pre> <p>Note that you call the Landsat mission with a string:  </p> <ul> <li><code>\"L9\"</code> calls Landsat 9  </li> <li><code>\"L8\"</code> calls Landsat 8  </li> <li><code>\"L7\"</code> calls Landsat 7   </li> <li><code>\"L5\"</code> calls Landsat 5   </li> </ul> <p>Sofia\u2019s script pulls data from both surface reflectance and top of atmosphere Landsat collections, so behind the scenes the string that you enter as an argument points to a set of instructions for working with that mission data that the module carries out. The underlying code is public-facing on her github site if you would like to understand in detail how it works. You can also read her article on the module if you would like to learn more.  </p> <p>This work is licensed under CC BY-NC-SA 4.0</p>"},{"location":"starters/sentinel/","title":"Sentinel","text":"<p>STARTERS </p>"},{"location":"starters/sentinel/#sentinel","title":"Sentinel","text":"<p>Earth Engine provides a number of different Sentinel products as cloud assets.</p>"},{"location":"starters/sentinel/#sentinel-2-msi","title":"Sentinel-2 MSI","text":"<p>The starter below will help you quickly find and process Level 1-C Harmonized Surface Reflectance data from the Sentinel 2 Multispectral Instrument (MSI). </p>"},{"location":"starters/sentinel/#prereqs","title":"prereqs","text":"<p>To thoughtfully use the starter script below, you should be able to answer these questions:</p> <ul> <li>what is surface reflectance and how does this differ from other Sentinel products available through Earth Engine catalog?</li> <li>why is harmonized data helpful for time series analysis?  </li> <li>what is the mission duration (start and end of image collection)?</li> <li>what is the recurrence time of each scene (how may days between images)?</li> <li>how does the satellite orbit affect the time difference between neighboring scenes?</li> <li>what time of day is the scene captured as an image?</li> <li>what portion of the EM spectrum does each band measure?</li> <li>what is the spatial resolution of each band?</li> </ul> <p>You can glean much of this info from these resources:  </p> <ul> <li>Earth Engine data catalog </li> <li>ESA Copernicus page </li> <li>Sentinel 2 on SentiWiki </li> </ul>"},{"location":"starters/sentinel/#spectral-bands","title":"spectral bands","text":"<p>The chart below shows how the MSI sensor on Sentinel compares to the sensors onboard the Landsat missions.  </p> <p></p>"},{"location":"starters/sentinel/#starter","title":"starter","text":"<pre><code>//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n//  Title:        starter_S2.js\n//  Author:       Jeff Howarth\n//  Last edited:  11/12/2023\n//\n//  Starter for harmonized Sentinel 2 collection. \n//  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nvar geo = require(\"users/jhowarth/eePatterns:modules/geo.js\");\n\nprint(\"geo methods dictionary\", geo.help);    // Prints dictionary of all tools in module.  \nprint(\"geo palettes\", geo.iPalettes);         // Prints dictionary of all palettes in module. \n\n// ----------------------------------------------------------------------\n//  Define your point or area of interest with geometry tools. \n// ----------------------------------------------------------------------\n\nvar geometry = ee.Geometry.Point([37.34715255366928, -3.0521293499524087]);\n\nMap.centerObject(geometry, 9);\n\n// ----------------------------------------------------------------------\n//  Filter and flatten image collection.\n// ----------------------------------------------------------------------\n\nvar output = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n.filterBounds(geometry)\n// .filter(ee.Filter.calendarRange(2020, 2020, 'year'))\n.filter(ee.Filter.calendarRange(1, 3, 'month')) // .filter(ee.Filter.calendarRange(1, 30, 'day')) \n.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))\n.map(geo.icSentinel.cloudMask_S2)\n.map(geo.icSentinel.scale_S2)\n.median()\n;\n\nprint(output);\n\n// ----------------------------------------------------------------------\n//  Display layer on Map. \n// ----------------------------------------------------------------------\n\n// Print list of band names for S2.\n\nprint(\n\"S2 BAND LIST\",\ngeo.icSentinel.bands_S2\n);\n\n// Define viz parameters. \n\nvar viz = {\nbands: ['B4', 'B3', 'B2'],\nmin: [0, 0, 0],\nmax: [0.2, 0.15, 0.1]\n};\n\n// Add layer to Map. \n\nMap.addLayer(output, viz, 'From Sentinel 2 Collection');\n\n// ------------------------------------------------------------------------\n//  Chart histogram for a selected Image band.  \n// ------------------------------------------------------------------------\n\n// Select a band in viz dictionary to chart. \n\nvar select_band = output.select(viz.bands[0]);\n\n// Get AOI from map extent.\n\nvar aoi = geo.uiMap.getAOIfromMapExtent();\n\n// Get scale from map extent.\n\nvar scale =  Map.getScale();\n\n// Make and print histogram.\n\nvar histogram = geo.iCart.iHistogram(\nselect_band, scale,\naoi                 );\n\nprint(\"Histogram of selected band\", histogram);\n</code></pre> <p>This work is licensed under CC BY-NC-SA 4.0</p>"}]}